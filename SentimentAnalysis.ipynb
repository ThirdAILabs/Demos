{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **IMPORTANT**\n",
    "To run this notebook, you need to download the ThirdAI docker container by signing up [here](https://www.thirdai.com/try-bolt/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Sentiment analysis with BOLT**\n",
    "\n",
    "We will walk through the process of building a sentiment analysis model with BOLT from data preprocessing all the way to inference. This notebook is structured as follows:\n",
    "1. Selecting and preprocessing the dataset\n",
    "2. Defining the BOLT network\n",
    "3. Training the network\n",
    "4. Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Choosing and preprocessing the dataset**\n",
    "At our webinar on April 6th, we showed how BOLT reached state-of-the-art accuracy on the [Yelp Reviews](https://github.com/huggingface/datasets/blob/master/datasets/yelp_polarity/yelp_polarity.py) dataset and demonstrated that a model trained on the [Amazon Polarity](https://huggingface.co/datasets/amazon_polarity) dataset can be used for interactive, real-time sentiment analysis. Now, we want to give you a chance to try out BOLT with a dataset of your choice. \n",
    "\n",
    "We provided a utility function that converts text datasets into input vectors and saves them in SVM format. The text dataset must be a CSV file where each row follows this format:\n",
    "\n",
    "\\<pos or neg\\>,\\<text\\> \n",
    "\n",
    "For example, we can have a training corpus called example_train.csv that contains the following:\n",
    "```\n",
    "pos,Had a great time at the webinar.\n",
    "neg,I hate slow deep learning models.\n",
    "```\n",
    "We recommend using a training corpus with at least 500,000 training samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thirdai import dataset\n",
    "\n",
    "text_vector_dim = 100000 # We will vectorize our samples into 100,000-dimensional sparse vectors.\n",
    "\n",
    "path_to_train_svm = dataset.tokenize_to_svm(\n",
    "    filename=\"/path/to/train_data.csv\", # TODO: Change the path to train data\n",
    "    output_dim=text_vector_dim, \n",
    "    train=True)\n",
    "\n",
    "path_to_test_svm = dataset.tokenize_to_svm(\n",
    "    filename=\"/path/to/test_data.csv\", # TODO: Change the path to test data\n",
    "    output_dim=text_vector_dim,\n",
    "    train=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now load the SVM datasets that we just generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset.load_bolt_svm_dataset(\n",
    "    filename=path_to_train_svm, \n",
    "    batch_size=256)\n",
    "\n",
    "test_data = dataset.load_bolt_svm_dataset(\n",
    "    filename=path_to_test_svm, \n",
    "    batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Defining the BOLT network**\n",
    "**Layer configuration**\n",
    "\n",
    "First, we need to define the sequence of layers. In this limited demo version, we only support fully-connected layers, which we define with using `bolt.FullyConnected()`. It takes the following arguments:\n",
    "* `dim`: Int - The dimension of the layer.\n",
    "* `load_factor`: Float - The fraction of neurons to use during sparse training and sparse inference. For example, `load_factor`=0.05 means the layer uses 5% of its neurons when processing an individual sample.\n",
    "* `activation_function`: Bolt activation function - We support three activation functions: `ReLU`, `Softmax` and `Linear`.\n",
    "\n",
    "**Constructing the network**\n",
    "\n",
    "We then call the `bolt.Network()` constructor, which takes in the sequence of layer configurations we defined earlier as well as the dimension of the input vectors.\n",
    "\n",
    "**Network specifications**\n",
    "\n",
    "The network defined below has the same specifications as the network that we used for sentiment analysis on the [Yelp Reviews dataset](https://github.com/huggingface/datasets/blob/master/datasets/yelp_polarity/yelp_polarity.py) during our April 6th webinar. It is a 202,000 parameter model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thirdai import bolt\n",
    "\n",
    "layers = [\n",
    "    \n",
    "    bolt.FullyConnected(\n",
    "        dim=2000, \n",
    "        load_factor=0.2, \n",
    "        activation_function=bolt.ActivationFunctions.ReLU),\n",
    "        \n",
    "    bolt.FullyConnected(\n",
    "        dim=2,\n",
    "        load_factor=1.0, \n",
    "        activation_function=bolt.ActivationFunctions.Softmax)     \n",
    "]\n",
    "\n",
    "network = bolt.Network(\n",
    "    layers=layers, \n",
    "    input_dim=text_vector_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Training\n",
    "**The train() method**\n",
    "\n",
    "Train the BOLT network by calling the `train()` method, which accepts the following arguments:\n",
    "* `train_data`: BOLT dataset - The training dataset in a format returned by `dataset.load_bolt_svm_dataset()`.\n",
    "* `loss_fn`: BOLT loss function - The loss function to minimize. In this demo version, we only support the `bolt.CategoricalCrossEntropyLoss()` loss function.\n",
    "* `learning_rate`: Float - The learning rate for gradient descent. The default value is 0.0001.\n",
    "* `epochs`: Int - The number of training epochs (a full cycle through the dataset).\n",
    "* `verbose` (Optional): Boolean - Set to `True` to print a progress bar, accuracy, and elapsed time for each training epoch. Set to `False` otherwise. `True` by default.\n",
    "\n",
    "It then returns a dictionary that contains the loss value and elapsed time for each training epoch.\n",
    "\n",
    "\n",
    "**Training with sparse inference in mind**\n",
    "\n",
    "If you plan to use sparse inference, we recommend calling the `enable_sparse_inference()` method before the last training epoch for accuracy improvements. For example, if the model trains for 10 epochs, this method should be called after the 9th epoch.\n",
    "\n",
    "\n",
    "**Saving a trained model**\n",
    "\n",
    "Simply call the `save()` method, passing in the location of the save file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.train(\n",
    "    train_data=train_data,\n",
    "    loss_fn=bolt.CategoricalCrossEntropyLoss(), \n",
    "    learning_rate=0.0001, \n",
    "    epochs=20, \n",
    "    verbose=True)\n",
    "\n",
    "network.enable_sparse_inference()\n",
    "\n",
    "network.train(\n",
    "    train_data=train_data,\n",
    "    loss_fn=bolt.CategoricalCrossEntropyLoss(), \n",
    "    learning_rate=0.0001, \n",
    "    epochs=1,\n",
    "    verbose=True)\n",
    "\n",
    "# network.save(filename=\"/home/thirdai/work/saved_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4. Inference**\n",
    "**The predict() method**\n",
    "\n",
    "You can do inference by calling the `predict()` method, which accepts the following arguments:\n",
    "* `test_data`: BOLT dataset - The test dataset in a format returned by `dataset.load_bolt_svm_dataset()`.\n",
    "* `metrics`: List of strings - Metric to evaluate our prediction. In this demo version, we only support the `\"categorical_accuracy\"` metric.\n",
    "* `verbose` (Optional): Boolean - Set to `True` to print a progress bar, accuracy, and inference time. Set to `False` otherwise. `True` by default.\n",
    "\n",
    "It then returns a tuple of `(predictions, metric_results)`:\n",
    "* `predictions`: 2-dimensional Numpy array where - The i-th row is the output of the network for the i-th example in the dataset.\n",
    "* `metric_results`: Dictionary - A dictionary mapping each metric name in `metrics` to a list of values for that metric for each epoch (only one entry if returned by `predict()` method). An \"epoch_times\" metric is included by default.\n",
    "\n",
    "**Loading a saved model**\n",
    "\n",
    "To load a saved model, call the `bolt.Network.load()` method. We commented it out by default so you can just continue from the previous cell, but you can always uncomment it so you don't have to retrain the model the next time you visit this notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the next line to load a saved model.\n",
    "# network = bolt.Network.load(filename=\"/home/thirdai/work/saved_model\") \n",
    "\n",
    "predictions, metric_results = network.predict(\n",
    "    test_data=test_data, \n",
    "    metrics=[\"categorical_accuracy\"], \n",
    "    verbose=True)\n",
    "\n",
    "print(predictions)\n",
    "print(metric_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Congratulations! You just mastered BOLT.**\n",
    "If you face any issue running this notebook, please reach out to us by posting about it on [GitHub Issues](https://github.com/ThirdAILabs/Demos/issues)."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "770f9d9b0f5fef3cad996c08049ad520e594e1704f62e887f7dfddd0f70ee730"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
