{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Node Classification with ThirdAI's Universal Deep Transformer\n",
    "This notebook shows how to build a node prediction model with ThirdAI's Universal Deep Transformer (UDT) model. In this demo, we will train and evaluate the model on the YelpCHI dataset, but you can easily replace this with your own dataset.\n",
    "\n",
    "You can immediately run a version of this notebook in your browser on Google Colab at the following link:\n",
    "\n",
    "https://githubtocolab.com/ThirdAILabs/Demos/blob/main/GraphNodeClassification.ipynb\n",
    "\n",
    "This notebook uses an activation key that will only work with this demo. If you want to try us out on your own dataset, you can obtain a free trial license at the following link: https://www.thirdai.com/try-bolt/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install thirdai --upgrade\n",
    "!pip3 install scikit-learn\n",
    "\n",
    "# This activates the ThirdAI package with a key that is only good for this demo\n",
    "import thirdai\n",
    "\n",
    "thirdai.licensing.activate(\"MWHE-FVNH-3XN3-KWXY-TFRA-X3VJ-U7FT-RLVR\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Download\n",
    "We will use the demos module in the thirdai package to download the YelpCHI dataset. You can replace this step and the next step with a download method and a UDT initialization step that is specific to your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thirdai.demos import download_yelp_chi_dataset\n",
    "\n",
    "train_data_path, _, inference_samples, _ = download_yelp_chi_dataset()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UDT Initialization\n",
    "We can now create a UDT model by passing in the types of each column in the dataset and the target column we want to be able to predict. The input format for training UDT on a graph dataset is a typical CSV, where every row represents a single node in the graph. The bolt.types.node_id() column should be a unique integer identifying the node, while the bolt.types.neighbors() column should be a space separated list of node ids corresponding to the node's neighbors. For YelpChi, each node additionally has 32 numerical features (a \"feature vector\"), as well as a target column we wish to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thirdai import bolt\n",
    "\n",
    "model = bolt.UniversalDeepTransformer(\n",
    "    data_types={\n",
    "        \"node_id\": bolt.types.node_id(),\n",
    "        **{f\"col_{i}\": bolt.types.numerical([0, 1]) for i in range(32)},\n",
    "        \"target\": bolt.types.categorical(),\n",
    "        \"neighbors\": bolt.types.neighbors(),\n",
    "    },\n",
    "    target=\"target\",\n",
    "    n_target_classes=2,\n",
    "    integer_target=True,\n",
    "    # Optional: you can remove the next line to increase AUC to ~0.93 at the\n",
    "    # cost of increasing training time\n",
    "    options={\"contextual_columns\": False},\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexing\n",
    "Graph models with UDT require an additional *indexing* step before training. Since nodes in the train set have neighbors in the eval set, we must tell the model about the node features of nodes in the eval set before training. This effectively gives the UDT model complete knowledge of the graph structure and features before training. The eval set has all labels set to 0, so this is not leaking testing information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.index_nodes(eval_data_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "We can now train our UDT graph model! Feel free to customize the number of epochs and the learning rate; we have chosen values that give good convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(\n",
    "    train_data_path, learning_rate=0.001, epochs=15, metrics=[\"categorical_accuracy\"]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "We can evaluate the performance of UDT by calculating the Area Under the Receiver Operating Characteristic Curve (ROC AUC). UDT achieves about 91% with the default configurations in this notebook, and as noted above we achieve 93-94% with longer training time (the previous SOTA was [90%](https://paperswithcode.com/sota/node-classification-on-yelpchi)). Here, we show the predict API, where we pass in samples without labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "ground_truth = [inference_sample[1] for inference_sample in inference_samples]\n",
    "\n",
    "predictions = []\n",
    "ground_truths = []\n",
    "for sample, ground_truth in inference_samples:\n",
    "    prediction = model.predict(sample)\n",
    "    predictions.append(prediction)\n",
    "    ground_truths.append(ground_truth)\n",
    "predictions = np.array(predictions)\n",
    "\n",
    "auc = metrics.roc_auc_score(ground_truths, predictions[:, 1])\n",
    "\n",
    "print(\"Test AUC:\", auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
