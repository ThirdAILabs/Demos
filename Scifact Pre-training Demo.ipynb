{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-training and fine-tuning an LLM on CPU on BEIR datasets with ThirdAI's UDT\n",
    "\n",
    "In this notebook, we will pre-train a large language model from scratch on the popular BEIR datasets (https://github.com/beir-cellar/beir) using ThirdAIs Universal Deep Transformer (UDT). We will use just the 'Scifact' dataset to demonstrate how UDT can just fine-tune on a small dataset and outperform T5-large trained on a huge corpus. \n",
    "\n",
    "This demo shows that one-model for all is not sub-optimal and pre-training on specific downstream datasets is required to get the best results.\n",
    "\n",
    "While most LLMs cannot be fine-tuned even on a powerful GPU, ThirdAI's UDT can train a billion parameter model on just a moderate CPU in few minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import thirdai and activate license"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thirdai import bolt,licensing\n",
    "\n",
    "licensing.activate('8E46E4-653FD6-AA2B02-65E265-A4FACA-V3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and process the dataset into a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thirdai.demos import download_beir_dataset\n",
    "\n",
    "dataset = \"scifact\"\n",
    "unsup_file, sup_train_file, sup_test_file, n_target_classes = download_beir_dataset(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above step, *unsup_file* refers to the corpus file with document id, title and text. We can have even more columns with other metadata for each document. Pre-training with UDT supports two types of columns, strong and weak. For the purpose of this demo, we choose 'title' to be the strong column and 'text' to be the weak column. You can play with different settings shown in the pre-training (model.cold_start()) step.\n",
    "\n",
    "A couple of sample rows of the *unsup_file* are shown below.\n",
    "\n",
    "PLEASE NOTE: Currently, UDT's cold_start function requires the DOC_ID to be an integer. We will add support for other formats in a future release."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOC_ID</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.</td>\n",
       "      <td>alterations of the architecture of cerebral white matter in the developing human brain can affect cortical development and result in functional disabilities. a line scan diffusion-weighted magnetic resonance imaging (mri) sequence with diffusion tensor analysis was applied to measure the apparent diffusion coefficient  to calculate relative anisotropy  and to delineate three-dimensional fiber architecture in cerebral white matter in preterm (n = 17) and full-term infants (n = 7). to assess effects of prematurity on cerebral white matter development  early gestation preterm infants (n = 10) were studied a second time at term. in the central white matter the mean apparent diffusion coeffic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>induction of myelodysplasia by myeloid-derived suppressor cells.</td>\n",
       "      <td>myelodysplastic syndromes (mds) are age-dependent stem cell malignancies that share biological features of activated adaptive immune response and ineffective hematopoiesis. here we report that myeloid-derived suppressor cells (mdsc)  which are classically linked to immunosuppression  inflammation  and cancer  were markedly expanded in the bone marrow of mds patients and played a pathogenetic role in the development of ineffective hematopoiesis. these clonally distinct mdsc overproduce hematopoietic suppressive cytokines and function as potent apoptotic effectors targeting autologous hematopoietic progenitors. using multiple transfected cell models  we found that mdsc expansion is driven ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DOC_ID  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         TEXT\n",
       "0       0  ...  alterations of the architecture of cerebral white matter in the developing human brain can affect cortical development and result in functional disabilities. a line scan diffusion-weighted magnetic resonance imaging (mri) sequence with diffusion tensor analysis was applied to measure the apparent diffusion coefficient  to calculate relative anisotropy  and to delineate three-dimensional fiber architecture in cerebral white matter in preterm (n = 17) and full-term infants (n = 7). to assess effects of prematurity on cerebral white matter development  early gestation preterm infants (n = 10) were studied a second time at term. in the central white matter the mean apparent diffusion coeffic...\n",
       "1       1  ...  myelodysplastic syndromes (mds) are age-dependent stem cell malignancies that share biological features of activated adaptive immune response and ineffective hematopoiesis. here we report that myeloid-derived suppressor cells (mdsc)  which are classically linked to immunosuppression  inflammation  and cancer  were markedly expanded in the bone marrow of mds patients and played a pathogenetic role in the development of ineffective hematopoiesis. these clonally distinct mdsc overproduce hematopoietic suppressive cytokines and function as potent apoptotic effectors targeting autologous hematopoietic progenitors. using multiple transfected cell models  we found that mdsc expansion is driven ...\n",
       "\n",
       "[2 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.options.display.max_colwidth = 700\n",
    "pd.read_csv(unsup_file, nrows=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a UDT model\n",
    "\n",
    "The column name 'QUERY' has to match with the on in the header in *unsup_test_file*.\n",
    "The column name 'DOC_ID' should match with the one in the header of the corpus file (*unsup_file*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = bolt.UniversalDeepTransformer(\n",
    "    data_types={\n",
    "        \"QUERY\": bolt.types.text(),\n",
    "        \"DOC_ID\": bolt.types.categorical(delimiter=':'),\n",
    "    },\n",
    "    target=\"DOC_ID\",\n",
    "    n_target_classes=n_target_classes,\n",
    "    integer_target=True,\n",
    "    model_config='./configs/embeddings_and_cold_start.config',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-train (Cold Start) on the *unsup_file*\n",
    "\n",
    "In the following step, we do the pre-training by specifying the strong and weak columns. For this demo, we use 'TITLE' as the strong column and 'TEXT' as the weak column. We can have more columns in either of the lists. The training time and the test accuracies are shown below. We can see that by just pre-traiing on the Scifact dataset, we get 40% precision@1 which beats T5-large's performance on the same dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded data | source 'scifact/unsupervised.csv' | vectors 110213 | batches 54 | time 0s | complete\n",
      "\n",
      "train | epoch 0 | train_steps 54 | {} | train_batches 54 | time 19s | complete  \n",
      "\n",
      "train | epoch 1 | train_steps 108 | {} | train_batches 54 | time 18s | complete \n",
      "\n",
      "train | epoch 2 | train_steps 162 | {} | train_batches 54 | time 18s | complete \n",
      "\n",
      "train | epoch 3 | train_steps 216 | {} | train_batches 54 | time 17s | complete \n",
      "\n",
      "train | epoch 4 | train_steps 270 | {} | train_batches 54 | time 17s | complete \n",
      "\n",
      "loaded data | source 'scifact/tst_supervised.csv' | vectors 300 | batches 1 | time 0s | complete\n",
      "\n",
      "evaluate | epoch 5 | train_steps 270 | {categorical_accuracy: 0.4, Recall@100: 0.823} | eval_batches 1 | time 24ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.cold_start(\n",
    "    filename=unsup_file,\n",
    "    strong_column_names=[\"TITLE\"],\n",
    "    weak_column_names=[\"TEXT\"],\n",
    "    learning_rate=0.001,\n",
    "    epochs=5,\n",
    ")\n",
    "\n",
    "activations = model.evaluate(sup_test_file, metrics=['categorical_accuracy','recall@100'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tune on supervised data (OPTIONAL)\n",
    "\n",
    "If you have supervised data that maps queries to documents, you can further improve the model performance by fine-tuning your pre-trained model on the supervised data.\n",
    "\n",
    "Please note that in your *sup_train_file* and *sup_test_file* should have the same column names 'QUERY' and 'DOC_ID'.\n",
    "\n",
    "The training time to fine-tune and the final accuracy are shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded data | source 'scifact/trn_supervised.csv' | vectors 809 | batches 1 | time 0s | complete\n",
      "\n",
      "train | epoch 5 | train_steps 271 | {} | train_batches 1 | time 1s | complete   \n",
      "\n",
      "train | epoch 6 | train_steps 272 | {} | train_batches 1 | time 1s | complete   \n",
      "\n",
      "train | epoch 7 | train_steps 273 | {} | train_batches 1 | time 1s | complete   \n",
      "\n",
      "train | epoch 8 | train_steps 274 | {} | train_batches 1 | time 1s | complete   \n",
      "\n",
      "train | epoch 9 | train_steps 275 | {} | train_batches 1 | time 1s | complete   \n",
      "\n",
      "loaded data | source 'scifact/tst_supervised.csv' | vectors 300 | batches 1 | time 0s | complete\n",
      "\n",
      "evaluate | epoch 10 | train_steps 275 | {categorical_accuracy: 0.583333, Recall@100: 0.891} | eval_batches 1 | time 30ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.train(\n",
    "    filename=sup_train_file,\n",
    "    learning_rate=0.001,\n",
    "    epochs=5,\n",
    ")\n",
    "\n",
    "activations = model.evaluate(sup_test_file, metrics=['categorical_accuracy','recall@100'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./scidocs.model')\n",
    "\n",
    "model = bolt.UniversalDeepTransformer.load('./scidocs.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparisons against T5\n",
    "\n",
    "| Model | Precision@1 | Recall@100 |\n",
    "| --- | --- | --- |\n",
    "| UDT (pre-training + fine-tuning) | 58% | 90% |\n",
    "|  UDT (just pre-training) |     40%     | 82.3%      |\n",
    "| T5-large | 39.3%    | 82%        |\n",
    "| T5-base |  34.7%    | 80%        |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
