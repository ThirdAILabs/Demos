{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intent Classification with ThirdAI's Universal Deep Transformer\n",
    "This notebook shows how to build an intent classification model with ThirdAI's Universal Deep Transformer (UDT) model, our all-purpose classifier for tabular datasets. In this demo, we will train and evaluate the model on the CLINC 150 dataset, but you can easily replace this with your own dataset.\n",
    "\n",
    "You can immediately run a version of this notebook in your browser on Google Colab at the following link:\n",
    "\n",
    "https://githubtocolab.com/ThirdAILabs/Demos/blob/main/IntentClassification.ipynb\n",
    "\n",
    "This notebook uses an activation key that will only work with this demo. If you want to try us out on your own dataset, you can obtain a free trial license at the following link: https://www.thirdai.com/try-bolt/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install thirdai --upgrade\n",
    "\n",
    "# This activates the ThirdAI package with a key that is only good for this demo\n",
    "import thirdai\n",
    "thirdai.activate(\"PRCH-AAVV-3ART-3WY9-PM9H-KULT-PRW3-C399\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Download\n",
    "We will use the demos module in the thirdai package to download the CLINC 150 dataset. You can replace this step and the next step with a download method and a UDT initialization step that is specific to your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thirdai.demos import download_clinc_dataset\n",
    "\n",
    "train_filename, test_filename, inference_batch = download_clinc_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UDT Initialization\n",
    "We can now create a UDT model by passing in the types of each column in the dataset and the target column we want to be able to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thirdai import bolt\n",
    "\n",
    "model = bolt.UniversalDeepTransformer(\n",
    "    data_types={\n",
    "        \"text\": bolt.types.text(),\n",
    "        \"category\": bolt.types.categorical(),\n",
    "    },\n",
    "    target=\"category\",\n",
    "    n_target_classes=151,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "We can now train our UDT model with just one line! Feel free to customize the number of epochs and the learning rate; we have chosen values that give good convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(train_filename, epochs=5, learning_rate=0.01, metrics=[\"categorical_accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "Evaluating the performance of the UDT model is also just one line!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_filename, metrics=[\"categorical_accuracy\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and Loading\n",
    "Saving and loading a trained UDT model to disk is also extremely straight forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_location = \"intent_classification.model\"\n",
    "\n",
    "# Saving\n",
    "model.save(save_location)\n",
    "\n",
    "# Loading\n",
    "model = bolt.UniversalDeepTransformer.load(save_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Predictions\n",
    "The evaluation method is great for testing, but it requires labels, which don't exist in a production setting. We also have a predict method that can take in an in-memory batch of rows or a single row (without the target column), allowing easy integration into production pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(\"Inference batch:\", inference_batch, \"\\n\")\n",
    "\n",
    "prediction = model.predict(inference_batch[0])\n",
    "class_name = model.class_name(np.argmax(prediction))\n",
    "print(\"Input:\", inference_batch[0], \"Prediction:\", class_name, \"\\n\")\n",
    "\n",
    "prediction_batch = model.predict_batch(inference_batch)\n",
    "class_names = [\n",
    "    model.class_name(class_id) for class_id in np.argmax(prediction_batch, axis=1)\n",
    "]\n",
    "print(\"Batch Prediction Results\")\n",
    "for input_sample, class_name in zip(inference_batch, class_names):\n",
    "    print(\"Input:\", input_sample, \"Prediction:\", class_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
