{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PII (Personally Identifiable Information) Detection with a pre-trained BOLT NER model\n",
    "\n",
    "In this notebook, we will show how to use ThirdAI's pre-trained PII detection model on your dataset. This model was trained on a proprietaty synthetic dataset generated from GPT-4. This is a multi-lingual model that was trained on English, French, Spanish and Italian data. It detects the following types of PII:\n",
    "\n",
    "* NAME\n",
    "* EMAIL\n",
    "* HOMEADDRESS\n",
    "* DOB\n",
    "* UIN\n",
    "* PHONENUMBER\n",
    "* DATE\n",
    "* VEHICLEUIN\n",
    "* AGE\n",
    "* GENDER\n",
    "* HEIGHT\n",
    "* USERNAME\n",
    "* PASSWORD\n",
    "* OCCUPATION\n",
    "* ACCOUNTNUMBER\n",
    "* PIN\n",
    "* CREDITCARDNUMBER\n",
    "* SEX\n",
    "* AMOUNT\n",
    "* ACCOUNTNAME\n",
    "* IBAN\n",
    "* ORGANIZATION\n",
    "* URL\n",
    "* CREDITCARDCVV\n",
    "\n",
    "The latter part of the script shows how to load a pretrained model and train it on new PII entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install thirdai --upgrade\n",
    "!pip3 install datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activate your ThirdAI License Key\n",
    "\n",
    "You can apply for a trial license [here](https://www.thirdai.com/try-bolt/) ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from thirdai import bolt, licensing\n",
    "import utils\n",
    "\n",
    "import os\n",
    "\n",
    "if \"THIRDAI_KEY\" in os.environ:\n",
    "    licensing.activate(os.environ[\"THIRDAI_KEY\"])\n",
    "else:\n",
    "    licensing.activate(\"\")  # Enter your ThirdAI key here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.isdir(\"./models/\"):\n",
    "    os.system(\"mkdir ./models/\")\n",
    "\n",
    "if not os.path.exists(\"./models/pretrained_multilingual.model\"):\n",
    "    os.system(\n",
    "        \"wget -nv -O ./models/pretrained_multilingual.model 'https://www.dropbox.com/scl/fi/jxo7pk93wubae5zxatx5m/udt_pretrained_small.bolt?rlkey=cq1fz98z33ljem6kb4i5o5oki&st=98aut7bu&dl=0'\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pii_model = bolt.UniversalDeepTransformer.load(\"./models/pretrained_multilingual.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Pretrained Model Out of the Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sentence = \"I'm Robert. I work for as an AI Engineer for a startup in Houston. I want to apply for a credit card. My email is robbie@gmail.com.\"\n",
    "\n",
    "predicted_tags = pii_model.predict({\"source\": sample_sentence}, top_k=1)\n",
    "\n",
    "for i, token in enumerate(sample_sentence.split()):\n",
    "    if predicted_tags[i][0][0] != \"O\":\n",
    "        print(token + \" : \" + predicted_tags[i][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sentence = \"I'm Siddharth. I work at for a big multinational company in Mountain View. I want to cancel my credit card with number 4147202361663155.\"\n",
    "\n",
    "predicted_tags = pii_model.predict({\"source\": sample_sentence}, top_k=1)\n",
    "\n",
    "for i, token in enumerate(sample_sentence.split()):\n",
    "    if predicted_tags[i][0][0] != \"O\":\n",
    "        print(token + \" : \" + predicted_tags[i][0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetune a pretrained model on your own data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a Tag to label Map\n",
    "\n",
    "Tag to Label Map is used to map text entities to their corresponding integer labels while training/inferencing using a model. \n",
    "\n",
    "Note: Ensure that the tags in your dataset should not be outside of TAG_MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAGS= [\n",
    "    \"B-PER\",\n",
    "    \"I-PER\",\n",
    "    \"B-ORG\",\n",
    "    \"I-ORG\",\n",
    "    \"B-LOC\",\n",
    "    \"I-LOC\",\n",
    "    \"B-MISC\",\n",
    "    \"I-MISC\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and Process the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = utils.download_conll_dataset_as_file(\"train\")\n",
    "validation_file = utils.download_conll_dataset_as_file(\"validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize a NER Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_model = bolt.UniversalDeepTransformer(\n",
    "    data_types={\n",
    "        \"source\": bolt.types.text(), \n",
    "        \"target\": bolt.types.token_tags(tags=TAGS, default_tag=\"O\")\n",
    "    },\n",
    "    target=\"target\",\n",
    "    pretrained_model=pii_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the train function for the NER model and pass the training file to the function [required]. All other parameters are optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_model.train(\n",
    "    train_file,\n",
    "    epochs=2,\n",
    "    learning_rate=0.001,\n",
    "    batch_size=1024,\n",
    "    metrics=[\"loss\"],\n",
    "    validation=bolt.Validation(filename=validation_file, metrics=[\"loss\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Finetuned Model on Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = utils.load_dataset(\"conll2003\")[\"test\"]\n",
    "\n",
    "predictions = []\n",
    "actuals = []\n",
    "\n",
    "labels = [\"O\"] + TAGS\n",
    "\n",
    "for example in test_data:\n",
    "    tokens = {\"source\": \" \".join(example[\"tokens\"])}\n",
    "    actual_tags = [labels[tag] for tag in example[\"ner_tags\"]]\n",
    "\n",
    "    # Predict and evaluate\n",
    "    predicted_tags = ner_model.predict(tokens, top_k=1)\n",
    "\n",
    "    predictions.extend(predicted_tags)\n",
    "    actuals.extend(actual_tags)\n",
    "\n",
    "correct_predictions = sum(p[0][0] == a for p, a in zip(predictions, actuals))\n",
    "total_predictions = len(predictions)\n",
    "accuracy = correct_predictions / total_predictions\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
