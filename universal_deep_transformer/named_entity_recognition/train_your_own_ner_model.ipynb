{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scripts to train a NER Model\n",
    "\n",
    "This script use ThirdAI's NER library to train a model on an NER dataset from scratch. For this demonstration, we are using the `https://huggingface.co/datasets/conll2003` dataset. We also show how to load a saved ThirdAI NER model and further fine-tune it, provided the labels remain the same.\n",
    "\n",
    "If you want to just use ThirdAI's pretrained multi-lingual PII detection model, please refer to [the other notebook](https://github.com/ThirdAILabs/Demos/blob/main/named_entity_recognition/pretrained_pii_model.ipynb) in this folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install thirdai --upgrade\n",
    "!pip3 install datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thirdai import bolt, dataset, licensing\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activate ThirdAI's license key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if \"THIRDAI_KEY\" in os.environ:\n",
    "    licensing.activate(os.environ[\"THIRDAI_KEY\"])\n",
    "else:\n",
    "    licensing.activate(\"\")  # Enter your ThirdAI key here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Tag to label Map\n",
    "\n",
    "Tag to Label Map is used to map text entities to their corresponding integer labels while training/inferencing using a model.\n",
    "\n",
    "Note: Ensure that the tags in your dataset should not be outside of TAG_MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAGS = [\n",
    "    \"B-PER\",\n",
    "    \"I-PER\",\n",
    "    \"B-ORG\",\n",
    "    \"I-ORG\",\n",
    "    \"B-LOC\",\n",
    "    \"I-LOC\",\n",
    "    \"B-MISC\",\n",
    "    \"I-MISC\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download and Process the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = utils.download_conll_dataset_as_file(\"train\")\n",
    "validation_file = utils.download_conll_dataset_as_file(\"validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and validation files should have a source and target column where each token in the source column has a corresponding tag in the target column. \n",
    "Note : tags with spaces not supported, e.g, 'credit card' is not a valid tag but 'credit_card' is valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_file, \"r\") as f:\n",
    "    for line in f.readlines()[:3]:\n",
    "        print(line, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize a Bolt NER model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_model = bolt.UniversalDeepTransformer(\n",
    "    data_types={\n",
    "        \"source\": bolt.types.text(),\n",
    "        \"target\": bolt.types.token_tags(tags=TAGS, default_tag=\"O\"),\n",
    "    },\n",
    "    target=\"target\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the train function for the NER model and pass the training file to the function [required]. All other parameters are optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_model.train(\n",
    "    train_file,\n",
    "    epochs=2,\n",
    "    learning_rate=0.001,\n",
    "    batch_size=1024,\n",
    "    metrics=[\"loss\"],\n",
    "    validation=bolt.Validation(filename=validation_file, metrics=[\"loss\"]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_model.save(\"thirdai_ner_model\")\n",
    "ner_model = bolt.UniversalDeepTransformer.load(\"thirdai_ner_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = utils.load_dataset(\"conll2003\")[\"test\"]\n",
    "\n",
    "predictions = []\n",
    "actuals = []\n",
    "\n",
    "labels = [\"O\"] + TAGS\n",
    "\n",
    "for example in test_data:\n",
    "    tokens = {\"source\": \" \".join(example[\"tokens\"])}\n",
    "    actual_tags = [labels[tag] for tag in example[\"ner_tags\"]]\n",
    "\n",
    "    # Predict and evaluate\n",
    "    predicted_tags = ner_model.predict(tokens, top_k=1)\n",
    "\n",
    "    predictions.extend(predicted_tags)\n",
    "    actuals.extend(actual_tags)\n",
    "\n",
    "correct_predictions = sum(p[0][0] == a for p, a in zip(predictions, actuals))\n",
    "total_predictions = len(predictions)\n",
    "accuracy = correct_predictions / total_predictions\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetune the model further\n",
    "\n",
    "In case, you want to further finetune on a already trained model, using a subset of tags. Here, we are creating a small retraining data, further we save it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample sentences with corresponding NER tags\n",
    "sentences = [\n",
    "    (\"John Doe went to Paris\", [\"B-PER\", \"I-PER\", \"O\", \"O\", \"B-LOC\"]),\n",
    "    (\n",
    "        \"Alice and Bob are from New York City\",\n",
    "        [\"B-PER\", \"O\", \"B-PER\", \"O\", \"O\", \"B-LOC\", \"I-LOC\", \"I-LOC\"],\n",
    "    ),\n",
    "    (\"The Eiffel Tower is in France\", [\"O\", \"B-LOC\", \"I-LOC\", \"O\", \"O\", \"B-LOC\"]),\n",
    "    (\n",
    "        \"Microsoft Corporation was founded by Bill Gates\",\n",
    "        [\"B-ORG\", \"I-ORG\", \"O\", \"O\", \"O\", \"B-PER\", \"I-PER\"],\n",
    "    ),\n",
    "    (\n",
    "        \"She visited the Louvre Museum in Paris last summer\",\n",
    "        [\"O\", \"O\", \"O\", \"B-LOC\", \"I-LOC\", \"O\", \"B-LOC\", \"O\", \"O\"],\n",
    "    ),\n",
    "    (\n",
    "        \"Google and IBM are big tech companies\",\n",
    "        [\"B-ORG\", \"O\", \"B-ORG\", \"O\", \"O\", \"O\", \"O\"],\n",
    "    ),\n",
    "    (\n",
    "        \"Mount Everest is the highest mountain in the world\",\n",
    "        [\"B-LOC\", \"I-LOC\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"],\n",
    "    ),\n",
    "    (\"Leonardo DiCaprio won an Oscar\", [\"B-PER\", \"I-PER\", \"O\", \"O\", \"O\"]),\n",
    "]\n",
    "\n",
    "# File to write the data\n",
    "retrain_filename = \"retraining_ner_data.csv\"\n",
    "data = {\"source\": [], \"target\": []}\n",
    "for sentence, tags in sentences:\n",
    "    data[\"source\"].append(sentence)\n",
    "    data[\"target\"].append(\" \".join(tags))\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(retrain_filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can just call the train function again for retraining the NER model on subset of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_model.train(\n",
    "    retrain_filename,\n",
    "    epochs=3,\n",
    "    learning_rate=0.001,\n",
    "    batch_size=1024,\n",
    "    metrics=[\"loss\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.remove(\"thirdai_ner_model\")\n",
    "os.remove(retrain_filename)\n",
    "os.remove(\"train_ner_data.csv\")\n",
    "os.remove(\"validation_ner_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
