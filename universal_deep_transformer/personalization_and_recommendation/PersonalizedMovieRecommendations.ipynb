{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Personalized Movie Recommendations\n",
    "This notebook shows how to build a personalized movie recommendation model with ThirdAI's Universal Deep Transformer (UDT) model, our all-purpose classifier for tabular datasets. In this demo, we will train and evaluate the model on the Movielens 1M dataset, but you can easily replace this with your own dataset.\n",
    "\n",
    "You can immediately run a version of this notebook in your browser on Google Colab at the following link:\n",
    "\n",
    "https://githubtocolab.com/ThirdAILabs/Demos/blob/main/universal_deep_transformer/personlization_and_recommendation/PersonalizedMovieRecommendations.ipynb\n",
    "\n",
    "This notebook uses an activation key that will only work with this demo. If you want to try us out on your own dataset, you can obtain a free trial license at the following link: https://www.thirdai.com/try-bolt/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install thirdai --upgrade\n",
    "\n",
    "import thirdai\n",
    "thirdai.licensing.activate(\"Y9MT-TV7T-4JTP-L4XH-PWYC-4KEF-VX93-3HV7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Download\n",
    "We will use the demos module in the thirdai package to download the Movielens 1M dataset. You can replace this step and the next step with a download method and a UDT initialization step that is specific to your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thirdai.demos import download_movielens\n",
    "\n",
    "train_filename, test_filename, inference_batch, index_batch = download_movielens()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UDT Initialization\n",
    "We can now create a UDT model by passing in the types of each column in the dataset and the target column we want to be able to predict.\n",
    "\n",
    "For this demo, we additionally want to use \"temporal context\" to make predictions. Adding temporal context requires a single bolt.types.date() column to use to track the timestamp of training data. We pass in a dictionary called temporal_tracking_relationships that tells UDT we want to track movies over time for each user. This allows UDT to make better predictions for the target column by creating temporal features that take into account the historical relationship between users and movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thirdai import bolt\n",
    "\n",
    "model = bolt.UniversalDeepTransformer(\n",
    "    data_types={\n",
    "        \"userId\": bolt.types.categorical(),\n",
    "        \"movieTitle\": bolt.types.categorical(n_classes=3706),\n",
    "        \"timestamp\": bolt.types.date(),\n",
    "    },\n",
    "    temporal_tracking_relationships={\"userId\": [\"movieTitle\"]},\n",
    "    target=\"movieTitle\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "We can now train our UDT model with just one line! Feel free to customize the number of epochs and the learning rate; we have chosen values that give good convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(train_filename, epochs=3, learning_rate=0.001, metrics=[\"recall@10\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "Evaluating the performance of the UDT model is also just one line! We measure the model's ability to predict the movie that a user chooses to watch out of 3706 options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validate | epoch 3 | train_steps 1320 | val_recall@10=0.129263 val_recall@100=0.425501 val_recall@1=0.0220054  | val_batches 49 | time 17.180s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(test_filename, metrics=[\"recall@1\", \"recall@10\", \"recall@100\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and Loading\n",
    "Saving and loading a trained UDT model to disk is also extremely straight forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_location = \"personalized_movie_recommendation.model\"\n",
    "\n",
    "# Saving\n",
    "model.save(save_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading\n",
    "model = bolt.UniversalDeepTransformer.load(save_location)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Predictions\n",
    "The evaluation method is great for testing, but it requires labels, which don't exist in a production setting. We also have a predict method that can take in an in-memory batch of rows or a single row (without the target column), allowing easy integration into production pipelines.\n",
    "\n",
    "In the following cell, let's say we have a new user with an ID \"6040\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## resetting temporal trackers erases all users watch history. \n",
    "## The model weights are still intact, but all subsequent predictions are made as if it is the user's first visit.\n",
    "## We are resetting temporal trackers here to introduce a new user \"6040\" for the demo purposes. Use this API carefully in production use cases.\n",
    "\n",
    "model.reset_temporal_trackers()\n",
    "\n",
    "sample_input = {\n",
    "    \"userId\": \"6040\",\n",
    "    \"timestamp\": \"2000-04-25\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Star Wars: Episode VI - Return of the Jedi (1983)', 'Rain Man (1988)', 'Fatal Attraction (1987)', \"One Flew Over the Cuckoo's Nest (1975)\", 'Back to the Future (1985)']\n"
     ]
    }
   ],
   "source": [
    "predictions, _ = model.predict(sample_input, top_k=5)\n",
    "print([model.class_name(p) for p in predictions])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that for a new user \"6040\", the model recommends the most popular movies in the dataset, such as \"Star Wars: Episode VI - Return of the Jedi (1983)\" and \"Back to the Future (1985)\".\n",
    " \n",
    "Now, let's say user \"6040\" went ahead and watched \"Godfather The (1972)\" instead of the recommended one, we can always incrementally update the model by using the model.index() API as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_observation = {\n",
    "    'userId': '6040',\n",
    "    'movieTitle': 'Godfather The (1972)',\n",
    "    'timestamp': '2000-04-25'\n",
    "}\n",
    "\n",
    "model.index(new_observation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, let's make a recommendation again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Raiders of the Lost Ark (1981)', 'Godfather: Part II The (1974)', 'Godfather: Part III The (1990)', 'Casablanca (1942)', 'Star Wars: Episode IV - A New Hope (1977)']\n"
     ]
    }
   ],
   "source": [
    "sample_input = {\n",
    "    \"userId\":\"6040\",\n",
    "    \"timestamp\": \"2000-04-25\"\n",
    "}\n",
    "\n",
    "predictions, _ = model.predict(sample_input, top_k=5)\n",
    "print([model.class_name(p) for p in predictions])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voila! You can see that the model now predicts \"Godfather: Part II The (1974)\" and \"Godfather: Part III The (1990)\", which were not in the previous recommendations.\n",
    "\n",
    "Until we update UDT's temporal trackers with new observations of a user, we keep recommending the same movies to the same person. If we \"index\" new observations as we get them, then UDT will take advantage of this new information to make better predictions. When you run the following cell, notice how the prediction changes in response to new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before indexing new observation\n",
      "['Raiders of the Lost Ark (1981)', 'Godfather: Part II The (1974)', 'Godfather: Part III The (1990)', 'Casablanca (1942)', 'Star Wars: Episode IV - A New Hope (1977)']\n",
      "After indexing new observation\n",
      "['Godfather: Part III The (1990)', 'Star Wars: Episode IV - A New Hope (1977)', 'Raiders of the Lost Ark (1981)', \"One Flew Over the Cuckoo's Nest (1975)\", 'Star Wars: Episode V - The Empire Strikes Back (1980)']\n"
     ]
    }
   ],
   "source": [
    "# Returns the same prediction\n",
    "print(\"Before indexing new observation\")\n",
    "predictions, _ = model.predict(sample_input, top_k=5)\n",
    "print([model.class_name(p) for p in predictions])\n",
    "\n",
    "# Index a new observation\n",
    "new_observation = {\n",
    "    'userId': '6040',\n",
    "    'movieTitle': 'Godfather: Part II The (1974)',\n",
    "    'timestamp': '2000-04-25'\n",
    "}\n",
    "model.index(new_observation)\n",
    "\n",
    "# Returns a different prediction\n",
    "print(\"After indexing new observation\")\n",
    "predictions, _ = model.predict(sample_input, top_k=5)\n",
    "print([model.class_name(p) for p in predictions])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
