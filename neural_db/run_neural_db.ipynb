{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's import the relevant module and initialize a neural db class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thirdai import neural_db as ndb\n",
    "\n",
    "db = ndb.NeuralDB(user_id=\"my_user\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, the db is uninitialized. We can either initialize from scratch like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.from_scratch()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or load a checkpoint / base model as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.from_checkpoint(\"path/to/checkpoint\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A database is useless if it doesn't contain anything. So let's insert things into it!\n",
    "\n",
    "The insertion method takes in a list of `Document` objects. The `Document` interface is easily extendable. We plan to support some common formats out of the box, but for right now we'll show you how to extend the Document interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import shutil\n",
    "    \n",
    "\n",
    "class CSVDocument(ndb.Document):\n",
    "    def __init__(self, path, strong_columns, weak_columns, reference_columns):\n",
    "        self.path = Path(path)\n",
    "        self._hash = ndb.utils.hash_file(path)\n",
    "        self.df = pd.read_csv(path)\n",
    "        self.strong_columns = strong_columns\n",
    "        self.weak_columns = weak_columns\n",
    "        self.reference_columns = reference_columns\n",
    "    \n",
    "    def hash(self) -> str:\n",
    "        return self._hash\n",
    "    \n",
    "    def size(self) -> int:\n",
    "        return len(self.df)\n",
    "    \n",
    "    def name(self) -> str:\n",
    "        return self.path.name\n",
    "    \n",
    "    def strong_text(self, element_id: int) -> str:\n",
    "        row = self.df.iloc[element_id]\n",
    "        return \" \".join([row[col] for col in self.strong_columns])\n",
    "    \n",
    "    def weak_text(self, element_id: int) -> str:\n",
    "        row = self.df.iloc[element_id]\n",
    "        return \" \".join([row[col] for col in self.weak_columns])\n",
    "    \n",
    "    def reference(self, element_id: int) -> ndb.Reference:\n",
    "        row = self.df.iloc[element_id]\n",
    "        text = \" \".join([row[col] for col in self.reference_columns])\n",
    "        def show_fn(*args, **kwargs):\n",
    "            print(\"Showing\", text)\n",
    "        return ndb.Reference(element_id, text, str(self.path.absolute()), {}, show_fn)\n",
    "    \n",
    "    def context(self, element_id: int, radius) -> str:\n",
    "        row = self.df.iloc[element_id]\n",
    "        return \" \".join([row[col] for col in self.reference_columns])\n",
    "    \n",
    "    def save_meta(self, directory: Path):\n",
    "        # Let's copy the original CSV file to the provided directory\n",
    "        shutil.copy(self.path, directory)\n",
    "    \n",
    "    def load_meta(self, directory: Path):\n",
    "        # Since we've moved the CSV file to the provided directory, let's make\n",
    "        # sure that we point to this CSV file.\n",
    "        self.path = directory / self.path.name\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phew! *Now* we insert the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @Tharun please change the parameters here.\n",
    "csv_doc = CSVDocument(\n",
    "    path=\"test_cs.csv\", \n",
    "    weak_columns=[\"weak1\", \"wEaK2\"], \n",
    "    strong_columns=[\"strong1\", \"stronk2\"], \n",
    "    reference_columns=[\"ref1\", \"REF2\"])\n",
    "\n",
    "# Just like that!\n",
    "db.add_documents([csv_doc])\n",
    "\n",
    "# Note that this method does not throw since it catches all exceptions.\n",
    "# To handle errors or progress, you can pass in handles like this\n",
    "db.add_documents(\n",
    "    documents=[csv_doc], \n",
    "    on_progress=lambda fraction: print(f\"Progress at {fraction * 100}%\"),\n",
    "    on_error=lambda error_msg: print(f\"Error! {error_msg}\"),\n",
    "    on_irrecoverable_error=lambda error_msg: print(f\"Really bad error! {error_msg}\"),\n",
    "    on_success= lambda: print(\"SUCCESS!!!\"))\n",
    "\n",
    "# @Tharun I thought about changing this to be db.insert_into_db but I don't\n",
    "# a real database would have a method called \"insert_into_db\" since people know\n",
    "# it's a database. I strongly suggest that we keep it as is, or maybe rename it \n",
    "# to \"insert\", but I say let's avoid \"db\" in the method name. Plus, people\n",
    "# are going to call the neural db object with the variable \"db\" since that's\n",
    "# the example we give in this demo, so I think it will be clear enough that\n",
    "# it's a DB!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait, we added the same document multiple times... is that going to be an issue?\n",
    "\n",
    "Nope! Let's double-check by listing all of our sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.sources() # @Tharun on second thought we should probably call this documents() or list_documents() to be consistent."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = db.search(\n",
    "    query=\"STRONK\", # @Tharun feel free to change the query.\n",
    "    top_k=2,\n",
    "    on_error=lambda error_msg: print(f\"Error! {error_msg}\"))\n",
    "\n",
    "for result in search_results:\n",
    "    print(result.text())\n",
    "    print(result.source())\n",
    "    print(result.metadata())\n",
    "    result.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've covered the basics, let's go over some of NeuralDB's advanced features. The first one is text-to-result association. Suppose that out of the top k results above, you actually like the 3rd result best. You can tell the model exactly this by running the following snippet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @Tharun this is pending. DOn't run this cell.\n",
    "db.text_to_result(text=\"STRONK\", result_id=search_results[2].id())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even more interesting than the first one is text-to-text association. This allows you to teach the model that two keywords, phrases, or concepts are related."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @Tharun please change as needed\n",
    "# Maybe we can rename to associate_concepts or associate_texts or associate_phrases.\n",
    "# But I prefer associate\n",
    "# Or what about text_to_text?\n",
    "db.associate(source=\"stronk\", target=\"very stronk\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, saving is a one-liner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.save(\"path/to/checkpoint/\")\n",
    "# You can also see the progress\n",
    "db.save(\"path/to/checkpoint/\", on_progress=lambda fraction: print(f\"{fraction}% done with saving.\"))\n",
    "\n",
    "# Loading is just like we showed above, with an optional progress handler\n",
    "db.from_checkpoint(\"path/to/checkpoint\", on_progress=lambda fraction: print(f\"{fraction}% done with loading.\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you decide to start anew, we have just the right method for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.clear_documents()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
