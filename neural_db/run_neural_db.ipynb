{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ThirdAI's NeuralDB\n",
    "\n",
    "First let's import the relevant module and initialize a neural db class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thirdai import licensing\n",
    "licensing.activate(\"D0F869-B61466-6A28F0-14B8C6-0AC6C6-V3\")\n",
    "\n",
    "from thirdai import neural_db as ndb\n",
    "\n",
    "db = ndb.NeuralDB(user_id=\"my_user\") # you can use any username, in the future, this username will let you push models to the model hub"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize\n",
    "\n",
    "At this point, the db is uninitialized. \n",
    "\n",
    "##### Option 1: We can either initialize from scratch like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.from_scratch()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Option 2: Or even load from a base DB that we provide, as shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "checkpoint = \"qna_db_1\"\n",
    "\n",
    "if not os.path.exists(checkpoint):\n",
    "    os.system(\"wget -O qna_db_1.zip 'https://www.dropbox.com/scl/fi/s1zhxmwjpayj5jphzct0p/qna_1_db.zip?dl=0&rlkey=ftcgrzt1rpc2d6hx0iuk1lz1r'\")\n",
    "    os.system(\"unzip qna_db_1.zip -d qna_db_1\")\n",
    "\n",
    "db.from_checkpoint(\"qna_db_1\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep CSV data\n",
    "\n",
    "Let's insert things into it!\n",
    "\n",
    "Currently, we support adding as many CSV files as you wish. All other file formats have to be converted into CSV files where each row represents a paragraph/text-chunk of the document. \n",
    "\n",
    "The file is required to have a column named \"DOC_ID\" with rows numbered from 0 to n_rows-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import CSV\n",
    "\n",
    "csv_files = ['sample_nda.csv']\n",
    "csv_docs = []\n",
    "\n",
    "for file in csv_files:\n",
    "    csv_doc = CSV(\n",
    "        path=file,\n",
    "        id_column=\"DOC_ID\",\n",
    "        strong_columns=[\"passage\"],\n",
    "        weak_columns=[\"para\"],  \n",
    "        reference_columns=[\"passage\"])\n",
    "\n",
    "    csv_docs.append(csv_doc)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert CSV files into NeuralDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_ids = db.insert(csv_docs, train=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded data | source 'Documents:\n",
      "sample_nda.csv' | vectors 109 | batches 1 | time 0s | complete\n",
      "\n",
      "train | epoch 0 | train_steps 1 | train_hash_precision@5=0.00917431  | train_batches 1 | time 0s\n",
      "\n",
      "loaded data | source 'Documents:\n",
      "sample_nda.csv' | vectors 109 | batches 1 | time 0s | complete\n",
      "\n",
      "train | epoch 0 | train_steps 2 | train_hash_precision@5=0.506422  | train_batches 1 | time 0s\n",
      "\n",
      "loaded data | source 'Documents:\n",
      "sample_nda.csv' | vectors 109 | batches 1 | time 0s | complete\n",
      "\n",
      "train | epoch 0 | train_steps 3 | train_hash_precision@5=0.422018  | train_batches 1 | time 0s\n",
      "\n",
      "loaded data | source 'Documents:\n",
      "sample_nda.csv' | vectors 109 | batches 1 | time 0s | complete\n",
      "\n",
      "train | epoch 0 | train_steps 4 | train_hash_precision@5=0.388991  | train_batches 1 | time 0s\n",
      "\n",
      "loaded data | source 'Documents:\n",
      "sample_nda.csv' | vectors 109 | batches 1 | time 0s | complete\n",
      "\n",
      "train | epoch 0 | train_steps 5 | train_hash_precision@5=0.847706  | train_batches 1 | time 0s\n",
      "\n",
      "loaded data | source 'Documents:\n",
      "sample_nda.csv' | vectors 109 | batches 1 | time 0s | complete\n",
      "\n",
      "train | epoch 0 | train_steps 6 | train_hash_precision@5=0.948624  | train_batches 1 | time 0s\n",
      "\n",
      "loaded data | source 'Documents:\n",
      "sample_nda.csv' | vectors 109 | batches 1 | time 0s | complete\n",
      "\n",
      "train | epoch 0 | train_steps 7 | train_hash_precision@5=0.976147  | train_batches 1 | time 0s\n",
      "\n",
      "loaded data | source 'Documents:\n",
      "sample_nda.csv' | vectors 109 | batches 1 | time 0s | complete\n",
      "\n",
      "train | epoch 0 | train_steps 8 | train_hash_precision@5=0.977982  | train_batches 1 | time 0s\n",
      "\n",
      "loaded data | source 'Documents:\n",
      "sample_nda.csv' | vectors 109 | batches 1 | time 0s | complete\n",
      "\n",
      "train | epoch 0 | train_steps 9 | train_hash_precision@5=0.976147  | train_batches 1 | time 0s\n",
      "\n",
      "loaded data | source 'Documents:\n",
      "sample_nda.csv' | vectors 109 | batches 1 | time 0s | complete\n",
      "\n",
      "train | epoch 0 | train_steps 10 | train_hash_precision@5=0.972477  | train_batches 1 | time 0s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "source_ids = db.insert(csv_docs, train=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just train on the docs\n",
    "\n",
    "Do not worry abt files being inserted multiple times, the DB takes care of de-duplication!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_ids = db.insert(csv_docs, train=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search\n",
    "\n",
    "Now let's start searching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12. entire agreement. this agreement constitutes the entire agreement with respect to the subject matter hereof and supersedes all prior agreements and understandings between the parties (whether written or oral) relating to the subject matter and may not be amended or modified except in a writing signed by an authorized representative of both parties. the terms of this agreement relating to the confidentiality and non-use of confidential information shall continue after the termination of this agreement for a period of the longer of (i) five (5) years or (ii) when the confidential information no longer qualifies as a trade secret under applicable law.\n",
      "************\n",
      "4. return of confidential information. upon request of the other party termination of the discussions regarding a business relationship between the parties or termination of the current business relationship each party shall promptly destroy or deliver to the other party any and all documents notes and other physical embodiments of or reflecting the confidential information (including any copies thereof) that are in their possession or control. upon request of a party a responsible officer of the other party shall provide written certification of the completeness of the delivery or destruction of such materials.\n",
      "************\n"
     ]
    }
   ],
   "source": [
    "search_results = db.search(\n",
    "    query=\"what is the termination period\",\n",
    "    top_k=2,\n",
    "    on_error=lambda error_msg: print(f\"Error! {error_msg}\"))\n",
    "\n",
    "for result in search_results:\n",
    "    print(result.text())\n",
    "    # print(result.context(radius=3))\n",
    "    # print(result.source())\n",
    "    # print(result.metadata())\n",
    "    # result.show()\n",
    "    print('************')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the search pulled up the right passage that contains the termination period \"(i) five (5) years or (ii) when the confidential information no longer qualifies as a trade secret\" ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confidentiality agreement this confidentiality agreement (the “agreement”) is made by and between acme. dba tothemoon inc. with offices at 2025 guadalupe st. suite 260 austin tx 78705 and starwars dba tothemars with offices at the forest moon of endor and entered as of may 3 2023 (“effective date”).\n",
      "************\n",
      "in consideration of the business discussions disclosure of confidential information and any future business relationship between the parties it is hereby agreed as follows: 1. confidential information. for purposes of this agreement the term “confidential information” shall mean any information business plan concept idea know-how process technique program design formula algorithm or work-in-process request for proposal (rfp) or request for information (rfi) and any responses thereto engineering manufacturing marketing technical financial data or sales information or information regarding suppliers customers employees investors or business operations and other information or materials whether disclosed in written graphic oral or electronic form whether tangible or intangible and in whatever form or medium provided or which is learned or disclosed in the course of discussions studies or other work undertaken between the parties prior to or after the effective date.\n",
      "************\n"
     ]
    }
   ],
   "source": [
    "search_results = db.search(\n",
    "    query=\"made by and between\",\n",
    "    top_k=2,\n",
    "    on_error=lambda error_msg: print(f\"Error! {error_msg}\"))\n",
    "\n",
    "for result in search_results:\n",
    "    print(result.text())\n",
    "    # print(result.context(radius=3))\n",
    "    # print(result.source())\n",
    "    # print(result.metadata())\n",
    "    # result.show()\n",
    "    print('************')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the search pulled up the right passage again that has \"made by and between\".\n",
    "\n",
    "Now let's ask a tricky question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. joint undertaking. each party agrees that it will not at any time disclose give or transmit in any manner or for any purpose the confidential information received from the other party to any person firm or corporation or use such confidential information for its own benefit or the benefit of anyone else or for any purpose other than to engage in discussions regarding a possible business relationship or the current business relationship involving both parties.\n",
      "************\n",
      "6. excluded information. the parties agree that confidential information of the other party shall not include any information to the extent that the information: (i) is or at any time becomes a part of the public domain through no act or omission of the receiving party; (ii) is independently discovered or developed by the receiving party without use of the disclosing party’s confidential information; (iii) is rightfully obtained from a third party without any obligation of confidentiality; or (iv) is already known by the receiving party without any obligation of confidentiality prior to obtaining the confidential information from the disclosing party.\n",
      "************\n"
     ]
    }
   ],
   "source": [
    "search_results = db.search(\n",
    "    query=\"who are the parties involved?\",\n",
    "    top_k=2,\n",
    "    on_error=lambda error_msg: print(f\"Error! {error_msg}\"))\n",
    "\n",
    "for result in search_results:\n",
    "    print(result.text())\n",
    "    # print(result.context(radius=3))\n",
    "    # print(result.source())\n",
    "    # print(result.metadata())\n",
    "    # result.show()\n",
    "    print('************')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oops! looks like when we search for \"parties involved\", we do not get the correct paragraph in the 1st position (we should be expecting the first paragraph as the correct results instead fo the last). \n",
    "\n",
    "No worries, we'll show shot to teach the model to correct it's retrieval.\n",
    "\n",
    "### RLHF\n",
    "\n",
    "Let's go over some of NeuralDB's advanced features. The first one is text-to-text association. This allows you to teach the model that two keywords, phrases, or concepts are related.\n",
    "\n",
    "Based on the above example, let's teach the model that \"parties involved\" and the phrase \"made by between\" are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.associate(source=\"parties involved\", target=\"made by and between\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's search again with the same query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confidentiality agreement this confidentiality agreement (the “agreement”) is made by and between acme. dba tothemoon inc. with offices at 2025 guadalupe st. suite 260 austin tx 78705 and starwars dba tothemars with offices at the forest moon of endor and entered as of may 3 2023 (“effective date”).\n",
      "************\n",
      "6. excluded information. the parties agree that confidential information of the other party shall not include any information to the extent that the information: (i) is or at any time becomes a part of the public domain through no act or omission of the receiving party; (ii) is independently discovered or developed by the receiving party without use of the disclosing party’s confidential information; (iii) is rightfully obtained from a third party without any obligation of confidentiality; or (iv) is already known by the receiving party without any obligation of confidentiality prior to obtaining the confidential information from the disclosing party.\n",
      "************\n"
     ]
    }
   ],
   "source": [
    "search_results = db.search(\n",
    "    query=\"who are the parties involved?\",\n",
    "    top_k=2,\n",
    ")\n",
    "\n",
    "for result in search_results:\n",
    "    print(result.text())\n",
    "    # print(result.source())\n",
    "    # print(result.metadata())\n",
    "    # result.show()\n",
    "    print('************')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There you go! In just a line, you taught the model to correct itself and retrieve the correct result.\n",
    "\n",
    "Now, let's see the 2nd option which is text-to-result association. Let's say that you know that \"parties involved\" should go the paragraph with DOC_ID=0, you can simply teach the model to associate the query to the corresponding label using the following API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.text_to_result(\"made by and between\",0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to use the above RLHF methods in a batch instead of a single sample, you can simply use the batched versions of the APIs as shown next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.associate_batch([(\"parties involved\",\"made by and between\"),(\"date of signing\",\"duly executed\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.text_to_result_batch([(\"parties involved\",0),(\"date of signing\",16)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised Training (Optional)\n",
    "\n",
    "If you have supervised data for a specific CSV file in your list, you can simply train the DB on that file by specifying a source_id = source_ids[*file_number_in_your_list*].\n",
    "\n",
    "Note: The supervised file should have the query_column and id_column that you specify in the following call. The id_column should match the id_column that you specified in the \"Prep CSV Data\" step or default to \"DOC_ID\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_files = ['sample_nda_sup.csv']\n",
    "\n",
    "db.supervised_train([ndb.Sup(path, query_column=\"QUERY\", id_column=\"DOC_ID\", source_id=source_ids[0]) for path in sup_files])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Answers from OpenAI using Langchain\n",
    "\n",
    "In this section, we will show how to use LangChain and query OpenAI's QnA module to generate an answer from the references that you retrieve from the above DB. You'll have to specify your own OpenAI key for this module to work. You can replace this segment with any other generative model of your choice. You can choose to use an source model like MPT or Dolly for answer generation with the same prompt that you use with OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from paperqa.qaprompts import qa_prompt, make_chain\n",
    "\n",
    "your_openai_key = \"\"\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model_name='gpt-3.5-turbo', \n",
    "    temperature=0.1, \n",
    "    openai_api_key=your_openai_key,\n",
    ")\n",
    "\n",
    "qa_chain = make_chain(prompt=qa_prompt, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_references(query):\n",
    "    search_results = db.search(query,top_k=3)\n",
    "    references = []\n",
    "    for result in search_results:\n",
    "        references.append(result.text())\n",
    "    return references\n",
    "\n",
    "def get_answer(query, references):\n",
    "    return qa_chain.run(question=query, context_str='\\n\\n'.join(references[:3]), length=\"abt 50 words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['confidentiality agreement this confidentiality agreement (the “agreement”) is made by and between acme. dba tothemoon inc. with offices at 2025 guadalupe st. suite 260 austin tx 78705 and starwars dba tothemars with offices at the forest moon of endor and entered as of may 3 2023 (“effective date”).', 'each party shall take all reasonable measures to preserve the confidentiality and avoid the disclosure of the other party’s confidential information including but not limited to those steps taken with respect to the party’s own confidential information of like importance. neither party shall disassemble decompile or otherwise reverse engineer any software product of the other party and to the extent any such activity may be permitted the results thereof shall be deemed confidential information subject to the requirements of this agreement.', 'in consideration of the business discussions disclosure of confidential information and any future business relationship between the parties it is hereby agreed as follows: 1. confidential information. for purposes of this agreement the term “confidential information” shall mean any information business plan concept idea know-how process technique program design formula algorithm or work-in-process request for proposal (rfp) or request for information (rfi) and any responses thereto engineering manufacturing marketing technical financial data or sales information or information regarding suppliers customers employees investors or business operations and other information or materials whether disclosed in written graphic oral or electronic form whether tangible or intangible and in whatever form or medium provided or which is learned or disclosed in the course of discussions studies or other work undertaken between the parties prior to or after the effective date.']\n"
     ]
    }
   ],
   "source": [
    "query = \"what is the effective date of this agreement?\"\n",
    "\n",
    "references = get_references(query)\n",
    "print(references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The effective date of this confidentiality agreement is May 3, 2023 (line 3).\n"
     ]
    }
   ],
   "source": [
    "answer = get_answer(query, references)\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Save\n",
    "As usual, saving and loading the DB are one-liners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save your db\n",
    "db.save(\"sample_nda.db\")\n",
    "\n",
    "# Loading is just like we showed above, with an optional progress handler\n",
    "db.from_checkpoint(\"sample_nda.db\", on_progress=lambda fraction: print(f\"{fraction}% done with loading.\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export to Playground\n",
    "\n",
    "Note: Currently, we support exporting to Playground UI with only 1 CSV file, if you have multiple CSV files, please watch out for our next release that will add support to export a NeuralDB directly into Playground."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from export_utils import neural_db_to_playground\n",
    "\n",
    "neural_db_to_playground(db, './sample_nda/', csv=csv_doc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
