{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ThirdAI's NeuralDB\n",
    "\n",
    "First let's import the relevant module and initialize a neural db class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thirdai import licensing\n",
    "licensing.activate(\"\")\n",
    "\n",
    "from thirdai import neural_db as ndb\n",
    "\n",
    "db = ndb.NeuralDB(user_id=\"my_user\") # you can use any username, in the future, this username will let you push models to the model hub"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize\n",
    "At this point, the db is uninitialized. We can either initialize from scratch like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.from_scratch()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or even build one with a base DB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from thirdai import bolt\n",
    "\n",
    "checkpoint = \"qna_1.bolt\" # choose from ['qna_1','qna_2','contracts']\n",
    "\n",
    "if not os.path.exists(checkpoint):\n",
    "    if checkpoint==\"qna_1.bolt\":\n",
    "        os.system(\"wget -O qna_1.bolt 'https://www.dropbox.com/scl/fi/8i3qd9edhrm6zjviq7vvy/qna_1_0.7.7_frozen.bolt?dl=0&rlkey=raonu7dh3cy6mooucjrns49vf' \")\n",
    "    elif checkpoint==\"qna_2.bolt\":\n",
    "        os.system(\"wget -O qna_2.bolt 'https://www.dropbox.com/scl/fi/27psws3dcujgbma5xwsh1/qna_2_0.7.7_frozen.bolt?dl=0&rlkey=z1ivtoquspqole3i6mdmgwb9v' \")\n",
    "    elif checkpoint==\"contracts.bolt\":\n",
    "        os.system(\"wget -O contracts.bolt 'https://www.dropbox.com/scl/fi/dk9bw59bix245d9x49nhy/contracts_0.7.7_frozen.bolt?dl=0&rlkey=xs9uzyv65sug30oi201sy7u6v' \")\n",
    "    else:\n",
    "        print(\"please choose the checkpoint from the aforementioned list in the comment only\")\n",
    "\n",
    "db.from_udt(\n",
    "    udt=bolt.UniversalDeepTransformer.load(checkpoint),\n",
    "    id_col=\"DOC_ID\", id_delimiter=\":\", query_col=\"QUERY\", \n",
    "    input_dim=50_000, hidden_dim=2048, extreme_output_dim=50_000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep CSV data\n",
    "\n",
    "Let's insert things into it!\n",
    "\n",
    "Currently, we support adding as many CSV files as you wish. All other file formats have to be converted into CSV files where each row represents a paragraph/text-chunk of the document. \n",
    "\n",
    "The file is required to have a column named \"DOC_ID\" with rows numbered from 0 to n_rows-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import CSV\n",
    "\n",
    "csv_files = ['sample_nda.csv']\n",
    "csv_docs = []\n",
    "\n",
    "for file in csv_files:\n",
    "    csv_doc = CSV(\n",
    "        path=file,\n",
    "        id_column=\"DOC_ID\",\n",
    "        strong_columns=[\"passage\"],\n",
    "        weak_columns=[\"para\"],  \n",
    "        reference_columns=[\"passage\"])\n",
    "\n",
    "    csv_docs.append(csv_doc)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert CSV files into NeuralDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_ids = db.insert(csv_docs, train=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_ids = db.insert(csv_docs, train=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just train on the docs\n",
    "\n",
    "Do not worry abt files being inserted multiple times, the DB takes care of de-duplication!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_ids = db.insert(csv_docs, train=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search\n",
    "\n",
    "Now let's start searching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12. entire agreement. this agreement constitutes the entire agreement with respect to the subject matter hereof and supersedes all prior agreements and understandings between the parties (whether written or oral) relating to the subject matter and may not be amended or modified except in a writing signed by an authorized representative of both parties. the terms of this agreement relating to the confidentiality and non-use of confidential information shall continue after the termination of this agreement for a period of the longer of (i) five (5) years or (ii) when the confidential information no longer qualifies as a trade secret under applicable law.\n",
      "************\n",
      "4. return of confidential information. upon request of the other party termination of the discussions regarding a business relationship between the parties or termination of the current business relationship each party shall promptly destroy or deliver to the other party any and all documents notes and other physical embodiments of or reflecting the confidential information (including any copies thereof) that are in their possession or control. upon request of a party a responsible officer of the other party shall provide written certification of the completeness of the delivery or destruction of such materials.\n",
      "************\n"
     ]
    }
   ],
   "source": [
    "search_results = db.search(\n",
    "    query=\"what is the termination period\",\n",
    "    top_k=2,\n",
    "    on_error=lambda error_msg: print(f\"Error! {error_msg}\"))\n",
    "\n",
    "for result in search_results:\n",
    "    print(result.text())\n",
    "    # print(result.context(radius=3))\n",
    "    # print(result.source())\n",
    "    # print(result.metadata())\n",
    "    # result.show()\n",
    "    print('************')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the search pulled up the right passage that contains the termination period \"(i) five (5) years or (ii) when the confidential information no longer qualifies as a trade secret\" ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confidentiality agreement this confidentiality agreement (the “agreement”) is made by and between acme. dba tothemoon inc. with offices at 2025 guadalupe st. suite 260 austin tx 78705 and starwars dba tothemars with offices at the forest moon of endor and entered as of may 3 2023 (“effective date”).\n",
      "************\n",
      "in witness whereof this agreement has been duly executed by the parties hereto as of the latest date set forth below: acme inc. starwars inc. by: by: name: bugs bunny name: luke skywalker title: ceo title: ceo date: may 5 2023 date: may 7 2023\n",
      "************\n"
     ]
    }
   ],
   "source": [
    "search_results = db.search(\n",
    "    query=\"made by and between\",\n",
    "    top_k=2,\n",
    "    on_error=lambda error_msg: print(f\"Error! {error_msg}\"))\n",
    "\n",
    "for result in search_results:\n",
    "    print(result.text())\n",
    "    # print(result.context(radius=3))\n",
    "    # print(result.source())\n",
    "    # print(result.metadata())\n",
    "    # result.show()\n",
    "    print('************')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the search pulled up the right passage again that has \"made by and between\".\n",
    "\n",
    "Now let's ask a tricky question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in witness whereof this agreement has been duly executed by the parties hereto as of the latest date set forth below: acme inc. starwars inc. by: by: name: bugs bunny name: luke skywalker title: ceo title: ceo date: may 5 2023 date: may 7 2023\n",
      "************\n",
      "3. joint undertaking. each party agrees that it will not at any time disclose give or transmit in any manner or for any purpose the confidential information received from the other party to any person firm or corporation or use such confidential information for its own benefit or the benefit of anyone else or for any purpose other than to engage in discussions regarding a possible business relationship or the current business relationship involving both parties.\n",
      "************\n"
     ]
    }
   ],
   "source": [
    "search_results = db.search(\n",
    "    query=\"who are the parties involved?\",\n",
    "    top_k=2,\n",
    "    on_error=lambda error_msg: print(f\"Error! {error_msg}\"))\n",
    "\n",
    "for result in search_results:\n",
    "    print(result.text())\n",
    "    # print(result.context(radius=3))\n",
    "    # print(result.source())\n",
    "    # print(result.metadata())\n",
    "    # result.show()\n",
    "    print('************')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oops! looks like when we search for \"parties involved\", we do not get the correct paragraph in the 1st position (we should be expecting the first paragraph as the correct results instead fo the last). \n",
    "\n",
    "No worries, we'll show shot to teach the model to correct it's retrieval.\n",
    "\n",
    "### RLHF\n",
    "\n",
    "Let's go over some of NeuralDB's advanced features. The first one is text-to-text association. This allows you to teach the model that two keywords, phrases, or concepts are related.\n",
    "\n",
    "Based on the above example, let's teach the model that \"parties involved\" and the phrase \"made by between\" are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.associate(source=\"parties involved\", target=\"made by and between\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's search again with the same query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confidentiality agreement this confidentiality agreement (the “agreement”) is made by and between acme. dba tothemoon inc. with offices at 2025 guadalupe st. suite 260 austin tx 78705 and starwars dba tothemars with offices at the forest moon of endor and entered as of may 3 2023 (“effective date”).\n",
      "************\n",
      "in witness whereof this agreement has been duly executed by the parties hereto as of the latest date set forth below: acme inc. starwars inc. by: by: name: bugs bunny name: luke skywalker title: ceo title: ceo date: may 5 2023 date: may 7 2023\n",
      "************\n"
     ]
    }
   ],
   "source": [
    "search_results = db.search(\n",
    "    query=\"who are the parties involved?\",\n",
    "    top_k=2,\n",
    ")\n",
    "\n",
    "for result in search_results:\n",
    "    print(result.text())\n",
    "    # print(result.source())\n",
    "    # print(result.metadata())\n",
    "    # result.show()\n",
    "    print('************')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There you go! In just a line, you taught the model to correct itself and retrieve the correct result.\n",
    "\n",
    "Now, let's see the 2nd option which is text-to-result association. Let's say that you know that \"parties involved\" should go the paragraph with DOC_ID=0, you can simply teach the model to associate the query to the corresponding label using the following API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.text_to_result(\"made by and between\",0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to use the above RLHF methods in a batch instead of a single sample, you can simply use the batched versions of the APIs as shown next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.associate_batch([(\"parties involved\",\"made by and between\"),(\"date of signing\",\"duly executed\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.text_to_result_batch([(\"parties involved\",0),(\"date of signing\",16)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised Training (Optional)\n",
    "\n",
    "If you have supervised data for a specific CSV file in your list, you can simply train the DB on that file by specifying a source_id = source_ids[*file_number_in_your_list*].\n",
    "\n",
    "Note: The supervised file should have the query_column and id_column that you specify in the following call. The id_column should match the id_column that you specified in the \"Prep CSV Data\" step or default to \"DOC_ID\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_files = ['sample_nda_sup.csv']\n",
    "\n",
    "db.supervised_train([ndb.Sup(path, query_column=\"QUERY\", id_column=\"DOC_ID\", source_id=source_ids[0]) for path in sup_files])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Save\n",
    "As usual, saving and loading are one-liners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save your db\n",
    "db.save(\"sample_nda.db\")\n",
    "\n",
    "# Loading is just like we showed above, with an optional progress handler\n",
    "db.from_checkpoint(\"sample_nda.db\", on_progress=lambda fraction: print(f\"{fraction}% done with loading.\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export to Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import bolt_and_csv_to_checkpoint\n",
    "\n",
    "bolt_and_csv_to_checkpoint(db._savable_state.model.get_model(), csv_files[0], './sample_nda/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
