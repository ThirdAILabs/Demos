{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural DB distributed training\n",
    "\n",
    "In this notebook, you will be able to train ThirdAI's Neural DB on 10k Amazon datapoints in a distributed fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install thirdai --upgrade\n",
    "!pip3 install \"thirdai[neural_db]\"  # You may have to unquote this\n",
    "!pip3 install pyarrow\n",
    "!pip3 install \"ray[all]>=2.7.0\"  # You may have to unquote this\n",
    "!pip3 install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thirdai import neural_db as ndb\n",
    "import thirdai.distributed_bolt as dist"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activate your license keys\n",
    "email us at contact@thirdai.com for your license key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thirdai import licensing\n",
    "import os\n",
    "\n",
    "## Please request for a trial license @ https://www.thirdai.com/try-bolt/\n",
    "if \"THIRDAI_KEY\" in os.environ:\n",
    "    licensing.activate(os.environ[\"THIRDAI_KEY\"])\n",
    "else:\n",
    "    licensing.activate(\"\")  # Enter your ThirdAI key here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the training data file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "filename = \"amazon_10k.csv\"\n",
    "os.system(f\"wget -O {filename} 'https://www.dropbox.com/scl/fi/97utx7ukp0rb37f8d98ia/amazon_10k.csv?rlkey=aq8yq42o54tcj62u9q3op0m80&dl=0'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = ndb.NeuralDB(\"my_user\") # you can use any username, in the future, this username will let you push models to the model bazaar\n",
    "\n",
    "doc = ndb.CSV(\n",
    "    filename,\n",
    "    id_column=\"id\",\n",
    "    strong_columns=[\"TITLE\", \"BULLET_POINTS\"],\n",
    "    weak_columns=[\"DESCRIPTION\"],\n",
    "    reference_columns=[\"TITLE\"],\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert the document to be indexed\n",
    "train should be set False for distributed pretraining. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.insert(sources=[doc], train=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ray Cluster Initialization\n",
    "For the purpose of this demo, we will be initializing a mock ray cluster of 2 nodes here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray.train import ScalingConfig, RunConfig\n",
    "\n",
    "cpus_per_node = (dist.get_num_cpus() - 1) // 2\n",
    "\n",
    "ray.init(ignore_reinit_error=True, runtime_env={\"env_vars\": {\"OMP_NUM_THREADS\": f\"{cpus_per_node}\"}})\n",
    "scaling_config = ScalingConfig(\n",
    "    num_workers=2,\n",
    "    use_gpu=False,\n",
    "    trainer_resources={\"CPU\": 1},\n",
    "    resources_per_worker={\"CPU\": cpus_per_node},\n",
    "    placement_strategy=\"PACK\",\n",
    ")\n",
    "\n",
    "# We need to specify `storage_path` in `RunConfig` which must be a networked file system \n",
    "# or cloud storage path accessible by all workers. (Ray 2.7.0 onwards)\n",
    "run_config = RunConfig(\n",
    "    name=\"NeuralDB_ray_storage\",\n",
    "    storage_path=\"~/ray_results\", # For the purpose of this demo, this `storage_path` will work fine since both workers are run on same machine.\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runs distributed training on the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.pretrain_distributed(documents=[doc], scaling_config=scaling_config, run_config=run_config, epochs=15, metrics=[\"loss\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's ask!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = db.search(query=\"Macbook pro 13 inches laptop cover\", top_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in search_results:\n",
    "    print(result.text)\n",
    "    print('**************')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Terminate the ray cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
