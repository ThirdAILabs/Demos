{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "\n",
    "import textwrap\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = chromadb.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = client.create_collection(name=\"demo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-11 10:01:18 URL:https://ucd55e10d6121fa273f6098da9a2.dl.dropboxusercontent.com/cd/0/inline/CO7-1xMQb8A09-lu2YuWwssOx8IigZIT68-sswhKdrhnQPYQgOOKpy81tV-wfF3hF30W-RZejLJpQO7P80FS5YM5SvIrGxt7h8OptTCjpWnfGyEZwYRNkemUjqesmH_flRaw1gmaytdi8d2HaNtjzz6v/file [26625547/26625547] -> \"./stackoverflow_data/train.csv\" [1]\n",
      "2024-03-11 10:01:19 URL:https://uc53e2d8f0465990ef478106ecf7.dl.dropboxusercontent.com/cd/0/inline/CO4fDAaq7oqxmvStXX0dmzAnoApzpkgfnZ3gXEXF41AHFB3fn-E99enpgvp7afte3rhaInlgP6WIPN8D_MCUxPJ3GXdh6Q6Qu5j-PZeSWZ-4pdi8IqHXVKfE5Mo4wu4OAsBMH13kuM1TZ3y-YM49iIh4/file [136081/136081] -> \"./stackoverflow_data/test.csv\" [1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = \"./stackoverflow_data/\"\n",
    "if not os.path.isdir(data_dir):\n",
    "    os.system(\"mkdir \"+data_dir)\n",
    "\n",
    "os.system(\"wget -nv -O \"+data_dir+\"train.csv 'https://www.dropbox.com/scl/fi/e7ltns3teqmngai3fp71o/stackoverflow_train.csv?rlkey=f9pq0amo5swfrdi1hcvk52cuc&dl=0'\")\n",
    "os.system(\"wget -nv -O \"+data_dir+\"test.csv 'https://www.dropbox.com/scl/fi/9rqf0nf2cmti0ihn5x4uu/stackoverflow_test.csv?rlkey=cn3ttfenhgxrsaemidnat0kt2&dl=0'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = data_dir+\"train.csv\"\n",
    "test_file = data_dir+\"test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_csv(train_file)\n",
    "test_df = pd.read_csv(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_answers = train_df['answer'].to_list()\n",
    "answer_ids = train_df['id'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "total_docs = len(train_answers)\n",
    "max_batch_size = 512  \n",
    "for start_idx in tqdm(range(0, total_docs, max_batch_size)):\n",
    "    end_idx = min(start_idx + max_batch_size, total_docs)\n",
    "    batch_documents = train_answers[start_idx:end_idx]\n",
    "    batch_ids = answer_ids[start_idx:end_idx]\n",
    "    collection.add(documents=batch_documents, ids=list(map(str, batch_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event CollectionQueryEvent: module 'chromadb' has no attribute 'get_settings'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevance Precision@1 = 0.45226130653266333\n",
      "Helpfulness Precision@1 = 0.37185929648241206\n"
     ]
    }
   ],
   "source": [
    "def precision_at_k(predicted, original, k):\n",
    "    total_precision = 0\n",
    "    for pred_instance, orig_instance in zip(predicted, original):\n",
    "        total_precision += len(set(pred_instance[:k]) & set(orig_instance)) / k\n",
    "    return total_precision / len(predicted) \n",
    "questions = test_df['query'].to_list()\n",
    "true_labels_all = list(map(lambda x: list(map(int, x.split(\",\"))), test_df['ids'].to_list()))\n",
    "predicted_all, original_all, original_top  = [], [], []\n",
    "results = collection.query(query_texts=questions,n_results=5)['ids']\n",
    "for result, true_labels in list(zip(results, true_labels_all)):\n",
    "    predicted_all.append(list(map(int, result)))\n",
    "    original_all.append(true_labels)\n",
    "    original_top.append(true_labels[:1])\n",
    "print(\"Relevance Precision@1 =\", precision_at_k(predicted_all, original_all, 1)) \n",
    "print(\"Helpfulness Precision@1 =\", precision_at_k(predicted_all, original_top, 1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapper = textwrap.TextWrapper(width=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Since you are searching for whole words, how about searching for \\w+ , and checking if the word is\n",
      "in a collection. A hash-based set or a hash-map would work well here. This approach would make it\n",
      "easier to update the list if the need should arise.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"I possess an algorithm that produces strings from a list of input words. \n",
    "How do I isolate only the strings that sound like English words? ie. reject \n",
    "RDLO while retaining LORD. EDIT: To clarify, they don't have to be real words \n",
    "in the dictionary. They just need to resemble English. For instance, KEAL would be \n",
    "acceptable.\"\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "results = collection.query(query_texts=[query],n_results=1)\n",
    "for answer in results['documents'][0]:\n",
    "    wrapped_text = wrapper.wrap(text = answer)\n",
    "    for element in wrapped_text:\n",
    "        print(element)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tests that check for more than one thing aren't usually recommended because they are more tightly\n",
      "coupled and brittle. If you change something in the code, it'll take longer to change the test,\n",
      "since there are more things to account for. [Edit:] Ok, say this is a sample test method:\n",
      "[TestMethod] public void TestSomething() { // Test condition A // Test condition B // Test condition\n",
      "C // Test condition D } If your test for condition A fails, then B, C, and D will appear to fail as\n",
      "well, and won't provide you with any usefulness. What if your code change would have caused C to\n",
      "fail as well? If you had split them out into 4 separate tests, you would know this.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"What is the optimal way to unit test a method that\n",
    "invokes multiple methods, for instance: modify(string value) \n",
    "{ if(value.Length &gt; 5) replaceit(value); else \n",
    "changeit(value); } This pseudo code has a modify method \n",
    "that (currently) calls either replaceit() or changeit() . \n",
    "I have already written tests for replaceit and changeit , \n",
    "so creating a new test for modify will be 99% the same set \n",
    "of code. I need to test it though because it might change \n",
    "in the future. So do I duplicate the existing test code? \n",
    "Shift the test code to a common function? Any other \n",
    "suggestions? I'm uncertain of the best practice here.\n",
    "\"\"\"\n",
    "\n",
    "results = collection.query(query_texts=[query],n_results=1)\n",
    "for answer in results['documents'][0]:\n",
    "    wrapped_text = wrapper.wrap(text = answer)\n",
    "    for element in wrapped_text:\n",
    "        print(element)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Have a look at Qt . It is an open source library for making GUI's. Unlike Swing in Java, it assumes\n",
      "a lot of stuff, so it is really easy to make functional GUI's. For example, a textarea assumes that\n",
      "you want a context menu when you right click it with copy, paste, select all, etc. The documentation\n",
      "is also very good.\n",
      "\n",
      " Visual Editor for quick GUI development.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"I am seeking to develop a very lightweight GUI front end in Windows.\n",
    "It's meant to perform a simple task - when a hot key combination is pressed it\n",
    "opens up a text box. Any text can be pasted in and then saved with a simple text \n",
    "box. I am aiming to avoid any menu bar or toolbars completely. What would be the\n",
    "perfect GUI library to create something like this?\"\"\"\n",
    "\n",
    "results = collection.query(query_texts=[query],n_results=2)\n",
    "for answer in results['documents'][0]:\n",
    "    wrapped_text = wrapper.wrap(text = answer)\n",
    "    for element in wrapped_text:\n",
    "        print(element)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
