{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install thirdai --upgrade\n",
    "!pip3 install \"thirdai[neural_db]\"  # You may have to unquote this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/pratyush/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/pratyush/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from thirdai import licensing, neural_db as ndb\n",
    "\n",
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "import os\n",
    "if \"THIRDAI_KEY\" in os.environ:\n",
    "    licensing.activate(os.environ[\"THIRDAI_KEY\"])\n",
    "else:\n",
    "    licensing.activate(\"\")  # Enter your ThirdAI key here\n",
    "    \n",
    "import pandas as pd\n",
    "import textwrap\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./stackoverflow_data/\"\n",
    "if not os.path.isdir(data_dir):\n",
    "    os.system(\"mkdir \"+data_dir)\n",
    "\n",
    "os.system(\"wget -nv -O \"+data_dir+\"train.csv 'https://www.dropbox.com/scl/fi/e7ltns3teqmngai3fp71o/stackoverflow_train.csv?rlkey=f9pq0amo5swfrdi1hcvk52cuc&dl=0'\")\n",
    "os.system(\"wget -nv -O \"+data_dir+\"test.csv 'https://www.dropbox.com/scl/fi/9rqf0nf2cmti0ihn5x4uu/stackoverflow_test.csv?rlkey=cn3ttfenhgxrsaemidnat0kt2&dl=0'\")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = data_dir+\"train.csv\"\n",
    "test_file = data_dir+\"test.csv\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Base GeneralQnA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'success', 'message': 'Succesfully got the detailed model info', 'data': {'model_name': 'GeneralQnA', 'description': '', 'is_indexed': True, 'publish_date': '2024-03-21 19:09:43.557831', 'size': '1307999671', 'size_in_memory': '5231994778', 'trained_on': 'Own Documents', 'num_params': '300052000', 'user_email': 'benito@thirdai.com', 'username': 'thirdai', 'access_level': 'public', 'domain': 'thirdai.com', 'hash': '1b5cfd975b40cc72e85de3b7c38f30e6234f8687ba46817ed978f7d3fff466e4', 'thirdai_version': '0.7.34+f86bbef'}}\n"
     ]
    }
   ],
   "source": [
    "bazaar = ndb.ModelBazaar(base_url=\"http://40.78.143.4/api/\")\n",
    "db = bazaar.pull_model(\"thirdai/GeneralQnA\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate metrics\n",
    "\n",
    "-   Relevance denotes that model predicts a revalant answer to query\n",
    "-   Helpfulness denotes that model predicts the highest scoring answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(db):\n",
    "    def precision_at_k(predicted, original, k):\n",
    "        total_precision = 0\n",
    "        for pred_instance, orig_instance in zip(predicted, original):\n",
    "            total_precision += len(set(pred_instance[:k]) & set(orig_instance)) / k\n",
    "        return total_precision / len(predicted) \n",
    "    test_df = pd.read_csv(test_file)\n",
    "    questions = test_df['query'].to_list()\n",
    "    true_labels_all = list(map(lambda x: list(map(int, x.split(\",\"))), test_df['ids'].to_list()))\n",
    "    predicted_all, original_all, original_top  = [], [], []\n",
    "    results = db.search_batch(questions, top_k=1)\n",
    "    for result, true_labels in list(zip(results, true_labels_all)):\n",
    "        predicted_labels = [res.metadata['id'] for res in result]\n",
    "        predicted_all.append(predicted_labels)\n",
    "        original_all.append(true_labels)\n",
    "        original_top.append(true_labels[:1])\n",
    "    print(\"Relevance Precision@1 =\", precision_at_k(predicted_all, original_all, 1)) \n",
    "    print(\"Helpfulness Precision@1 =\", precision_at_k(predicted_all, original_top, 1)) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsupervised training on answer and titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train | epoch 0 | train_steps 263928 | train_hash_precision@5=0.44301  | train_batches 10 | time 9.566s\n",
      "\n",
      "train | epoch 1 | train_steps 263938 | train_hash_precision@5=0.41672  | train_batches 10 | time 7.444s\n",
      "\n",
      "train | epoch 2 | train_steps 263948 | train_hash_precision@5=0.65176  | train_batches 10 | time 7.389s\n",
      "\n",
      "train | epoch 3 | train_steps 263958 | train_hash_precision@5=0.78096  | train_batches 10 | time 7.228s\n",
      "\n",
      "train | epoch 4 | train_steps 263968 | train_hash_precision@5=0.875  | train_batches 10 | time 6.739s\n",
      "\n",
      "train | epoch 5 | train_steps 263978 | train_hash_precision@5=0.93123  | train_batches 10 | time 6.687s\n",
      "\n",
      "train | epoch 6 | train_steps 263988 | train_hash_precision@5=0.96209  | train_batches 10 | time 6.640s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csv_file = ndb.CSV(train_file, id_column=\"id\", strong_columns=['title', 'answer'])\n",
    "source_ids = db.insert([csv_file], train=True, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevance Precision@1 = 0.04522613065326633\n",
      "Helpfulness Precision@1 = 0.035175879396984924\n"
     ]
    }
   ],
   "source": [
    "test(db)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised training on questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train | epoch 7 | train_steps 263998 |  | train_batches 10 | time 7.801s\n",
      "\n",
      "train | epoch 8 | train_steps 264008 |  | train_batches 10 | time 7.705s\n",
      "\n",
      "train | epoch 9 | train_steps 264018 |  | train_batches 10 | time 7.664s\n",
      "\n",
      "train | epoch 10 | train_steps 264028 |  | train_batches 10 | time 7.693s\n",
      "\n",
      "train | epoch 11 | train_steps 264038 |  | train_batches 10 | time 7.716s\n",
      "\n",
      "train | epoch 12 | train_steps 264048 |  | train_batches 10 | time 7.739s\n",
      "\n",
      "train | epoch 13 | train_steps 264058 |  | train_batches 10 | time 7.768s\n",
      "\n",
      "train | epoch 14 | train_steps 264068 |  | train_batches 10 | time 7.599s\n",
      "\n",
      "train | epoch 15 | train_steps 264078 |  | train_batches 10 | time 7.724s\n",
      "\n",
      "train | epoch 16 | train_steps 264088 |  | train_batches 10 | time 7.662s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sup_data = ndb.Sup(\n",
    "            train_file,\n",
    "            query_column=\"query\",\n",
    "            id_delimiter=\"\",\n",
    "            id_column=\"id\",\n",
    "            source_id=source_ids[0],\n",
    "        )\n",
    "db.supervised_train([sup_data], learning_rate=0.001, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevance Precision@1 = 0.7587939698492462\n",
      "Helpfulness Precision@1 = 0.6381909547738693\n"
     ]
    }
   ],
   "source": [
    "test(db)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upvoting highest scoring answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_file)\n",
    "train_df = train_df.sort_values('score', ascending=False).groupby('query').first().reset_index()\n",
    "batches_to_upvote=[(row.query, row.id) for row in train_df.itertuples()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(batches_to_upvote)\n",
    "\n",
    "db.text_to_result_batch(batches_to_upvote, n_upvote_samples=1, n_balancing_samples=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevance Precision@1 = 0.9547738693467337\n",
      "Helpfulness Precision@1 = 0.9045226130653267\n"
     ]
    }
   ],
   "source": [
    "test(db)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's ask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapper = textwrap.TextWrapper(width=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " You can build a markov-chain of a huge english text. Afterwards you can feed words into the markov\n",
      "chain and check how high the probability is that the word is english. See here:\n",
      "http://en.wikipedia.org/wiki/Markov_chain At the bottom of the page you can see the markov text\n",
      "generator. What you want is exactly the reverse of it. In a nutshell: The markov-chain stores for\n",
      "each character the probabilities of which next character will follow. You can extend this idea to\n",
      "two or three characters if you have enough memory.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"I possess an algorithm that produces strings from a list of input words. \n",
    "How do I isolate only the strings that sound like English words? ie. reject \n",
    "RDLO while retaining LORD. EDIT: To clarify, they don't have to be real words \n",
    "in the dictionary. They just need to resemble English. For instance, KEAL would be \n",
    "acceptable.\"\n",
    "\"\"\"\n",
    "\n",
    "results = db.search(query,top_k=1)\n",
    "for result in results:\n",
    "    answer = result.metadata['answer']\n",
    "    wrapped_text = wrapper.wrap(text = answer)\n",
    "    for element in wrapped_text:\n",
    "        print(element)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " You basically need 2 tests. 1) Pass in a string like \"The Quick Brown Fox Jumps!\" (length greater\n",
      "than five) makes sure that the value is affected by replaceit(...) 2) Pass in a string like \"Foo\"\n",
      "(length is less than five) and make sure that the value is affected by changeit(...) Your test (in\n",
      "pseudo code) might look like this: testLongValue() { string testValue = \"A value longer than 5\n",
      "chars\"; string expected = \"Replaced!\"; string actual = modify(testValue); assertEqual(expected,\n",
      "actual); } testShortValue() { string testValue = \"len4\"; string expected = \"Changed!\"; string actual\n",
      "= modify(testValue); assertEqual(expected, actual); } Obviously I could give you a more realistic\n",
      "example if I knew what replacit() and changeit() were supposed to do, but this should give you the\n",
      "idea. If it mutates the original value reference instead of returning it, you can just use testValue\n",
      "as the actual value after the call occurs.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"What is the optimal way to unit test a method that invokes multiple methods, \n",
    "for instance: modify(string value) { if(value.Length &gt; 5) replaceit(value); else \n",
    "changeit(value); } This pseudo code has a modify method that (currently) calls either replaceit() \n",
    "or changeit() . I have already written tests for replaceit and changeit , so creating a new test for\n",
    "modify will be 99% the same set of code. I need to test it though because it might change \n",
    "in the future. So do I duplicate the existing test code? Shift the test code to a common function? \n",
    "Any other suggestions? I'm uncertain of the best practice here.\n",
    "\"\"\"\n",
    "\n",
    "results = db.search(query,top_k=1)\n",
    "for result in results:\n",
    "    answer = result.metadata['answer']\n",
    "    wrapped_text = wrapper.wrap(text = answer)\n",
    "    for element in wrapped_text:\n",
    "        print(element)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The question is pretty broad, but I'm partial to markup-based UIs. Here's a window with a text box\n",
      "in WPF: &lt;Window xmlns=\"http://schemas.microsoft.com/winfx/2006/xaml/presentation\"&gt;\n",
      "&lt;Grid&gt; &lt;TextBox x:Name=\"InputBox\"/&gt; &lt;/Grid&gt; &lt;/Window&gt; Now I won't even try\n",
      "to claim that WPF has the shortest learning curve, but it is the most powerful on Windows and it's\n",
      "pretty easy to pick up with the right tooling. (i.e. Expression Blend). Blend isn't cheap but some\n",
      "folks already have it for free and don't know it (students, MSDN subscribers, some startups). Visual\n",
      "Studio 2010 is much improved in this area too, so Blend may not be needed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"I am seeking to develop a very lightweight GUI front end in Windows.\n",
    "It's meant to perform a simple task - when a hot key combination is pressed it\n",
    "opens up a text box. Any text can be pasted in and then saved with a simple text \n",
    "box. I am aiming to avoid any menu bar or toolbars completely. What would be the\n",
    "perfect GUI library to create something like this?\"\"\"\n",
    "\n",
    "results = db.search(query,top_k=1)\n",
    "for result in results:\n",
    "    answer = result.metadata['answer']\n",
    "    wrapped_text = wrapper.wrap(text = answer)\n",
    "    for element in wrapped_text:\n",
    "        print(element)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
