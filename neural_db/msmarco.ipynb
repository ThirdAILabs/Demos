{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SOTA Q&A over MSMarco text (~9M chunks) in 4 minutes on Laptop\n",
    "\n",
    "With ThirdAI we can build a Q&A system on MSMarco, the largest BEIR Benchmark — achieving SoTA accuracy in 4 minutes using just a Laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install \"thirdai>=0.7.40\"\n",
    "!pip3 install beir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Getting Started\n",
    "\n",
    "First let's import the library and download the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thirdai import neural_db as ndb\n",
    "from thirdai import demos, licensing\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import os\n",
    "if \"THIRDAI_KEY\" in os.environ:\n",
    "    licensing.activate(os.environ[\"THIRDAI_KEY\"])\n",
    "else:\n",
    "    licensing.activate(\"\")  # Enter your ThirdAI key here\n",
    "\n",
    "# Downloads msmarco and puts all of the documents into a csv file.\n",
    "documents, train_queries, test_queries, _ = demos.download_beir_dataset(\"msmarco\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Building the System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qna_model = ndb.NeuralDB()\n",
    "\n",
    "start = time.perf_counter()\n",
    "\n",
    "qna_model.insert([\n",
    "\tndb.CSV(\n",
    "        documents,\n",
    "        id_column=\"DOC_ID\",        # Indicates which column stores the document ids.\n",
    "        strong_columns=[\"TITLE\"],  # Indicates which column contains the title.\n",
    "        weak_columns=[\"TEXT\"],     # Indicates which column contains the text.\n",
    ")])\n",
    "\n",
    "end = time.perf_counter()\n",
    "print(f\"Completed in {end-start:.3f} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_labels(labels):\n",
    "    return list(map(int, labels.split(\":\")))\n",
    "\n",
    "\n",
    "def evaluate(qna_model, test_queries):\n",
    "    test_df = pd.read_csv(test_queries)\n",
    "    test_df[\"DOC_ID\"] = test_df[\"DOC_ID\"].map(parse_labels)\n",
    "\n",
    "    true_positives = 0\n",
    "    start = time.perf_counter()\n",
    "    for _, row in test_df.iterrows():\n",
    "        result = qna_model.search(row[\"QUERY\"], top_k=5)\n",
    "        if len(result) and result[0].id in row[\"DOC_ID\"]:\n",
    "            true_positives += 1\n",
    "    end = time.perf_counter()\n",
    "\n",
    "    precision = true_positives / len(test_df)\n",
    "    print(f\"precision@1={precision:.3f}\")\n",
    "    avg_time = (end - start) / len(test_df) * 1000\n",
    "    print(f\"average query time: {avg_time:.3f} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(qna_model=qna_model, test_queries=test_queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So how does this compare to other systems?\n",
    "\n",
    "| Model/System | precision@1 |\n",
    "| --- | --- |\n",
    "| Elastic Search  | 0.65 |\n",
    "| Google T5-Base | 0.56 |\n",
    "| Open AI Ada | 0.81 |\n",
    "| ThirdAI | 0.79 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Domain Specialization\n",
    "\n",
    "While this system already achieves a comparable accuracy to the best Embedding Models, what if we want to improve it further? One of the defining characteristics of successful production search systems is their ability to continually improve based on user interactions. For example, say a company uses the custom acronym IDD to mean “initial design document”. Since this acronym doesn't appear in the training data used to create the LLMs in the search system, user queries like the “summarize the IDD for project xyz” will fail since the system doesn't understand the acronym used. With domain specialization the system can adapt to understand these relationships and answer queries like this correctly. These user interactions allow the underlying system to learn patterns/trends in user preferences that aren't present in the raw documents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_queries)\n",
    "train_df[\"DOC_ID\"] = train_df[\"DOC_ID\"].map(parse_labels)\n",
    "\n",
    "start = time.perf_counter()\n",
    "\n",
    "qna_model.supervised_train_with_ref_ids(\n",
    "    queries=train_df[\"QUERY\"].to_list(), labels=train_df[\"DOC_ID\"].to_list()\n",
    ")\n",
    "\n",
    "end = time.perf_counter()\n",
    "print(f\"finetuned in {end-start:.3f} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we rerun the evaluation we see that the precision@1 has improved to 0.814 just by feeding sample user interactions into the system. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(qna_model=qna_model, test_queries=test_queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Energy Efficient AI\n",
    "\n",
    "Another point of emphasis should be the environmental impact. While new advances in AI are undoubtably impressive and revolutionary, the energy requirements are enormous. The next generation of Nvidia H100 GPUs in production are alone projected to surpass the energy usage of a small nation. Finding energy efficient alternatives is essential as this technology continues to develop. A system like ThirdAI that uses only a fraction of the computing resources and requires no hardware accelerators offers a path to significantly less energy usage when deploying generative AI systems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
