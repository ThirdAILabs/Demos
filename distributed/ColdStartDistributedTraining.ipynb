{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Distributed] Pre-training and fine-tuning an LLM on CPU on AG News with ThirdAI's UDT\n",
    "\n",
    "This training script shows how to run data parallel pre-training of an LLM from scratch on the popular AG News Dataset (https://www.kaggle.com/datasets/amananandrai/ag-news-classification-dataset) using ThirdAI's Universal Deep Transformer (UDT)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import thirdai and activate license"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install datasets\n",
    "!pip3 install thirdai --upgrade\n",
    "!pip3 install ray\n",
    "!pip3 install torch\n",
    "\n",
    "import thirdai\n",
    "from thirdai import bolt\n",
    "import os\n",
    "import thirdai.distributed_bolt as dist  \n",
    "thirdai.licensing.activate('XFTR-LPUL-HFRY-V4A3-NAR4-YEUK-X9VT-MNLR')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Ray Cluster Initialization\n",
    " For the purpose of this demo, we will be initializing a mock ray cluster of 2 nodes here. Change num_cpus accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray.air import ScalingConfig, session\n",
    "\n",
    "cpus_per_node = (dist.get_num_cpus() - 1) // 2\n",
    "\n",
    "ray.init(ignore_reinit_error=True, runtime_env={\"env_vars\": {\"OMP_NUM_THREADS\": f\"{cpus_per_node}\"}})\n",
    "scaling_config = ScalingConfig(\n",
    "    num_workers=2,\n",
    "    use_gpu=False,\n",
    "    trainer_resources={\"CPU\": 1},\n",
    "    resources_per_worker={\"CPU\": cpus_per_node},\n",
    "    placement_strategy=\"PACK\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Download and process the dataset into a csv file. <br>\n",
    "### 3.1 We divide our dataset into 2 datasets for purpose of data-parallel training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "file_1 = open('agnews_train_0.csv', 'w')\n",
    "file_2 = open('agnews_train_1.csv', 'w')\n",
    "\n",
    "corpus = load_dataset(\"ag_news\")[\"train\"][\"text\"]\n",
    "num_datapoints = len(corpus)\n",
    "\n",
    "file_1.write(\"id,text\\n\")\n",
    "file_2.write(\"id,text\\n\")\n",
    "\n",
    "idx = 0\n",
    "for line in corpus:\n",
    "    if idx < num_datapoints//2:\n",
    "        nothing = file_1.write(str(idx) + \",\" + line.replace(\",\", \" \").lower() + \"\\n\")\n",
    "    else:\n",
    "        nothing = file_2.write(str(idx) + \",\" + line.replace(\",\", \" \").lower() + \"\\n\")\n",
    "\n",
    "    idx += 1\n",
    "\n",
    "file_1.close()\n",
    "file_2.close()\n",
    "\n",
    "train_filenames = ['agnews_train_0.csv', 'agnews_train_1.csv']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Looking at the dataset\n",
    "In the above step, *agnews_train_[0/1].csv* files refers to the corpus file with document id and text. We can have even more columns with other metadata for each row. <br>\n",
    "\n",
    "A couple of sample rows of the *corpus_file* are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.options.display.max_colwidth = 700\n",
    "pd.read_csv(train_filenames[0], nrows=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define a UDT model and training loop\n",
    "\n",
    "In the UDT model, <i>data_type</i> *query* can be anything of your choice but *id* should match with the one in the header of the *corpus_file*.\n",
    "\n",
    "The <b><i>train_loop_per_worker</i></b> defines the training that will run on each worker node.\n",
    "\n",
    "Pre-training with UDT supports two types of columns, strong and weak. For the purpose of this demo, we choose *text* to be the strong column and leave the weak column list to be empty.<br>\n",
    "We will now train a UDT model in distributed data parallel fashion. Feel free to customize the number of epochs and the learning rate. <br>\n",
    "<u><b>PLEASE NOTE :</b></u> Currently, UDT's cold_start function requires the *id* to be an integer. We will add support for other formats in a future release."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_udt_model(model_config_path):\n",
    "    model = bolt.UniversalDeepTransformer(\n",
    "        data_types={\n",
    "            \"query\": bolt.types.text(),\n",
    "            \"id\": bolt.types.categorical(delimiter=':'),\n",
    "        },\n",
    "        target=\"id\",\n",
    "        n_target_classes=num_datapoints,\n",
    "        integer_target=True,\n",
    "        model_config=model_config_path,\n",
    "    )\n",
    "    return model\n",
    "    \n",
    "def train_loop_per_worker(config):\n",
    "    # thirdai.licensing.deactivate()\n",
    "    # thirdai.licensing.activate(\"HN7J-W79C-KN9U-WTKE-9PNM-4PVR-CNPJ-WTWE\")\n",
    "    thirdai.logging.setup(log_to_stderr=False, path=\"log.txt\", level=\"info\")\n",
    "    thirdai.licensing.activate('XFTR-LPUL-HFRY-V4A3-NAR4-YEUK-X9VT-MNLR')\n",
    "    \n",
    "    \n",
    "    model_config_path = os.path.join(config[\"curr_dir\"], '../configs/embeddings_and_cold_start_0.005.config')\n",
    "    model = get_udt_model(model_config_path)\n",
    "    model = dist.prepare_model(model)\n",
    "\n",
    "    metrics = model.coldstart_distributed_v2(\n",
    "        filename=os.path.join(config[\"curr_dir\"], train_filenames[session.get_world_rank()]),\n",
    "        strong_column_names=[\"text\"],\n",
    "        weak_column_names=[],\n",
    "        learning_rate=0.001,\n",
    "        epochs=5,\n",
    "        metrics=[\"categorical_accuracy\"],\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    session.report(\n",
    "        metrics=metrics,\n",
    "        checkpoint=dist.UDTCheckPoint.from_model(model),\n",
    "    )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Distributed Training\n",
    "\n",
    "Now, we start the training using <b>ThirdAI</b> <i>BoltTrainer</i> which runs the <i>train_loop_per_worker</i> function on different worker nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from ray.train.torch import TorchConfig\n",
    "\n",
    "trainer = dist.BoltTrainer(\n",
    "    train_loop_per_worker=train_loop_per_worker,\n",
    "    train_loop_config={\n",
    "        \"curr_dir\": os.path.abspath(os.getcwd()),\n",
    "    },\n",
    "    scaling_config=scaling_config,\n",
    "    backend_config=TorchConfig(backend=\"gloo\"),\n",
    ")\n",
    "\n",
    "result_checkpoint_and_history = trainer.fit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save and load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = result_checkpoint_and_history.checkpoint.get_model()\n",
    "model.save('./agnews.model')\n",
    "\n",
    "model = bolt.UniversalDeepTransformer.load('./agnews.model')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Make Predictions\n",
    "\n",
    "### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from thirdai.demos import download_agnews_dataset\n",
    "\n",
    "corpus_file = './agnews.csv'\n",
    "download_agnews_dataset(corpus_file)\n",
    "\n",
    "df = pd.read_csv(corpus_file)\n",
    "\n",
    "activations = model.predict({'query':'BRITAIN: BLAIR WARNS OF CLIMATE THREAT Prime Minister Tony Blair urged the international community to consider global warming a dire threat and agree on a plan of action to curb the  quot;alarming quot; growth of greenhouse gases'})\n",
    "top_preds = np.argsort(-activations)[:5]\n",
    "\n",
    "df.iloc[top_preds]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the same example, here are the top-5 results that OpenAI's Search and Recommendation notebook (https://github.com/openai/openai-cookbook/blob/main/examples/Recommendation_using_embeddings.ipynb) gets.\n",
    "\n",
    "| text |\n",
    "| --- |\n",
    "| THE re-election of British Prime Minister Tony Blair would be seen as an endorsement of the military action in Iraq, Prime Minister John Howard said today |\n",
    "| LONDON, England -- A US scientist is reported to have observed a surprising jump in the amount of carbon dioxide, the main greenhouse gas. |\n",
    "| The anguish of hostage Kenneth Bigley in Iraq hangs over Prime Minister Tony Blair today as he faces the twin test of a local election and a debate by his Labour Party about the divisive war. |\n",
    "| Israel is prepared to back a Middle East conference convened by Tony Blair early next year despite having expressed fears that the British plans were over-ambitious and designed |\n",
    "| AFP - A battle group of British troops rolled out of southern Iraq on a US-requested mission to deadlier areas near Baghdad, in a major political gamble for British Prime Minister Tony Blair. |\n",
    "\n",
    "\n",
    "### Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = model.predict({'query':'PC World - Upcoming chip set will include built-in security features for your PC'})\n",
    "top_preds = np.argsort(-activations)[:5]\n",
    "\n",
    "df.iloc[top_preds]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the same example, here are the top-5 results that OpenAI's Search and Recommendation notebook (https://github.com/openai/openai-cookbook/blob/main/examples/Recommendation_using_embeddings.ipynb) gets.\n",
    "\n",
    "| text |\n",
    "| --- |\n",
    "| PC World - Updated antivirus software for businesses adds intrusion prevention features. |\n",
    "| PC World - The one-time World Class Product of the Year PDA gets a much-needed upgrade. |\n",
    "| PC World - Send your video throughout your house--wirelessly--with new gateways and media adapters. |\n",
    "| PC World - Symantec, McAfee hope raising virus-definition fees will move users to\\  suites. |\n",
    "| Gateway computers will be more widely available at Office Depot, in the PC maker #39;s latest move to broaden distribution at retail stores since acquiring rival eMachines this year. |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ray Cluster Teardown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
