{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bolt TextClassifier Demo\n",
    "\n",
    "The bolt TextClassifier is an easy way to quickly develop, train, and test a model to perform classification and categorization of text data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thirdai import bolt\n",
    "import datasets\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Helper Functions \n",
    "def write_dataset_to_csv(dataset, filename, return_labels=False):\n",
    "    label_names = dataset.features[\"intent\"].names\n",
    "\n",
    "    data = []\n",
    "    for item in dataset:\n",
    "        sentence = item[\"text\"]\n",
    "        label = item[\"intent\"]\n",
    "        label_name = label_names[label]\n",
    "        data.append((sentence, label_name))\n",
    "\n",
    "    random.shuffle(data)\n",
    "\n",
    "    with open(filename, \"w\") as file:\n",
    "        file.write('\"text\",\"category\"\\n')\n",
    "        lines = [\n",
    "            '\"{}\",\"{}\"\\n'.format(sentence, label_name) for sentence, label_name in data\n",
    "        ]\n",
    "        file.writelines(lines)\n",
    "\n",
    "    if return_labels:\n",
    "        labels = [x[1] for x in data]\n",
    "        return labels\n",
    "\n",
    "\n",
    "def download_clinc_dataset(train_filename, test_filename):\n",
    "    clinc_dataset = datasets.load_dataset(\"clinc_oos\", \"plus\")\n",
    "    write_dataset_to_csv(clinc_dataset[\"train\"], train_filename)\n",
    "    labels = write_dataset_to_csv(clinc_dataset[\"test\"], test_filename, return_labels=True)\n",
    "\n",
    "    return (clinc_dataset[\"train\"].features[\"intent\"].num_classes, labels)\n",
    "\n",
    "\n",
    "\n",
    "def compute_accuracy(test_labels, pred_file):\n",
    "    with open(pred_file) as pred:\n",
    "        predictions = pred.readlines()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    assert len(predictions) == len(test_labels)\n",
    "    for (prediction, answer) in zip(predictions, test_labels):\n",
    "        if prediction[:-1] == answer:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset clinc_oos (/Users/nmeisburger/.cache/huggingface/datasets/clinc_oos/plus/1.0.0/abcc41d382f8137f039adc747af44714941e8196e845dfbdd8ae7a7e020e6ba1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b340908676045e493244d56c882604f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TRAIN_FILE = \"./clinc_train.csv\"\n",
    "TEST_FILE = \"./clinc_test.csv\"\n",
    "PREDICTION_FILE = \"./clinc_predictions.txt\"\n",
    "\n",
    "(n_classes, test_labels) = download_clinc_dataset(TRAIN_FILE, TEST_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the TextClassifier model\n",
    "\n",
    "## Arguments\n",
    "- `model_size`: Controls how big the model is. Options are ‘small’, ‘medium’,  ‘large’, or a target model size in gigabytes, i.e. “4 Gb” or “4Gb”.\n",
    "- `n_classes`: How many output classes are in the dataset.\n",
    "- `input_dim`: The range of the input. This determines what range the pairgrams are hashed to. This is an optional parameter that defaults to 100,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Using large load_factor value 0.2 in Layer, consider decreasing load_factor\n",
      "====== Building Fully Connected Network ======\n",
      "FullyConnected: dim=670, load_factor=0.2, act_func=ReLU, sampling: {hashes_per_table=3, num_tables=102, range_pow=9, reservoir_size=4}\n",
      "FullyConnected: dim=151, load_factor=1, act_func=Softmax\n",
      "Initialized Network in 0 seconds\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "classifier = bolt.TextClassifier(model_size=\"small\", n_classes=n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the TextClassifier\n",
    "\n",
    "## Arguments\n",
    "- `train_file`: The dataset to train on. The expected format is a csv file with two columns. The columns should be named “text” and “category”. The category column will contain the labels, the “text” column should contain the sentence. The columns should be column separated. Example:\n",
    "    \n",
    "    ```json\n",
    "    “text”,”category”\n",
    "    “the red dog ran up the hill”,”action\"\n",
    "    ```\n",
    "    \n",
    "- `epochs`: This is an optional parameter that determines the number of epochs to train on. The default value is 1. If there is 1 epoch then it uses a streaming dataset. If the number of epochs is greater than 1 then it loads the dataset into memory and trains for the specified number of epochs.\n",
    "- `learning_rate`: This is an optional parameter to control the learning rate. Default value is 0.001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1:\n",
      "[==================================================] 100%\n",
      "Processed 60 training batches in 2 seconds\n",
      "\n",
      "Epoch 2:\n",
      "[==================================================] 100%\n",
      "Processed 60 training batches in 2 seconds\n",
      "\n",
      "Epoch 3:\n",
      "[==================================================] 100%\n",
      "Processed 60 training batches in 2 seconds\n",
      "\n",
      "Epoch 4:\n",
      "[==================================================] 100%\n",
      "Processed 60 training batches in 2 seconds\n",
      "\n",
      "Epoch 5:\n",
      "[==================================================] 100%\n",
      "Processed 60 training batches in 2 seconds\n",
      "\n",
      "Epoch 6:\n",
      "[==================================================] 100%\n",
      "Processed 60 training batches in 2 seconds\n",
      "\n",
      "Epoch 7:\n",
      "[==================================================] 100%\n",
      "Processed 60 training batches in 2 seconds\n"
     ]
    }
   ],
   "source": [
    "classifier.train(train_file=TRAIN_FILE, epochs=7, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing The Classifier\n",
    "## Arguments\n",
    "- `test_file`: The test dataset to run. The expected format is the same as train file in the train method.\n",
    "- `output_file`: This is an optional parameter. If it is specified then as the data is processed it writes the names of the predicted classes into this file. Each predicted class name is on its own line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.815273 (4484/5500)\n"
     ]
    }
   ],
   "source": [
    "classifier.predict(test_file=TEST_FILE, output_file=PREDICTION_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run evaluation on predictions\n",
    "Here we are just recomputing the accuracy to demonstrate use of the output file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8152727272727273"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_accuracy(test_labels, PREDICTION_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup files\n",
    "os.remove(TRAIN_FILE)\n",
    "os.remove(TEST_FILE)\n",
    "os.remove(PREDICTION_FILE)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
