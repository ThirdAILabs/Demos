{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Personalized Movie Recommendations\n",
    "This notebook shows how to build a personalized movie recommendation model with ThirdAI's Universal Deep Transformer (UDT) model, our all-purpose classifier for tabular datasets. In this demo, we will train and evaluate the model on the Movielens 1M dataset, but you can easily replace this with your own dataset.\n",
    "\n",
    "To run this notebook, you will need to obtain a ThirdAI license at the following link if you have not already: https://www.thirdai.com/try-bolt/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install thirdai\n",
    "!pip3 install pandas # We need Pandas in the utils module to convert downloaded datasets to CSV format\n",
    "!pip3 install numpy # We use numpy to analyze UDT performance in this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Download\n",
    "We will use the utils module in this repo to download dataset_name (if you have just copied this notebook and not cloned the entire repo, you will need to copy the utils.py file as well). You can replace this step and the next step with a download method and a UDT initialization step that is specific to your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "train_filename, test_filename, inference_batch, index_batch = utils.download_movielens()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UDT Initialization\n",
    "We can now create a UDT model by passing in the types of each column in the dataset and the target column we want to be able to predict.\n",
    "\n",
    "For this demo, we additionally want to use \"temporal context\" to make predictions. Adding temporal context requires a single bolt.types.date() column to use to track the timestamp of training data. We pass in a dictionary called temporal_tracking_relationships that tells UDT we want to track movies over time for each user. This allows UDT to make better predictions for the target column by creating temporal features that take into account the historical relationship between users and movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thirdai import bolt\n",
    "\n",
    "model = bolt.UniversalDeepTransformer(\n",
    "    data_types={\n",
    "        \"userId\": bolt.types.categorical(n_unique_classes=6040),\n",
    "        \"movieTitle\": bolt.types.categorical(n_unique_classes=3706),\n",
    "        \"timestamp\": bolt.types.date(),\n",
    "    },\n",
    "    temporal_tracking_relationships={\n",
    "        \"userId\": [\"movieTitle\"]\n",
    "    },\n",
    "    target=\"movieTitle\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "We can now train our UDT model with just two lines! Feel free to customize the number of epochs and the learning rate; we have chosen values that give good convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = (bolt.TrainConfig(epochs=3, learning_rate=0.001)\n",
    "                    .with_metrics([\"recall@10\"]))\n",
    "\n",
    "model.train(train_filename, train_config);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "Evaluating the performance of the UDT model is also just two lines!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_config = (bolt.EvalConfig()\n",
    "                   .with_metrics([\"recall@1\", \"recall@10\", \"recall@100\"]))\n",
    "\n",
    "model.evaluate(test_filename, eval_config);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and Loading\n",
    "Saving and loading a trained UDT model to disk is also extremely straight forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_location = \"personalized_movie_recommendation.model\"\n",
    "\n",
    "# Saving\n",
    "model.save(save_location)\n",
    "\n",
    "# Loading\n",
    "model = bolt.UniversalDeepTransformer.load(save_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Predictions\n",
    "The evaluation method is great for testing, but it requires labels, which don't exist in a production setting. We also have a predict method that can take in an in-memory batch of rows or a single row (without the target column), allowing easy integration into production pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inference_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(\"Inference batch:\", inference_batch)\n",
    "\n",
    "prediction = model.predict(inference_batch[0])\n",
    "class_name = model.class_name(np.argmax(prediction))\n",
    "print(\"Input:\", inference_batch[0], \"Prediction:\", class_name, \"\\n\")\n",
    "\n",
    "prediction_batch = model.predict_batch(inference_batch)\n",
    "class_names = [model.class_name(class_id) for class_id in np.argmax(prediction_batch, axis=1)]\n",
    "print(\"Batch Prediction Results\")\n",
    "for input_sample, class_name in zip(inference_batch, class_names):\n",
    "    print(\"Input:\", input_sample, \"Prediction:\", class_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may notice that we keep recommending the same movies to the same person. This is because we don't update UDT's temporal trackers with new information. If we \"index\" new observations as we get them, then UDT will take advantage of this new information to make better predictions. When you run the following cell, notice how the prediction changes in response to new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Observations batch:\", inference_batch)\n",
    "\n",
    "# Let's reset the temporal trackers whenever we run this cell to keep results consistent.\n",
    "# This clears the watch histories of every user. \n",
    "model.reset_temporal_trackers()\n",
    "\n",
    "for input_sample, new_observation in zip(inference_batch, index_batch):\n",
    "    prediction = model.predict(input_sample)\n",
    "    top_10_ids = np.argsort(-prediction)[:10]\n",
    "    top_10_class_names = [model.class_name(class_id) for class_id in top_10_ids]\n",
    "    print(\"Single Prediction Result\")\n",
    "    print(\"Input:\", input_sample, \"Predictions:\", top_10_class_names)\n",
    "    \n",
    "    # Index new observations as we get them to help UDT make informed predictions.\n",
    "    model.index(new_observation)\n",
    "    print(\"Indexed ground truth sample:\", new_observation, \"\\n\")\n",
    "\n",
    "# We can also index an entire batch of observations.\n",
    "model.index_batch(index_batch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
