{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **How to use BOLT,**\n",
    "# **fast training,**\n",
    "# **benefits of sparse models,**\n",
    "# **and fast inference.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning the syntax with simple exercise: MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(Geordie): Add download scripts and change to relative path\n",
    "from thirdai import dataset\n",
    "\n",
    "mnist_train = dataset.load_bolt_svm_dataset(\n",
    "    filename=\"datasets/mnist/mnist\", \n",
    "    batch_size=256)\n",
    "\n",
    "mnist_test = dataset.load_bolt_svm_dataset(\n",
    "    filename=\"datasets/mnist/mnist.t\", \n",
    "    batch_size=256)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We'll use a simple neural network with 784-dim input, 1000-dim hidden layer with ReLU, and 10-dim output layer with Softmax."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Keras**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "keras_layers = [\n",
    "    keras.layers.Dense(\n",
    "        units=1000, \n",
    "        activation='relu', \n",
    "        input_shape=(784,)),\n",
    "        \n",
    "    keras.layers.Dense(\n",
    "        units=10, \n",
    "        activation='softmax')\n",
    "]\n",
    "\n",
    "keras_model = keras.Sequential(layers=keras_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **BOLT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thirdai import bolt\n",
    "\n",
    "mnist_layers = [\n",
    "    bolt.LayerConfig(\n",
    "        dim=1000, \n",
    "        activation_function=bolt.ActivationFunctions.ReLU),\n",
    "    \n",
    "    bolt.LayerConfig(\n",
    "        dim=10, \n",
    "        activation_function=bolt.ActivationFunctions.Softmax)\n",
    "]\n",
    "\n",
    "mnist_network = bolt.Network(\n",
    "    layers=mnist_layers, \n",
    "    input_dim=784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We now train the network with categorical cross entropy loss function. We'll measure how we do with the categorical accuracy metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_network.train(\n",
    "    train_data=mnist_train, \n",
    "    loss_fn=bolt.CategoricalCrossEntropyLoss(), \n",
    "    learning_rate=0.001, \n",
    "    epochs=1)\n",
    "\n",
    "mnist_network.predict(\n",
    "    test_data=mnist_test, \n",
    "    metrics=[\"categorical_accuracy\"], \n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## That's neat, but what about bigger models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(Geordie): Add download scripts and change to relative path\n",
    "intent_class_train = dataset.load_bolt_svm_dataset(\n",
    "    filename=\"datasets/intent_classification/train_shuf.svm\", \n",
    "    batch_size=256)\n",
    "\n",
    "intent_class_test = dataset.load_bolt_svm_dataset(\n",
    "    filename=\"datasets/intent_classification/test_shuf.svm\", \n",
    "    batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use `load_factor` to set the computational budget. <br> BOLT curates the best small network for each sample to accelerate training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigger_layers = [\n",
    "    bolt.LayerConfig(\n",
    "        dim=10000, \n",
    "        load_factor=0.05, \n",
    "        activation_function=bolt.ActivationFunctions.ReLU),\n",
    "    \n",
    "    bolt.LayerConfig(\n",
    "        dim=151, \n",
    "        activation_function=bolt.ActivationFunctions.Softmax)\n",
    "]\n",
    "\n",
    "bigger_network = bolt.Network(\n",
    "    layers=bigger_layers, \n",
    "    input_dim=5512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You can also use sparsity to accelerate inference using `enable_sparse_inference()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigger_network.train(\n",
    "    train_data=intent_class_train, \n",
    "    loss_fn=bolt.CategoricalCrossEntropyLoss(), \n",
    "    learning_rate=0.001, \n",
    "    epochs=2)\n",
    "\n",
    "bigger_network.enable_sparse_inference()\n",
    "\n",
    "bigger_network.train(\n",
    "    train_data=intent_class_train, \n",
    "    loss_fn=bolt.CategoricalCrossEntropyLoss(), \n",
    "    learning_rate=0.001, \n",
    "    epochs=1)\n",
    "\n",
    "bigger_network.predict(\n",
    "    test_data=intent_class_test, \n",
    "    metrics=[\"categorical_accuracy\"], \n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Even larger model for accurate sentiment classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset.load_bolt_svm_dataset(\n",
    "    filename=\"../sa_demo/text_data/yelp_review_full_2class_train.svm\", \n",
    "    batch_size=1024)\n",
    "\n",
    "test_data = dataset.load_bolt_svm_dataset(\n",
    "    filename=\"../sa_demo/text_data/yelp_review_full_2class_test.svm\", \n",
    "    batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supporting 100,000-dim rich input features through sparsity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_sentiment_analysis_layers = [\n",
    "    \n",
    "    bolt.LayerConfig(dim=2000, \n",
    "        load_factor=0.2, \n",
    "        activation_function=bolt.ActivationFunctions.ReLU),\n",
    "    \n",
    "    bolt.LayerConfig(dim=2,\n",
    "        load_factor=1.0, \n",
    "        activation_function=bolt.ActivationFunctions.Softmax)     \n",
    "]\n",
    "\n",
    "yelp_sentiment_analysis_network = bolt.Network(\n",
    "    layers=yelp_sentiment_analysis_layers, \n",
    "    input_dim=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model once and save it for later with `save()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(Geordie): Add download scripts and change to relative path\n",
    "\n",
    "\n",
    "yelp_sentiment_analysis_network.train(\n",
    "    train_data=train_data,\n",
    "    loss_fn=bolt.CategoricalCrossEntropyLoss(), \n",
    "    learning_rate=0.0001, \n",
    "    epochs=20, \n",
    "    rehash=6400, \n",
    "    rebuild=128000)\n",
    "\n",
    "yelp_sentiment_analysis_network.save(filename=\"yelp_sentiment_analysis_cp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the saved model with `load()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_sentiment_analysis_network = bolt.Network.load(filename=\"yelp_sentiment_analysis_cp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RoBERTa: 83% accuracy. Let's see how BOLT does!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(Geordie): Add download scripts and change to relative path\n",
    "res = yelp_sentiment_analysis_network.predict(\n",
    "    test_data=test_data, \n",
    "    metrics=[\"categorical_accuracy\"], \n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We also trained an even larger **2 billion parameter** model on a large text corpus to build an interactive sentiment analysis demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(Geordie): Add download scripts and change to relative path\n",
    "sentiment_analysis_network = bolt.Network.load(filename=\"interactive_demo_cp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's run this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import interactive_sentiment_analysis\n",
    "interactive_sentiment_analysis.demo(sentiment_analysis_network, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's talk speed. How much faster is BOLT compared to RoBERTa?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from transformers import pipeline\n",
    "sentiment_analysis = pipeline(\"sentiment-analysis\",model=\"siebert/sentiment-roberta-large-english\")\n",
    "t1 = time.time()\n",
    "out = sentiment_analysis(\"I love chocolate.\")\n",
    "t2 = time.time()\n",
    "print(out, flush=True)\n",
    "print('time elapsed: ',str(t2-t1),'s', flush=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
