{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using BOLT\n",
    "## Basics.\n",
    "Let's learn to use the BOLT Python API with an exercise. We'll do a simple image classification task on the MNIST dataset. Given 28 by 28 pixel images of handwritten numbers from 0 through 9, predict which number is being drawn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 60000 vectors from datasets/mnist/mnist in 1 seconds\n",
      "Read 10000 vectors from datasets/mnist/mnist.t in 0 seconds\n"
     ]
    }
   ],
   "source": [
    "# TODO(Geordie): Add download scripts and change to relative path\n",
    "from thirdai import dataset\n",
    "\n",
    "mnist_train = dataset.load_bolt_svm_dataset(\n",
    "    filename=\"datasets/mnist/mnist\", \n",
    "    batch_size=256)\n",
    "\n",
    "mnist_test = dataset.load_bolt_svm_dataset(\n",
    "    filename=\"datasets/mnist/mnist.t\", \n",
    "    batch_size=256)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform this task, we want to build a simple neural network with these specifications:\n",
    "* 784 (28 x 28) input dimension\n",
    "* A single 1000-dim hidden layer with ReLU\n",
    "* 10-dim output layer with Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "keras_layers = [\n",
    "    keras.layers.Dense(\n",
    "        units=1000, \n",
    "        activation='relu', \n",
    "        input_shape=(784,)),\n",
    "        \n",
    "    keras.layers.Dense(\n",
    "        units=10, \n",
    "        activation='softmax')\n",
    "]\n",
    "\n",
    "keras_model = keras.Sequential(layers=keras_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Building Fully Connected Network ======\n",
      "Layer: dim=1000, load_factor=1, act_func=ReLU\n",
      "Layer: dim=10, load_factor=1, act_func=Softmax\n",
      "Initialized Network in 0 seconds\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "from thirdai import bolt\n",
    "\n",
    "mnist_layers = [\n",
    "    bolt.LayerConfig(\n",
    "        dim=1000, \n",
    "        activation_function=bolt.ActivationFunctions.ReLU),\n",
    "    \n",
    "    bolt.LayerConfig(\n",
    "        dim=10, \n",
    "        activation_function=bolt.ActivationFunctions.Softmax)\n",
    "]\n",
    "\n",
    "mnist_network = bolt.Network(\n",
    "    layers=mnist_layers, \n",
    "    input_dim=784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now train the network to minimize categorical cross entropy loss and measure our success with the categorical accuracy metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1:\n",
      "[==================================================] 100%\n",
      "Processed 235 training batches in 3 seconds\n",
      "[==================================================] 100%\n",
      "Processed 40 test batches in 497 milliseconds\n",
      "Accuracy: 0.9535 (9535/10000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'test_time': [497.0], 'categorical_accuracy': [0.9535]},\n",
       " array([[1.6119853e-09, 4.9061071e-09, 9.0842747e-09, ..., 9.9999881e-01,\n",
       "         7.4112470e-12, 7.1178043e-08],\n",
       "        [7.8348904e-08, 4.7955339e-04, 7.8698450e-01, ..., 1.3695576e-07,\n",
       "         5.3275298e-06, 2.8925069e-07],\n",
       "        [9.4192680e-09, 9.9960941e-01, 9.1716443e-05, ..., 2.2237067e-04,\n",
       "         1.5032618e-05, 3.1097348e-05],\n",
       "        ...,\n",
       "        [2.6579289e-10, 1.1534446e-09, 7.5483649e-07, ..., 8.0246173e-05,\n",
       "         9.5714662e-05, 2.2119880e-03],\n",
       "        [6.5210443e-05, 3.2664754e-08, 7.9705176e-09, ..., 8.9524441e-08,\n",
       "         5.7288981e-04, 1.3805798e-08],\n",
       "        [4.6801352e-07, 1.0962963e-11, 1.6620123e-06, ..., 2.0000725e-11,\n",
       "         1.0412909e-09, 7.2178027e-11]], dtype=float32))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_network.train(\n",
    "    train_data=mnist_train, \n",
    "    loss_fn=bolt.CategoricalCrossEntropyLoss(), \n",
    "    learning_rate=0.001, \n",
    "    epochs=1)\n",
    "\n",
    "mnist_network.predict(\n",
    "    test_data=mnist_test, \n",
    "    metrics=[\"categorical_accuracy\"], \n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What about bigger models?\n",
    "One example of a more complicated task that requires a larger network is intent classification. To demonstrate that, we have chosen the CLINC150 dataset. It's a corpus of customer queries mapped to their intentions. For example, the dataset may have a query like \"do I have to pay for carry-ons on delta?\", and this query is assigned an intent id, so in this case the intent is \"carry-on\" and it has a unique id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(Geordie): Add download scripts and change to relative path\n",
    "intent_class_train = dataset.load_bolt_svm_dataset(\n",
    "    filename=\"datasets/intent_classification/train_shuf.svm\", \n",
    "    batch_size=256)\n",
    "\n",
    "intent_class_test = dataset.load_bolt_svm_dataset(\n",
    "    filename=\"datasets/intent_classification/test_shuf.svm\", \n",
    "    batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We converted the samples in this dataset into 5000 dimensional sparse input vectors and we'll use 10000 hidden layer. That's a 51 million parameter model so it's quite a big model. But with bolt we introduce a unique capability to set the load factor. The load factor defines the percentage of neurons that we want to use for each input sample. Here, we use 0.05 -> 500 neurons out of 10,000 for each input.\n",
    "\n",
    "And it's not just any 500 neurons. It's the 500 most important neurons for each input vector, so Bolt curates a small network for each input vector. This is the key to using powerful deep learning for very cheap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigger_layers = [\n",
    "    bolt.LayerConfig(\n",
    "        dim=10000, \n",
    "        load_factor=0.05, \n",
    "        activation_function=bolt.ActivationFunctions.ReLU),\n",
    "    \n",
    "    bolt.LayerConfig(\n",
    "        dim=151, \n",
    "        activation_function=bolt.ActivationFunctions.Softmax)\n",
    "]\n",
    "\n",
    "bigger_network = bolt.Network(\n",
    "    layers=bigger_layers, \n",
    "    input_dim=5512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse inference\n",
    "You can also use sparsity to accelerate inference. Simply call the `enable_sparse_inference()` method. Notice that we call the method before the last training epoch. This freezes the hash functions, effectively locking specialized subnetworks for each input vector, and then fine-tunes these subnetworks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigger_network.train(\n",
    "    train_data=intent_class_train, \n",
    "    loss_fn=bolt.CategoricalCrossEntropyLoss(), \n",
    "    learning_rate=0.001, \n",
    "    epochs=2)\n",
    "\n",
    "bigger_network.enable_sparse_inference()\n",
    "\n",
    "bigger_network.train(\n",
    "    train_data=intent_class_train, \n",
    "    loss_fn=bolt.CategoricalCrossEntropyLoss(), \n",
    "    learning_rate=0.001, \n",
    "    epochs=1)\n",
    "\n",
    "bigger_network.predict(\n",
    "    test_data=intent_class_test, \n",
    "    metrics=[\"categorical_accuracy\"], \n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What does this enable?\n",
    "We trained a 200 million parameter model on the Yelp Reviews public dataset. As a benchmark, we fine-tuned RoBERTa, the state-of-the-art NLP model, on this dataset and got an accuracy of 83%. Let's see how well BOLT does!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_sentiment_analysis_layers = [\n",
    "    \n",
    "    bolt.LayerConfig(dim=2000, \n",
    "        load_factor=0.2, \n",
    "        activation_function=bolt.ActivationFunctions.ReLU),\n",
    "    \n",
    "    bolt.LayerConfig(dim=2,\n",
    "        load_factor=1.0, \n",
    "        activation_function=bolt.ActivationFunctions.Softmax)     \n",
    "]\n",
    "\n",
    "yelp_sentiment_analysis_network = bolt.Network(\n",
    "    layers=yelp_sentiment_analysis_layers, \n",
    "    input_dim=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load & Save\n",
    "BOLT supports loading and saving networks from previous training sessions. \n",
    "\n",
    "To save, call the `save()` method on the trained network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(Geordie): Add download scripts and change to relative path\n",
    "train_data = dataset.load_bolt_svm_dataset(\n",
    "    filename=\"../sa_demo/text_data/yelp_review_full_2class_train.svm\", \n",
    "    batch_size=1024)\n",
    "\n",
    "yelp_sentiment_analysis_network.train(\n",
    "    train_data=train_data,\n",
    "    loss_fn=bolt.CategoricalCrossEntropyLoss(), \n",
    "    learning_rate=0.0001, \n",
    "    epochs=20, \n",
    "    rehash=6400, \n",
    "    rebuild=128000)\n",
    "\n",
    "yelp_sentiment_analysis_network.save(filename=\"yelp_sentiment_analysis_cp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load a trained model, call the `bolt.Network.load()` static method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/benito/Demos/bolt.ipynb Cell 17'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blocal3/home/benito/Demos/bolt.ipynb#ch0000016vscode-remote?line=0'>1</a>\u001b[0m \u001b[39m# TODO(Geordie): Add download scripts and change to relative path\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Blocal3/home/benito/Demos/bolt.ipynb#ch0000016vscode-remote?line=1'>2</a>\u001b[0m test_data \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mload_bolt_svm_dataset(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blocal3/home/benito/Demos/bolt.ipynb#ch0000016vscode-remote?line=2'>3</a>\u001b[0m     filename\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m../sa_demo/text_data/yelp_review_full_2class_test.svm\u001b[39m\u001b[39m\"\u001b[39m, \n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blocal3/home/benito/Demos/bolt.ipynb#ch0000016vscode-remote?line=3'>4</a>\u001b[0m     batch_size\u001b[39m=\u001b[39m\u001b[39m256\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blocal3/home/benito/Demos/bolt.ipynb#ch0000016vscode-remote?line=5'>6</a>\u001b[0m yelp_sentiment_analysis_network \u001b[39m=\u001b[39m bolt\u001b[39m.\u001b[39mNetwork\u001b[39m.\u001b[39mload(filename\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39myelp_sentiment_analysis_cp\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blocal3/home/benito/Demos/bolt.ipynb#ch0000016vscode-remote?line=7'>8</a>\u001b[0m res \u001b[39m=\u001b[39m yelp_sentiment_analysis_network\u001b[39m.\u001b[39mpredict(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blocal3/home/benito/Demos/bolt.ipynb#ch0000016vscode-remote?line=8'>9</a>\u001b[0m     test_data\u001b[39m=\u001b[39mtest_data, \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blocal3/home/benito/Demos/bolt.ipynb#ch0000016vscode-remote?line=9'>10</a>\u001b[0m     metrics\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mcategorical_accuracy\u001b[39m\u001b[39m\"\u001b[39m], \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blocal3/home/benito/Demos/bolt.ipynb#ch0000016vscode-remote?line=10'>11</a>\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "# TODO(Geordie): Add download scripts and change to relative path\n",
    "test_data = dataset.load_bolt_svm_dataset(\n",
    "    filename=\"../sa_demo/text_data/yelp_review_full_2class_test.svm\", \n",
    "    batch_size=256)\n",
    "\n",
    "yelp_sentiment_analysis_network = bolt.Network.load(filename=\"yelp_sentiment_analysis_cp\")\n",
    "\n",
    "res = yelp_sentiment_analysis_network.predict(\n",
    "    test_data=test_data, \n",
    "    metrics=[\"categorical_accuracy\"], \n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also trained an even larger 2 billion parameter model on a larger text corpus to build an interactive sentiment analysis demo. We first load the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(Geordie): Add download scripts and change to relative path\n",
    "sentiment_analysis_network = bolt.Network.load(filename=\"interactive_demo_cp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the demo to get a feel of what this network can do!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100%\n",
      "Processed 1 test batches in 18 milliseconds\n",
      "Accuracy: 0 (0/1)\n",
      "positive!\n",
      "[==================================================] 100%\n",
      "Processed 1 test batches in 6 milliseconds\n",
      "Accuracy: 0 (0/1)\n",
      "negative!\n",
      "[==================================================] 100%\n",
      "Processed 1 test batches in 9 milliseconds\n",
      "Accuracy: 0 (0/1)\n",
      "negative!\n",
      "[==================================================] 100%\n",
      "Processed 1 test batches in 9 milliseconds\n",
      "Accuracy: 0 (0/1)\n",
      "positive!\n",
      "Exiting demo...\n"
     ]
    }
   ],
   "source": [
    "import interactive_sentiment_analysis\n",
    "interactive_sentiment_analysis.demo(sentiment_analysis_network, verbose=False)\n",
    "# TODO(Geordie): Make the accuracy disappear when doing interactive demo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's talk speed.\n",
    "Now that we've seen how fast inference is on BOLT, let's compare it with RoBERTa by running the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from transformers import pipeline\n",
    "sentiment_analysis = pipeline(\"sentiment-analysis\",model=\"siebert/sentiment-roberta-large-english\")\n",
    "t1 = time.time()\n",
    "out = sentiment_analysis(\"I love chocolate.\")\n",
    "t2 = time.time()\n",
    "print(out, flush=True)\n",
    "print('time elapsed: ',str(t2-t1),'s', flush=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
