{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **BOLT Oracle**\n",
    "Oracle is all-purpose classifier for tabular datasets. In addition to learning from the columns of a single row, Oracle can make use of \"temporal context\". For example, if used to build a movie recommender, Oracle may use information about the last 5 movies that a user has watched to recommend the next movie. Similarly, if used to forecast the outcome of marketing campaigns, Oracle may use several months' worth of campaign history for each product to make better forecasts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **0. Install Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install thirdai\n",
    "!pip3 install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Dataset and Task**\n",
    "The code below downloads and cleans the Movielens1M dataset, which contains one million ratings given by 6,040 users to 3,706 movies. Each of the chronologically ordered rows consists of a user ID, a movie ID, a rating, and a timestamp. This makes it perfect for tasks like next item prediction; given a history of items that each user has interacted with, predict the item that each user will interact with next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thirdai import bolt\n",
    "import os\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "\n",
    "MOVIELENS_1M_URL = \"https://files.grouplens.org/datasets/movielens/ml-1m.zip\"\n",
    "\n",
    "ZIP = \"./movielens.zip\"\n",
    "DIR = \"./movielens\"\n",
    "RATINGS_FILE = DIR + \"/ml-1m/ratings.dat\"\n",
    "TRAIN_FILE = \"./movielens_train.csv\"\n",
    "TEST_FILE = \"./movielens_test.csv\"\n",
    "PREDICTION_FILE = \"./movielens_predictions.txt\"\n",
    "\n",
    "def download_movielens_1m_dataset():\n",
    "    if not os.path.exists(ZIP):\n",
    "        os.system(\n",
    "            f\"curl {MOVIELENS_1M_URL} --output {ZIP}\"\n",
    "        )\n",
    "\n",
    "    if not os.path.exists(DIR):\n",
    "        with zipfile.ZipFile(ZIP, 'r') as zip_ref:\n",
    "            zip_ref.extractall(DIR)\n",
    "\n",
    "def format_and_split_dataset():\n",
    "    if os.path.exists(TRAIN_FILE) and os.path.exists(TEST_FILE):\n",
    "        return\n",
    "\n",
    "    df = pd.read_csv(RATINGS_FILE, header=None, delimiter='::')\n",
    "    df.columns = [\"userId\", \"movieId\", \"rating\", \"timestamp\"]\n",
    "    print(\"Cleaned column names\")\n",
    "\n",
    "    # Convert timestamp from seconds since epoch to YYYY-MM-DD format.\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], unit='s')\n",
    "    print(\"Cleaned timestamp column\")\n",
    "\n",
    "    # For the next item prediction task, we move the last interaction\n",
    "    # of every user to the test set, and leave everything else in the\n",
    "    # train set.\n",
    "    df_test = (\n",
    "        df.groupby(\"userId\")\n",
    "            .apply(lambda dfg: dfg.sort_values(\"timestamp\").iloc[-1:])\n",
    "            .sort_values(\"timestamp\")\n",
    "    )\n",
    "    df_train = (\n",
    "        df.groupby(\"userId\")\n",
    "            .apply(lambda dfg: dfg.sort_values(\"timestamp\").iloc[:-1])\n",
    "            .sort_values(\"timestamp\")\n",
    "    )\n",
    "    print(\"Finished splitting into train and test sets\")\n",
    "\n",
    "    # Write to files\n",
    "    df_train.to_csv(TRAIN_FILE, index=False)\n",
    "    df_test.to_csv(TEST_FILE, index=False)\n",
    "    print(\"Finished writing to files\")\n",
    "\n",
    "download_movielens_1m_dataset()\n",
    "format_and_split_dataset()\n",
    "\n",
    "print(\"======== HEADER + FIRST 5 LINES ========\")\n",
    "lines_printed = 0\n",
    "for line in open(TRAIN_FILE):\n",
    "    print(line, end='')\n",
    "    lines_printed += 1\n",
    "    if lines_printed == 6:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Using Temporal Features**\n",
    "If the model learns from each user's entire history of interactions, the model will learn what each user is like *in general*, but the model will fail to capture what the user needs *at the moment*. In order to capture this context, we will specify \"temporal tracking features\". This allows the model to track the recent movies watched by each user and use this context to make better predictions. Let's run the following block of code and see how much improvement we get after just 3 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = bolt.Oracle(\n",
    "    data_types={\n",
    "        \"userId\": bolt.types.categorical(n_unique_classes=6040),\n",
    "        \"movieId\": bolt.types.categorical(n_unique_classes=3706),\n",
    "        \"timestamp\": bolt.types.date(),\n",
    "    },\n",
    "    temporal_tracking_relationships={\n",
    "        \"userId\": [\"movieId\"]\n",
    "    },\n",
    "    target=\"movieId\"\n",
    ")\n",
    "\n",
    "model.train(TRAIN_FILE, epochs=3, learning_rate=0.0001, metrics=[\"recall@10\"])\n",
    "model.evaluate(TEST_FILE, metrics=[\"recall@1\", \"recall@10\", \"recall@100\"], output_file=PREDICTION_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passing recent interactions to a deep learning model is not a new idea â€“ it is intuitive that a model can predict better when it knows the temporal context of the prediction. However, doing so in production requires significant investment in engineering the right data pipeline. With Oracle, you can just add one line in your python script to leverage an efficient data pipeline that pairs perfectly with our sparse deep learning engine. Furthermore, it can operate in a streaming fashion to fit your big data needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. More Results**\n",
    "We summarize our results on three datasets and compare them with the results we got from Tensorflow's two tower recommendation model. Note that the Movielens results are different from the above because we ran Oracle for more epochs in our benchmarks.\n",
    "\n",
    "|Dataset|Metric|Tensorflow Recommender|Oracle|\n",
    "| ----------- | ----------- | ----------- | ----------- |\n",
    "|Amazon Games|recall@1|0.00373|0.052|\n",
    "||recall@10|0.0501|0.133|\n",
    "||recall@100|0.138|0.329|\n",
    "|Movielens 1M|recall@1|0.0|0.054|\n",
    "||recall@10|0.00563|0.231|\n",
    "||recall@100|0.159|0.584|\n",
    "|Netflix 100M|recall@1|0.000444|0.01|\n",
    "||recall@10|0.00616|0.064|\n",
    "||recall@100|0.0682|0.267|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4. Load and Save**\n",
    "Like our other autoclassifiers, it is very easy to save an instance of Oracle and load it for inference later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"saved_model.seq\")\n",
    "loaded_model = bolt.Oracle.load(\"saved_model.seq\")\n",
    "loaded_model.evaluate(TEST_FILE, metrics=[\"recall@1\", \"recall@10\", \"recall@100\"], output_file=PREDICTION_FILE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "52b54101bd5542eeff946dfec5a0fb6655454559c99e355450360bbdf459e262"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
