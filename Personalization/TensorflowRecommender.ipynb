{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -q tensorflow-recommenders==0.7.0\n",
    "!pip3 install tensorflow==2.11.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "from tabnanny import verbose\n",
    "from typing import Dict, Text\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "\n",
    "class MovieLensModel(tfrs.Model):\n",
    "  # We derive from a custom base class to help reduce boilerplate. Under the hood,\n",
    "  # these are still plain Keras Models.\n",
    "\n",
    "  def __init__(\n",
    "      self,\n",
    "      user_model: tf.keras.Model,\n",
    "      movie_model: tf.keras.Model,\n",
    "      task: tfrs.tasks.Retrieval,\n",
    "      get_batch_users,\n",
    "      get_batch_movies):\n",
    "    super().__init__()\n",
    "\n",
    "    # Set up user and movie representations.\n",
    "    self.user_model = user_model\n",
    "    self.movie_model = movie_model\n",
    "\n",
    "    # Set up a retrieval task.\n",
    "    self.task = task\n",
    "\n",
    "    self.get_user = get_batch_users\n",
    "    self.get_movie = get_batch_movies\n",
    "\n",
    "  def compute_loss(self, features, training=False) -> tf.Tensor:\n",
    "    # Define how the loss is computed.\n",
    "\n",
    "    user_embeddings = self.user_model(self.get_user(features))\n",
    "    movie_embeddings = self.movie_model(self.get_movie(features))\n",
    "\n",
    "    return self.task(user_embeddings, movie_embeddings)\n",
    "\n",
    "class TFRecModel:\n",
    "    def __init__(\n",
    "        self,\n",
    "        user_ids_vocabulary,\n",
    "        movie_ids_vocabulary,\n",
    "        movie_ids_dataset,\n",
    "        get_batch_users,\n",
    "        get_batch_movies,\n",
    "        user_embedding_dim=64,\n",
    "        movie_embedding_dim=64,\n",
    "    ):\n",
    "        self._movie_ids_dataset = movie_ids_dataset\n",
    "        \n",
    "        self._user_model = tf.keras.Sequential([\n",
    "            user_ids_vocabulary,\n",
    "            tf.keras.layers.Embedding(\n",
    "                user_ids_vocabulary.vocabulary_size(), \n",
    "                user_embedding_dim)      \n",
    "        ])\n",
    "        \n",
    "        self._movie_model = tf.keras.Sequential([\n",
    "            tf.keras.layers.InputLayer(input_shape=[], dtype=tf.string),\n",
    "            movie_ids_vocabulary,\n",
    "            tf.keras.layers.Embedding(\n",
    "                movie_ids_vocabulary.vocabulary_size(), \n",
    "                movie_embedding_dim)\n",
    "        ])\n",
    "\n",
    "        self._task = tfrs.tasks.Retrieval(metrics=tfrs.metrics.FactorizedTopK(\n",
    "            self._movie_ids_dataset.batch(128).map(self._movie_model)\n",
    "          )\n",
    "        )\n",
    "\n",
    "        self._model = MovieLensModel(\n",
    "            user_model=self._user_model, \n",
    "            movie_model=self._movie_model, \n",
    "            task=self._task, \n",
    "            get_batch_users=get_batch_users, \n",
    "            get_batch_movies=get_batch_movies)\n",
    "\n",
    "        self._model.compile(optimizer=tf.keras.optimizers.Adagrad(0.5))\n",
    "\n",
    "    def train(\n",
    "        self, \n",
    "        batched_dataset,\n",
    "        epochs,\n",
    "    ):\n",
    "        self._model.fit(batched_dataset, epochs=epochs, verbose='1')\n",
    "    \n",
    "    def evaluate(\n",
    "        self,\n",
    "        user_ids,\n",
    "        actually_watched,\n",
    "        precision_at,\n",
    "    ):\n",
    "        index = tfrs.layers.factorized_top_k.BruteForce(self._user_model, k=max(precision_at))\n",
    "        index.index_from_dataset(\n",
    "            self._movie_ids_dataset.batch(100).map(lambda movie_id: (movie_id, self._movie_model(movie_id)))\n",
    "        )\n",
    "\n",
    "        _, recommendations = index(user_ids)\n",
    "\n",
    "        for k in precision_at:\n",
    "            rowwise_match_counts = self.get_rowwise_match_counts(recommendations[:, :k], actually_watched)\n",
    "            print(\"Recall at\", k, \"=\", self.recall_at_k(rowwise_match_counts, actually_watched))\n",
    "\n",
    "    \n",
    "    def get_rowwise_match_counts(self, recommendations, actually_watched):\n",
    "        def make_intersect_rec_actual(n_actual):\n",
    "            def intersect_rec_actual(matrix):\n",
    "                split_at = matrix.shape[0] - n_actual\n",
    "                recs, actuals = np.split(matrix, [split_at], axis=0)\n",
    "                intersection = np.intersect1d(recs, actuals)\n",
    "                return len(intersection)\n",
    "            return intersect_rec_actual\n",
    "\n",
    "        return np.apply_along_axis(\n",
    "            func1d=make_intersect_rec_actual(actually_watched.shape[1]), \n",
    "            axis=1, \n",
    "            arr=np.concatenate(\n",
    "                (recommendations, actually_watched), \n",
    "                axis=1)\n",
    "            )\n",
    "    \n",
    "    def precision_at_k(self, rowwise_match_counts, k):\n",
    "        n_rows = rowwise_match_counts.shape[0]\n",
    "        return np.sum(rowwise_match_counts) / (n_rows * k)\n",
    "\n",
    "    def recall_at_k(self, rowwise_match_counts, actually_watched):\n",
    "        [n_rows, n_cols] = actually_watched.shape\n",
    "        return np.sum(rowwise_match_counts) / (n_rows * n_cols)\n",
    "\n",
    "    def categorical_accuracy(self, rowwise_match_counts):\n",
    "        return np.sum(rowwise_match_counts > 0) / rowwise_match_counts.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adapting vocabularies...\n",
      "Finised adapting vocabularies...\n",
      "Epoch 1/3\n",
      "WARNING:tensorflow:From /home/benito/.local/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "Epoch 2/3\n",
      "Epoch 3/3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from thirdai.demos import download_movielens\n",
    "\n",
    "train_filename, test_filename, inference_batch, index_batch = download_movielens()\n",
    "\n",
    "\n",
    "train_file = train_filename\n",
    "test_file = test_filename\n",
    "\n",
    "train_df = pd.read_csv(train_file)[[\"userId\", \"movieTitle\"]].sample(frac=1) # .sample for shuffling\n",
    "train_users = train_df[\"userId\"]\n",
    "train_movies = train_df[\"movieTitle\"]\n",
    "train_tfds = tf.data.Dataset.from_tensor_slices((train_users, train_movies))\n",
    "\n",
    "test_df = pd.read_csv(test_file)[[\"userId\", \"movieTitle\"]]\n",
    "test_user_ids = np.array(test_df[\"userId\"])\n",
    "test_actually_watched = np.array(test_df[[\"movieTitle\"]])\n",
    "\n",
    "all_users = pd.concat([train_users, test_df[\"userId\"]]).unique()\n",
    "all_movies = pd.concat([train_movies, test_df[\"movieTitle\"]]).unique()\n",
    "movies_tfds = tf.data.Dataset.from_tensor_slices((all_movies, ))\n",
    "\n",
    "print(\"Adapting vocabularies...\")\n",
    "user_ids_vocabulary = tf.keras.layers.IntegerLookup(mask_token=None)\n",
    "user_ids_vocabulary.adapt(all_users)\n",
    "movie_ids_vocabulary = tf.keras.layers.StringLookup(mask_token=None)\n",
    "movie_ids_vocabulary.adapt(all_movies)\n",
    "print(\"Finised adapting vocabularies...\")\n",
    "\n",
    "model = TFRecModel(\n",
    "    user_ids_vocabulary=user_ids_vocabulary,\n",
    "    movie_ids_vocabulary=movie_ids_vocabulary,\n",
    "    movie_ids_dataset=movies_tfds,\n",
    "    get_batch_users=lambda batch: batch[0],\n",
    "    get_batch_movies=lambda batch: batch[1],\n",
    ")\n",
    "\n",
    "model.train(\n",
    "    batched_dataset=train_tfds.batch(2048),\n",
    "    epochs=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall at 1 = 2.999370132272223e-05\n",
      "Recall at 10 = 0.0016696493736315374\n",
      "Recall at 100 = 0.0398016416552524\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(\n",
    "    user_ids=test_user_ids,\n",
    "    actually_watched=tf.convert_to_tensor(test_actually_watched),\n",
    "    precision_at=[1, 10, 100],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
