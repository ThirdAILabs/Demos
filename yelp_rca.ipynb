{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train_file = \"/share/shubh/data/yelp_polarity/train_yelp.csv\"\n",
    "text_test_file = \"/share/shubh/data/yelp_polarity/test_yelp.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training a text classifier using Universal Deep Transformers is just a few lines of code.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================= Bolt Model =======================\n",
      "input_1 (Input): dim=200000\n",
      "input_1 -> fc_1 (FullyConnected): dim=512, sparsity=1, act_func=ReLU\n",
      "fc_1 -> fc_2 (FullyConnected): dim=2, sparsity=1, act_func=Softmax\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from thirdai import bolt\n",
    "\n",
    "text_model = bolt.UniversalDeepTransformer(\n",
    "    data_types={\n",
    "        \"text\": bolt.types.text(),\n",
    "        \"category\": bolt.types.categorical(n_unique_classes=2)\n",
    "    },\n",
    "    target=\"category\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will be training a model that has more than 100M parameters on an M1 under 10mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading vectors from './yelp_polarity/train_yelp.csv'\n",
      "Loaded 560000 vectors from './yelp_polarity/train_yelp.csv' in 10 seconds.\n",
      "train epoch 0:\n",
      "\n",
      "[==================================================] 100%\n",
      "\n",
      "train | epoch 0 | updates 274 | {categorical_accuracy: 0.913309} | batches 274 | time 222s | complete\n",
      "\n",
      "train epoch 1:\n",
      "\n",
      "[==================================================] 100%\n",
      "\n",
      "train | epoch 1 | updates 548 | {categorical_accuracy: 0.961759} | batches 274 | time 231s | complete\n",
      "\n",
      "train epoch 2:\n",
      "\n",
      "[==================================================] 100%\n",
      "\n",
      "train | epoch 2 | updates 822 | {categorical_accuracy: 0.974805} | batches 274 | time 210s | complete\n",
      "\n",
      "train epoch 3:\n",
      "\n",
      "[==================================================] 100%=================================   ] 93%\n",
      "\n",
      "train | epoch 3 | updates 1096 | {categorical_accuracy: 0.982463} | batches 274 | time 194s | complete\n",
      "\n",
      "train epoch 4:\n",
      "\n",
      "[==============================                    ] 59%"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[8.90052259e-01, 1.09947614e-01],\n",
       "       [9.95818436e-01, 4.18142136e-03],\n",
       "       [1.21686628e-06, 9.99998689e-01],\n",
       "       ...,\n",
       "       [9.99999762e-01, 1.74599634e-07],\n",
       "       [9.99999881e-01, 5.80643589e-10],\n",
       "       [9.99999881e-01, 5.16755847e-08]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100%\n",
      "\n",
      "train | epoch 4 | updates 1370 | {categorical_accuracy: 0.989852} | batches 274 | time 214s | complete\n",
      "\n",
      "Loading vectors from './yelp_polarity/test_yelp.csv'\n",
      "Loaded 38000 vectors from './yelp_polarity/test_yelp.csv' in 0 seconds.\n",
      "test:\n",
      "\n",
      "[==================================================] 100%\n",
      "\n",
      "predict | epoch 5 | updates 1370 | {categorical_accuracy: 0.919342} | batches 19 | time 8175ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_config = (bolt.TrainConfig(epochs=5, learning_rate=0.01)\n",
    "                    .with_metrics([\"categorical_accuracy\"]))\n",
    "\n",
    "text_model.train(text_train_file, train_config)\n",
    "\n",
    "test_config = (bolt.EvalConfig()\n",
    "                   .with_metrics([\"categorical_accuracy\"]))\n",
    "\n",
    "text_model.evaluate(text_test_file, test_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_model.save(\"yelp_udt.bolt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_sample={\"text\":\"Everyone said that Nobu is bad but nothing could be further away from the truth\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Machine learning models sometimes feel like a black box where it becomes very hard to gauge into how the model make decisions about the input data points. Our explainability module lifts the curtain over predictions and offers you deeper insights into how the decision process of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.998505   0.00149496]\n",
      "column_name: \"text\" | keyword: \"nothing\" | percentage_significance: 16.2851\n"
     ]
    }
   ],
   "source": [
    "predicted_class=text_model.predict(inference_sample)\n",
    "print(predicted_class)\n",
    "\n",
    "explanations=text_model.explain(inference_sample)\n",
    "print(explanations[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the word \"nothing\" has the highest significance.\n",
    "\n",
    "Not only can we get insights the predictions of the model, but also how to change the datapoint to get the desired output. By specifying a target, we can find out what columns should be changed to get the desired output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column_name: \"text\" | keyword: \"underwhelming\" | percentage_significance: -55.5133\n"
     ]
    }
   ],
   "source": [
    "inference_sample={\"text\":\"Nobu is an underwhelming restaurant\"}\n",
    "explanations=text_model.explain(inference_sample, target_class=\"1\")\n",
    "print(explanations[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "50292dbb1f747f7151d445135d392af3138fb3c65386d17d9510cb605222b10b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
