{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Real-Time Query Reformulation a.k.a Query Correction using the UniversalDeepTransformer API\n",
    "\n",
    "This notebook shows how to build a query reformulation model with ThirdAI's Universal Deep Transformer (UDT) model, our all-purpose solution for classification tasks on tabular datasets and query reformulation. In this demo, we will train and evaluate the model on a spelling correction dataset and show less than 5ms P99.9 inference latency.\n",
    "\n",
    "You can immediately run a version of this notebook in your browser on Google Colab at the following link:\n",
    "\n",
    "https://githubtocolab.com/ThirdAILabs/Demos/blob/main/QueryReformulation.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install datasets==2.6.2\n",
    "!pip3 install gradio\n",
    "!pip3 install thirdai --upgrade"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses an activation key that will only work with this demo. If you want to try us out on your own dataset, you can obtain a free trial license at the following link: https://www.thirdai.com/try-bolt/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'thirdai.licensing' has no attribute 'activate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mthirdai\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m thirdai\u001b[39m.\u001b[39;49mlicensing\u001b[39m.\u001b[39;49mactivate(\u001b[39m\"\u001b[39m\u001b[39mAWK9-WPMK-3NRE-AAAV-C39P-N9JV-43VC-CFUH\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'thirdai.licensing' has no attribute 'activate'"
     ]
    }
   ],
   "source": [
    "import thirdai\n",
    "thirdai.licensing.activate(\"AWK9-WPMK-3NRE-AAAV-C39P-N9JV-43VC-CFUH\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Download\n",
    "\n",
    "We will use the demos module in the ThirdAI repo to download and pre-process a dataset from HuggingFace. The dataset we will use from HuggingFace is typically used for semantic sentence similarity. We will pre-process it by adding noise so that it is suitable for query reformulation. You can replace this step and the next with a UDT initialization that is specific for your dataset - as long as your train dataset consists of **CSV files with two string columns**: The first one should be incorrect queries and the second column will be their target reformulations.  The incorrect queries column can be empty strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration embedding-data--sentence-compression-d643585deb6e0073\n",
      "Found cached dataset json (/Users/nmeisburger/.cache/huggingface/datasets/embedding-data___json/embedding-data--sentence-compression-d643585deb6e0073/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "425ff4f6e2074585bd9b04f2d9ec8d29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from thirdai.demos import prepare_query_reformulation_data\n",
    "\n",
    "train_filename, test_filename, inference_batch = prepare_query_reformulation_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UDT Initialization\n",
    "\n",
    "We can create a UDT model specific for query reformulation by specifying the name of the source column (optional, column containing queries to be reformulated) and the name of the target column (correct reformulations) and a dataset size parameter. The size of the input dataset can be configured to be either \"small\" (size < 1M), \"medium\"(size < 10M) or \"large\" (size >= 10M). We configure different model parameters depending on the size of the input dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thirdai import bolt\n",
    "\n",
    "model = bolt.UniversalDeepTransformer(\n",
    "    source_column=\"source_queries\", target_column=\"target_queries\", dataset_size=\"medium\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "We can now train our model in just one line of code. You just have to specify the path to the training file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data | source 'train_file.csv'\n",
      "loaded data | source 'train_file.csv' | vectors 900000 | batches 90 | time 3s | complete\n",
      "\n",
      "train | time 43s | complete                                             \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.train(filename=train_filename) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation \n",
    "\n",
    "Evaluating the UDT model is also just one line of code. Since this UDT model is specific for query reformulation, you need to provide the number of suggested candidate queries that the UDT model generates. For instance, if you want to see the top 5 suggested query reformulations of the input query, set the `top_k` parameter to 5. Evaluating this model will also display and return the recall @k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data | source 'test_file.csv'\n",
      "loaded data | source 'test_file.csv' | vectors 270000 | batches 27 | time 1s | complete\n",
      "\n",
      "evaluate | recall=0.88735557 | time 11s | complete                         \n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics = model.evaluate(filename=test_filename, top_k=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Loading\n",
    "\n",
    "Saving and loading a trained UDT model to disk is also extremely straight forward. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_location = \"query_reformulation.model\"\n",
    "\n",
    "# Saving\n",
    "model.save(filename=model_location)\n",
    "\n",
    "# Loading\n",
    "model = bolt.UniversalDeepTransformer.load(model_location)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Predictions \n",
    "\n",
    "The evaluation method is great for testing, but it requires labels, which don't exist in a production environment. We also provide a predict method that can take a list of queries or a single query, which allows for easy integration into production pipelines. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_batch(samples=inference_batch, top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['Health officials issue red air quality alert',\n",
       "   'I was born to entertain:',\n",
       "   'Ahs lifts air quality advisory',\n",
       "   'CLARCOR declares regular quarterly dividend',\n",
       "   'Air quality improves']],\n",
       " [[0.3125, 0.21875, 0.1484375, 0.1328125, 0.125]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(sample={\"phrase\": \"Health iiaclfsfo susei der air quality alert\"}, top_k=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## UI for interaction with model using Gradio\n",
    "\n",
    "A gradio based ui for going over model inference. Click on the link generated after running this cell, app will be hosted locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def generate(text, top_k):\n",
    "    result = model.predict(sample={\"phrase\": text}, top_k=top_k)\n",
    "    return pd.DataFrame(data=result[0][0], columns=[\"Queries\"])\n",
    "\n",
    "\n",
    "examples = [\n",
    "    [\"Health iiaclfsfo susei der air quality alert\"],\n",
    "    [\"Havy rains hae Mumabai\"],\n",
    "]\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=generate,\n",
    "    inputs=[gr.inputs.Textbox(lines=1, label=\"Input Query\"), gr.Slider(2, 10, step=1)],\n",
    "    outputs=gr.DataFrame(label=\"Reformulated Query\"),\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
