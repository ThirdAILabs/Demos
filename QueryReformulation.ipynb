{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Query Reformulation using the UniversalDeepTransformer API\n",
    "\n",
    "This notebook shows how to build a query reformulation model with ThirdAI's Universal Deep Transformer (UDT) model, our all-purpose API for classification tasks on tabular datasets and query reformulation. In this demo, we will train and evaluate the model on a spelling correction dataset.\n",
    "\n",
    "To run this notebook, you will need to obtain a ThirdAI license at the following link if you have not already: https://www.thirdai.com/try-bolt/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install thirdai==0.5.4\n",
    "!pip3 install pandas\n",
    "!pip3 install numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Download\n",
    "\n",
    "We will use the utils module in this repository to download and pre-process a dataset from HuggingFace. The dataset we will use from HuggingFace is typically used for semantic sentence similarity. We will pre-process it by adding noise so that it is suitable for query reformulation. You can replace this step and the next with a UDT initialization that is specific for your dataset - as long as your input dataset consists of a column with incorrect queries and a column with their target reformulations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import QueryReformulationDataProcessor\n",
    "import pandas as pd\n",
    "\n",
    "TRAIN_FILE_PATH = \"queries.csv\"\n",
    "\n",
    "data_processor = QueryReformulationDataProcessor(\n",
    "    dataset_name=\"embedding-data/sentence-compression\"\n",
    ")\n",
    "\n",
    "# The perturbed dataset consists of one column with incorrect queries\n",
    "# formed by adding noise to the original text.\n",
    "perturbed_dataset = data_processor.perturb_dataset()\n",
    "\n",
    "# Add file header since the \"train\" and \"evaluate\" methods assume the\n",
    "# input CSV file has a header.\n",
    "perturbed_dataset.columns = [\"target_column\", \"source_column\"]\n",
    "perturbed_dataset.to_csv(TRAIN_FILE_PATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perturbed_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UDT Initialization\n",
    "\n",
    "We can create a UDT model specific for query reformulation by specifying the name of the source column (column containing queries to be reformulated) and the name of the target column (correct reformulations) and a dataset size parameter. The size of the input dataset can be configured to be either \"small\", \"medium\" or \"large\". We configure different model parameters depending on the size of the input dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thirdai import bolt\n",
    "\n",
    "model = bolt.UniversalDeepTransformer(\n",
    "    source_column=\"source_column\", target_column=\"target_column\", dataset_size=\"medium\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "We can now train our model in just one line of code. You just have to specify the path to the training file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(filename=TRAIN_FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation \n",
    "\n",
    "Evaluating the UDT model is also just one line of code. Since this UDT model is specific for query reformulation, you need to provide the number of suggested candidate queries that the UDT model generates. For instance, if you want to see the top 10 suggested query reformulations of the input query, set the top_k parameter to 10. Evaluating this model will also print out recall @k. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_reformulations = model.evaluate(filename=TRAIN_FILE_PATH, top_k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Loading\n",
    "\n",
    "Saving and loading a trained UDT model to disk is also extremely straight forward. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_location = \"query_reformulation.model\"\n",
    "\n",
    "# Saving\n",
    "model.save(model_location = \"query_reformulation.model\"\n",
    ")\n",
    "\n",
    "# Loading\n",
    "model = bolt.UniversalDeepTransformer.load(model_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Predictions \n",
    "\n",
    "The evaluation method is great for testing, but it requires labels, which don't exist in a production environment. We also provide a predict method that can take a list of queries or a single query, which allows for easy integration into production pipelines. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_queries_list = [\n",
    "    \"ehT Beatles almost dformde while they were all still elive\",\n",
    "    \"Muslim poplatio to growe at twice the rate\",\n",
    "    \"Pakintan begins predesential poll process\"\n",
    "]\n",
    "predictions = model.predict_batch(queries=incorrect_queries_list, top_k=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the created training file\n",
    "import os\n",
    "\n",
    "os.remove(TRAIN_FILE_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('3.9.5')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c8573aafd228246904de159cbac3e8b63355dc71223fe3e3d5cbf4d60497d6ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
