{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Real-Time Query Reformulation a.k.a Query Correction using the UniversalDeepTransformer API\n",
    "\n",
    "This notebook shows how to build a query reformulation model with ThirdAI's Universal Deep Transformer (UDT) model, our all-purpose solution for classification tasks on tabular datasets and query reformulation. In this demo, we will train and evaluate the model on a spelling correction dataset and show less than 5ms P99.9 inference latency.\n",
    "\n",
    "You can immediately run a version of this notebook in your browser on Google Colab at the following link:\n",
    "\n",
    "https://githubtocolab.com/ThirdAILabs/Demos/blob/main/QueryReformulation.ipynb\n",
    "\n",
    "This notebook uses an activation key that will only work with this demo. If you want to try us out on your own dataset, you can obtain a free trial license at the following link: https://www.thirdai.com/try-bolt/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install datasets==2.6.1 \n",
    "# !pip3 install thirdai --upgrade\n",
    "\n",
    "import thirdai\n",
    "# thirdai.activate(\"AWK9-WPMK-3NRE-AAAV-C39P-N9JV-43VC-CFUH\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Download\n",
    "\n",
    "We will use the demos module in the ThirdAI repo to download and pre-process a dataset from HuggingFace. The dataset we will use from HuggingFace is typically used for semantic sentence similarity. We will pre-process it by adding noise so that it is suitable for query reformulation. You can replace this step and the next with a UDT initialization that is specific for your dataset - as long as your train dataset consists of **CSV files with two string columns**: The first one should be incorrect queries and the second column will be their target reformulations.  The incorrect queries column can be empty strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration embedding-data--sentence-compression-d643585deb6e0073\n",
      "Reusing dataset json (/Users/shubh/.cache/huggingface/datasets/embedding-data___json/embedding-data--sentence-compression-d643585deb6e0073/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253)\n",
      "100%|██████████| 1/1 [00:00<00:00, 14.53it/s]\n"
     ]
    }
   ],
   "source": [
    "from thirdai.demos import prepare_query_reformulation_data\n",
    "import pandas\n",
    "\n",
    "supervised_train_filename, unsupervised_train_filename, test_filename, inference_batch = prepare_query_reformulation_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UDT Initialization\n",
    "\n",
    "We can create a UDT model specific for query reformulation by specifying the name of the source column (column containing queries to be reformulated) and the name of the target column (correct reformulations) and a dataset size parameter. The size of the input dataset can be configured to be either \"small\" (size < 1M), \"medium\"(size < 10M) or \"large\" (size >= 10M). We configure different model parameters depending on the size of the input dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thirdai import bolt\n",
    "\n",
    "model = bolt.UniversalDeepTransformer(\n",
    "    source_column=\"source_queries\", target_column=\"target_queries\", dataset_size=\"medium\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "We can now train our model in just one line of code. You just have to specify the path to the training file. \n",
    "You can train the model in both **supervised** and **unsupervised** setting. When training the model in an unsupervised setting, only the target column is needed in the training file. \n",
    "\n",
    "*supervised_train_filename* has two columns `target_queries,source_queries` whereas *unsupervised_train_filename* has only `target_queries`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data | source 'supervised_train_file.csv'\n",
      "loading data | source 'supervised_train_file.csv' | vectors 900000 | batches 90 | time 4s | complete\n",
      "\n",
      "train | batches 90 | complete                                           \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# supervised training\n",
    "model.train(filename=supervised_train_filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data | source 'unsupervised_train_file.csv'\n",
      "loading data | source 'unsupervised_train_file.csv' | vectors 900000 | batches 90 | time 3s | complete\n",
      "\n",
      "train | batches 90 | complete                                           \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unsupervised training\n",
    "model.train(filename=unsupervised_train_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation \n",
    "\n",
    "Evaluating the UDT model is also just one line of code. Since this UDT model is specific for query reformulation, you need to provide the number of suggested candidate queries that the UDT model generates. For instance, if you want to see the top 10 suggested query reformulations of the input query, set the top_k parameter to 10. Evaluating this model will also print out recall @k. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data | source 'test_file.csv'\n",
      "loading data | source 'test_file.csv' | vectors 270000 | batches 27 | time 1s | complete\n",
      "\n",
      "evaluate | batches 27 | complete                                           \n",
      "\n",
      "Recall@5 = 0.88363\n"
     ]
    }
   ],
   "source": [
    "query_reformulations, = model.evaluate(filename=test_filename, top_k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Loading\n",
    "\n",
    "Saving and loading a trained UDT model to disk is also extremely straight forward. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_location = \"query_reformulation.model\"\n",
    "\n",
    "# Saving\n",
    "model.save(filename=model_location)\n",
    "\n",
    "# Loading\n",
    "model = bolt.UniversalDeepTransformer.load(model_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Predictions \n",
    "\n",
    "The evaluation method is great for testing, but it requires labels, which don't exist in a production environment. We also provide a predict method that can take a list of queries or a single query, which allows for easy integration into production pipelines. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, = model.predict_batch(queries=inference_batch, top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['Health officials issue red air quality alert',\n",
       "   'Air quality officials issue health notice',\n",
       "   'Air quality alert issued for Friday',\n",
       "   'Wife of Shane Osborn files for protection order',\n",
       "   'Apple sells $17 billion in bonds in record deal']],)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(query=\"Health iiaclfsfo susei der air quality alert\", top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "50292dbb1f747f7151d445135d392af3138fb3c65386d17d9510cb605222b10b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
