{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Click-Through Prediction with ThirdAI's Universal Deep Transformer\n",
    "\n",
    "This notebook shows how to build a Click-Through Prediction model with ThirdAI's\n",
    "Universal Deep Transformer (UDT), our all-purpose classifier for a multitude of problems.\n",
    "In this demo, we will train and evaluate the model on the Kaggle Display Advertising (Criteo) dataset, \n",
    "but you can easily replace this with your own dataset.\n",
    "\n",
    "To run this notebook, you will need to obtain a ThirdAI license at the following link if you have not already:\n",
    "https://www.thirdai.com/try-bolt/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install thirdai==0.5.1\n",
    "!pip3 install pandas # We need Pandas in the utils module to convert downloaded datasets to CSV format\n",
    "!pip3 install numpy # We use numpy to analyze UDT performance in this notebook\n",
    "!pip3 install sklearn # We use sklearn to analyze UDT performance (calculate AUC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Download\n",
    "\n",
    "We will use the utils module in this repo to download the Kaggle Display Advertising dataset (if you have just copied this notebook and not cloned the entire repo, you will need to copy the utils.py file as well). You can replace \n",
    "this step with your own downloader and preprocessor that is specific to your dataset. The file that you pass into the UDT's train and evaluate methods have to be in CSV format with a header that has all column names.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "(\n",
    "    train_filename,\n",
    "    test_filename,\n",
    "    y_train,\n",
    "    y_test,\n",
    "    min_vals_of_numeric_cols,\n",
    "    max_vals_of_numeric_cols,\n",
    "    n_unique_classes,\n",
    "    sample_batch,\n",
    ") = utils.download_criteo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UDT Initilization\n",
    "\n",
    "We can now create a UDT model by passing in the types of each column in the dataset\n",
    "and the target column we want to be able to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thirdai import bolt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "columns = {}\n",
    "\n",
    "# Add numerical columns\n",
    "for i in range(1, 14):\n",
    "    columns[f\"num_{i}\"] = bolt.types.numerical(\n",
    "        range=(min_vals_of_numeric_cols[i - 1], max_vals_of_numeric_cols[i - 1])\n",
    "    )\n",
    "\n",
    "# Add categorical columns\n",
    "for i in range(1, 27):\n",
    "    columns[f\"cat_{i}\"] = bolt.types.categorical(\n",
    "        n_unique_classes=n_unique_classes[i - 1]\n",
    "    )\n",
    "\n",
    "# Add label column\n",
    "columns[\"label\"] = bolt.types.categorical(n_unique_classes=2)\n",
    "\n",
    "# Define UDT\n",
    "model = bolt.UniversalDeepTransformer(columns, target=\"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "We can now train our UDT model with just two lines! You can customize the\n",
    "number of epochs and the learning rate through the *train_config* object. If you do not give any train_config, the *train()* method will auto-tune the best *train_config*.\n",
    "\n",
    "This task has N=40M examples and is thus a reasonably large problem. As such, depending on how powerful your machine is it may take an hour or more to train (a typical 16 core machine on AWS will take around 15 minutes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = bolt.TrainConfig(epochs=1, learning_rate=0.001)\n",
    "\n",
    "model.train(train_filename, train_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "Evaluating the performance of the UDT model is also just two lines! For this specific application, AUC is the preferred metric. We will first get the activations and then compute the AUC.\n",
    "\n",
    "This task again may take a while because of the size of the test dataset. We expect it to take about 10% as much time as the training step above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_config = bolt.EvalConfig().return_activations()\n",
    "\n",
    "activations = model.evaluate(test_filename, eval_config)\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, activations[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and Loading\n",
    "\n",
    "Saving and loading a trained UDT model to disk is also extremely straight forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_location = \"click_through.model\"\n",
    "\n",
    "# Saving\n",
    "model.save(save_location)\n",
    "\n",
    "# Loading\n",
    "model = bolt.UniversalDeepTransformer.load(save_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Predictions\n",
    "\n",
    "The evaluation method is great for testing, but it requires labels, which don't\n",
    "exist in a production setting. We also have a predict method that can take in an \n",
    "in-memory batch of rows or a single row (without the target column), allowing \n",
    "easy integration into production pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(sample_batch[0])\n",
    "\n",
    "prediction = model.predict(sample_batch[0])\n",
    "\n",
    "print(\"Predicted class:\", np.argmax(prediction))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
