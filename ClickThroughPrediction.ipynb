{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criteo Click Through Prediction using ThirdAI's Universal Deep Transformer(UDT) APIs\n",
    "This notebook shows how to build a Click Through Prediction model using ThirdAI's UDT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: thirdai in /home/pratik/.local/lib/python3.8/site-packages (0.5.10)\n",
      "Requirement already satisfied, skipping upgrade: pandas>=1.2.0 in /home/pratik/.local/lib/python3.8/site-packages (from thirdai) (1.5.2)\n",
      "Requirement already satisfied, skipping upgrade: typing-extensions in /home/pratik/.local/lib/python3.8/site-packages (from thirdai) (4.4.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy in /home/pratik/.local/lib/python3.8/site-packages (from thirdai) (1.23.5)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2020.1 in /home/pratik/.local/lib/python3.8/site-packages (from pandas>=1.2.0->thirdai) (2022.6)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.8.1 in /home/pratik/.local/lib/python3.8/site-packages (from pandas>=1.2.0->thirdai) (2.8.2)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in /home/pratik/.local/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas>=1.2.0->thirdai) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install thirdai --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and Process Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now create a sample dataset for training. Criteo-Click Logs dataset can be downloaded from https://ailab.criteo.com. Once datasets are downloaded convert the datasets into csv format. \n",
    "\n",
    "Column headers: `<label>` is titled as `<label>`, `<integer feature 1>` is titled as `numeric_1` and `<categorical feature 1>` as `cat_1`\n",
    "\n",
    "<span style=\"color:red\">Disclaimer: Remember that the following model is trained on sample data, to achieve better AUC train on the original criteo-dataset.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>numeric_1</th>\n",
       "      <th>numeric_2</th>\n",
       "      <th>numeric_3</th>\n",
       "      <th>numeric_4</th>\n",
       "      <th>numeric_5</th>\n",
       "      <th>numeric_6</th>\n",
       "      <th>numeric_7</th>\n",
       "      <th>numeric_8</th>\n",
       "      <th>numeric_9</th>\n",
       "      <th>...</th>\n",
       "      <th>cat_17</th>\n",
       "      <th>cat_18</th>\n",
       "      <th>cat_19</th>\n",
       "      <th>cat_20</th>\n",
       "      <th>cat_21</th>\n",
       "      <th>cat_22</th>\n",
       "      <th>cat_23</th>\n",
       "      <th>cat_24</th>\n",
       "      <th>cat_25</th>\n",
       "      <th>cat_26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>592</td>\n",
       "      <td>705</td>\n",
       "      <td>105</td>\n",
       "      <td>753</td>\n",
       "      <td>1237</td>\n",
       "      <td>1010</td>\n",
       "      <td>594</td>\n",
       "      <td>1343</td>\n",
       "      <td>276</td>\n",
       "      <td>...</td>\n",
       "      <td>4768</td>\n",
       "      <td>9631</td>\n",
       "      <td>9205</td>\n",
       "      <td>5841</td>\n",
       "      <td>744</td>\n",
       "      <td>5123</td>\n",
       "      <td>7816</td>\n",
       "      <td>8312</td>\n",
       "      <td>2153</td>\n",
       "      <td>7272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>314</td>\n",
       "      <td>1160</td>\n",
       "      <td>1269</td>\n",
       "      <td>1004</td>\n",
       "      <td>1317</td>\n",
       "      <td>546</td>\n",
       "      <td>193</td>\n",
       "      <td>223</td>\n",
       "      <td>...</td>\n",
       "      <td>9387</td>\n",
       "      <td>6668</td>\n",
       "      <td>3496</td>\n",
       "      <td>3965</td>\n",
       "      <td>7090</td>\n",
       "      <td>7440</td>\n",
       "      <td>1256</td>\n",
       "      <td>9550</td>\n",
       "      <td>5252</td>\n",
       "      <td>8862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1432</td>\n",
       "      <td>1115</td>\n",
       "      <td>898</td>\n",
       "      <td>1204</td>\n",
       "      <td>233</td>\n",
       "      <td>596</td>\n",
       "      <td>771</td>\n",
       "      <td>359</td>\n",
       "      <td>153</td>\n",
       "      <td>...</td>\n",
       "      <td>3222</td>\n",
       "      <td>4999</td>\n",
       "      <td>9008</td>\n",
       "      <td>3040</td>\n",
       "      <td>4554</td>\n",
       "      <td>9367</td>\n",
       "      <td>6920</td>\n",
       "      <td>4470</td>\n",
       "      <td>370</td>\n",
       "      <td>530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1113</td>\n",
       "      <td>449</td>\n",
       "      <td>139</td>\n",
       "      <td>537</td>\n",
       "      <td>597</td>\n",
       "      <td>101</td>\n",
       "      <td>1103</td>\n",
       "      <td>786</td>\n",
       "      <td>114</td>\n",
       "      <td>...</td>\n",
       "      <td>870</td>\n",
       "      <td>7576</td>\n",
       "      <td>1388</td>\n",
       "      <td>203</td>\n",
       "      <td>2006</td>\n",
       "      <td>5484</td>\n",
       "      <td>658</td>\n",
       "      <td>8703</td>\n",
       "      <td>5885</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1496</td>\n",
       "      <td>732</td>\n",
       "      <td>408</td>\n",
       "      <td>845</td>\n",
       "      <td>232</td>\n",
       "      <td>762</td>\n",
       "      <td>85</td>\n",
       "      <td>108</td>\n",
       "      <td>208</td>\n",
       "      <td>...</td>\n",
       "      <td>6863</td>\n",
       "      <td>9594</td>\n",
       "      <td>2187</td>\n",
       "      <td>6210</td>\n",
       "      <td>2807</td>\n",
       "      <td>8295</td>\n",
       "      <td>7723</td>\n",
       "      <td>9145</td>\n",
       "      <td>1024</td>\n",
       "      <td>7033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1262</td>\n",
       "      <td>887</td>\n",
       "      <td>779</td>\n",
       "      <td>537</td>\n",
       "      <td>282</td>\n",
       "      <td>480</td>\n",
       "      <td>422</td>\n",
       "      <td>808</td>\n",
       "      <td>951</td>\n",
       "      <td>...</td>\n",
       "      <td>3472</td>\n",
       "      <td>6151</td>\n",
       "      <td>7603</td>\n",
       "      <td>2362</td>\n",
       "      <td>1254</td>\n",
       "      <td>419</td>\n",
       "      <td>3398</td>\n",
       "      <td>8524</td>\n",
       "      <td>1310</td>\n",
       "      <td>458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>534</td>\n",
       "      <td>17</td>\n",
       "      <td>1264</td>\n",
       "      <td>126</td>\n",
       "      <td>498</td>\n",
       "      <td>1497</td>\n",
       "      <td>232</td>\n",
       "      <td>771</td>\n",
       "      <td>927</td>\n",
       "      <td>...</td>\n",
       "      <td>2699</td>\n",
       "      <td>9719</td>\n",
       "      <td>2718</td>\n",
       "      <td>8249</td>\n",
       "      <td>8956</td>\n",
       "      <td>8826</td>\n",
       "      <td>629</td>\n",
       "      <td>4285</td>\n",
       "      <td>3106</td>\n",
       "      <td>7750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1345</td>\n",
       "      <td>1352</td>\n",
       "      <td>943</td>\n",
       "      <td>1292</td>\n",
       "      <td>1277</td>\n",
       "      <td>781</td>\n",
       "      <td>586</td>\n",
       "      <td>517</td>\n",
       "      <td>425</td>\n",
       "      <td>...</td>\n",
       "      <td>7840</td>\n",
       "      <td>5009</td>\n",
       "      <td>6443</td>\n",
       "      <td>5532</td>\n",
       "      <td>1509</td>\n",
       "      <td>3247</td>\n",
       "      <td>3814</td>\n",
       "      <td>6611</td>\n",
       "      <td>3724</td>\n",
       "      <td>626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>857</td>\n",
       "      <td>780</td>\n",
       "      <td>284</td>\n",
       "      <td>922</td>\n",
       "      <td>653</td>\n",
       "      <td>1091</td>\n",
       "      <td>898</td>\n",
       "      <td>1152</td>\n",
       "      <td>182</td>\n",
       "      <td>...</td>\n",
       "      <td>6406</td>\n",
       "      <td>9644</td>\n",
       "      <td>1812</td>\n",
       "      <td>7734</td>\n",
       "      <td>5496</td>\n",
       "      <td>3294</td>\n",
       "      <td>373</td>\n",
       "      <td>7068</td>\n",
       "      <td>7338</td>\n",
       "      <td>1843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1318</td>\n",
       "      <td>998</td>\n",
       "      <td>909</td>\n",
       "      <td>1069</td>\n",
       "      <td>962</td>\n",
       "      <td>197</td>\n",
       "      <td>245</td>\n",
       "      <td>1411</td>\n",
       "      <td>245</td>\n",
       "      <td>...</td>\n",
       "      <td>6288</td>\n",
       "      <td>5427</td>\n",
       "      <td>1556</td>\n",
       "      <td>3282</td>\n",
       "      <td>9396</td>\n",
       "      <td>7379</td>\n",
       "      <td>1800</td>\n",
       "      <td>688</td>\n",
       "      <td>8318</td>\n",
       "      <td>8951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  numeric_1  numeric_2  numeric_3  numeric_4  numeric_5  numeric_6  \\\n",
       "0      1        592        705        105        753       1237       1010   \n",
       "1      1        160        314       1160       1269       1004       1317   \n",
       "2      1       1432       1115        898       1204        233        596   \n",
       "3      0       1113        449        139        537        597        101   \n",
       "4      0       1496        732        408        845        232        762   \n",
       "5      1       1262        887        779        537        282        480   \n",
       "6      0        534         17       1264        126        498       1497   \n",
       "7      0       1345       1352        943       1292       1277        781   \n",
       "8      1        857        780        284        922        653       1091   \n",
       "9      1       1318        998        909       1069        962        197   \n",
       "\n",
       "   numeric_7  numeric_8  numeric_9  ...  cat_17  cat_18  cat_19  cat_20  \\\n",
       "0        594       1343        276  ...    4768    9631    9205    5841   \n",
       "1        546        193        223  ...    9387    6668    3496    3965   \n",
       "2        771        359        153  ...    3222    4999    9008    3040   \n",
       "3       1103        786        114  ...     870    7576    1388     203   \n",
       "4         85        108        208  ...    6863    9594    2187    6210   \n",
       "5        422        808        951  ...    3472    6151    7603    2362   \n",
       "6        232        771        927  ...    2699    9719    2718    8249   \n",
       "7        586        517        425  ...    7840    5009    6443    5532   \n",
       "8        898       1152        182  ...    6406    9644    1812    7734   \n",
       "9        245       1411        245  ...    6288    5427    1556    3282   \n",
       "\n",
       "   cat_21  cat_22  cat_23  cat_24  cat_25  cat_26  \n",
       "0     744    5123    7816    8312    2153    7272  \n",
       "1    7090    7440    1256    9550    5252    8862  \n",
       "2    4554    9367    6920    4470     370     530  \n",
       "3    2006    5484     658    8703    5885      10  \n",
       "4    2807    8295    7723    9145    1024    7033  \n",
       "5    1254     419    3398    8524    1310     458  \n",
       "6    8956    8826     629    4285    3106    7750  \n",
       "7    1509    3247    3814    6611    3724     626  \n",
       "8    5496    3294     373    7068    7338    1843  \n",
       "9    9396    7379    1800     688    8318    8951  \n",
       "\n",
       "[10 rows x 40 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "TRAIN_FILE = 'train_file.txt'\n",
    "TEST_FILE = 'test_file.txt'\n",
    "\n",
    "\n",
    "header = 'label,numeric_1,numeric_2,numeric_3,numeric_4,numeric_5,numeric_6,numeric_7,numeric_8,numeric_9,numeric_10,numeric_11,numeric_12,numeric_13,'\n",
    "header += 'cat_1,cat_2,cat_3,cat_4,cat_5,cat_6,cat_7,cat_8,cat_9,cat_10,cat_11,cat_12,cat_13,cat_14,cat_15,cat_16,cat_17,cat_18,cat_19,cat_20,cat_21,'\n",
    "header += 'cat_22,cat_23,cat_24,cat_25,cat_26'\n",
    "\n",
    "column_header=header.split(\",\")\n",
    "\n",
    "\n",
    "def generate_data():\n",
    "    num_training_data=1200\n",
    "    num_numeric_features=13\n",
    "    num_categorical_features=26\n",
    "\n",
    "    numeric_data = np.random.randint(1500, size=(num_training_data, num_numeric_features))\n",
    "    categorical_data = np.random.randint(10000, size=(num_training_data, num_categorical_features))\n",
    "    label = np.random.randint(2, size=(num_training_data, 1))\n",
    "\n",
    "    return np.concatenate((numeric_data, categorical_data), axis=1), label\n",
    "\n",
    "data_X , data_Y = generate_data()\n",
    "\n",
    "# Saving CSV for train data\n",
    "train_data = np.concatenate((data_Y[:1000], data_X[:1000]), axis=1)\n",
    "train_df = pd.DataFrame(train_data, columns=column_header)\n",
    "train_df.to_csv(TRAIN_FILE, index=False)\n",
    "\n",
    "# Saving CSV for test data\n",
    "test_data = np.concatenate((data_Y[1000:], data_X[1000:]), axis=1)\n",
    "train_df = pd.DataFrame(test_data, columns=column_header)\n",
    "train_df.to_csv(TEST_FILE, index=False)\n",
    "\n",
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UDT Initialization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a UDT model specific for Criteo Click Through Prediction as follows. Here we define Bolt Datatype for all the columns, specify the target, n_target classes and the embedding dimension for UDT. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thirdai import bolt\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "tabular_model = bolt.UniversalDeepTransformer(\n",
    "    data_types={\n",
    "        \"numeric_1\": bolt.types.numerical(range=(0, 1500)),\n",
    "        \"numeric_2\": bolt.types.numerical(range=(0, 1500)),\n",
    "        \"numeric_3\": bolt.types.numerical(range=(0, 1500)),\n",
    "        \"numeric_4\": bolt.types.numerical(range=(0, 1500)),\n",
    "        \"numeric_5\": bolt.types.numerical(range=(0, 1500)),\n",
    "        \"numeric_6\": bolt.types.numerical(range=(0, 1500)),\n",
    "        \"numeric_7\": bolt.types.numerical(range=(0, 1500)),\n",
    "        \"numeric_8\": bolt.types.numerical(range=(0, 1500)),\n",
    "        \"numeric_9\": bolt.types.numerical(range=(0, 1500)),\n",
    "        \"numeric_10\": bolt.types.numerical(range=(0, 1500)),\n",
    "        \"numeric_11\": bolt.types.numerical(range=(0, 1500)),\n",
    "        \"numeric_12\": bolt.types.numerical(range=(0, 1500)),\n",
    "        \"numeric_13\": bolt.types.numerical(range=(0, 1500)),\n",
    "        \"cat_1\": bolt.types.categorical(),\n",
    "        \"cat_2\": bolt.types.categorical(),\n",
    "        \"cat_3\": bolt.types.categorical(),\n",
    "        \"cat_4\": bolt.types.categorical(),\n",
    "        \"cat_5\": bolt.types.categorical(),\n",
    "        \"cat_6\": bolt.types.categorical(),\n",
    "        \"cat_7\": bolt.types.categorical(),\n",
    "        \"cat_8\": bolt.types.categorical(),\n",
    "        \"cat_9\": bolt.types.categorical(),\n",
    "        \"cat_10\": bolt.types.categorical(),\n",
    "        \"cat_11\": bolt.types.categorical(),\n",
    "        \"cat_12\": bolt.types.categorical(),\n",
    "        \"cat_13\": bolt.types.categorical(),\n",
    "        \"cat_14\": bolt.types.categorical(),\n",
    "        \"cat_15\": bolt.types.categorical(),\n",
    "        \"cat_16\": bolt.types.categorical(),\n",
    "        \"cat_17\": bolt.types.categorical(),\n",
    "        \"cat_18\": bolt.types.categorical(),\n",
    "        \"cat_19\": bolt.types.categorical(),\n",
    "        \"cat_20\": bolt.types.categorical(),\n",
    "        \"cat_21\": bolt.types.categorical(),\n",
    "        \"cat_22\": bolt.types.categorical(),\n",
    "        \"cat_23\": bolt.types.categorical(),\n",
    "        \"cat_24\": bolt.types.categorical(),\n",
    "        \"cat_25\": bolt.types.categorical(),\n",
    "        \"cat_26\": bolt.types.categorical(),\n",
    "        \"label\": bolt.types.categorical(),\n",
    "    },\n",
    "    target=\"label\",\n",
    "    n_target_classes=2,\n",
    "    options={\"embedding_dimension\": 512},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now train the UDT with just one line of code. Here we are specifying the training file name, number of epochs to train and maximum number of batches we want to load in memory at once. `max_in_memory_batches` support loaing data in a streaming fashion. You can change `max_in_memory_batches` based on your own memory specification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data | source 'train_file.txt' | vectors 1000 | batches 1 | time 0s | complete\n",
      "\n",
      "train | epoch 0 | train_steps 1 | {} | train_batches 1 | time 0s | complete     \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "tabular_model.train(filename=TRAIN_FILE, epochs=1, max_in_memory_batches=1000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating the UDT is also just one line of code. Evaluate function by default returns activations. Then, we are using sklearn's roc_auc_score to calculate roc_auc_score for the model we trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data | source 'test_file.txt' | vectors 200 | batches 1 | time 0s | complete\n",
      "\n",
      "evaluate | epoch 1 | train_steps 1 | {categorical_accuracy: 0.555} | eval_batches 1 | time 9ms\n",
      "\n",
      "ROC_AUC: 0.48109243697478987\n"
     ]
    }
   ],
   "source": [
    "activations = tabular_model.evaluate(filename=TEST_FILE, metrics=[\"categorical_accuracy\"])\n",
    "\n",
    "true_labels = np.zeros(activations.shape[0], dtype=np.float32)\n",
    "with open(TEST_FILE) as f:\n",
    "    header = f.readline()\n",
    "    count = 0\n",
    "    for line in f:\n",
    "        true_labels[count] = np.float32(line.split(\",\")[0])\n",
    "        count += 1\n",
    "\n",
    "roc_auc = roc_auc_score(true_labels, activations[:, 1])\n",
    "\n",
    "print(\"ROC_AUC:\", roc_auc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.remove(TRAIN_FILE)\n",
    "os.remove(TEST_FILE)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
