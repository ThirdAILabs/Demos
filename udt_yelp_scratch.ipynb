{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from thirdai import bolt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using a standard dataset for sentiment classification called yelp_polarity. You should download the dataset from the link https://www.kaggle.com/datasets/irustandi/yelp-review-polarity. \n",
    "\n",
    "The dataset is in the form of a csv that has two columns:\n",
    "1. category (positive - 1 or negative - 0)\n",
    "2. text \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=pd.read_csv(\"yelp_review_polarity_csv/train.csv\",header=None)\n",
    "train_data.columns=[\"category\",\"text\"]\n",
    "\n",
    "test_data=pd.read_csv(\"yelp_review_polarity_csv/test.csv\",header=None)\n",
    "test_data.columns=[\"category\",\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Unfortunately  the frustration of being Dr. Go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Been going to Dr. Goldberg for over 10 years. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>I don't know what Dr. Goldberg was like before...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>I'm writing this review to give you a heads up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>All the food is great here. But the best thing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category                                               text\n",
       "0         1  Unfortunately  the frustration of being Dr. Go...\n",
       "1         2  Been going to Dr. Goldberg for over 10 years. ...\n",
       "2         1  I don't know what Dr. Goldberg was like before...\n",
       "3         1  I'm writing this review to give you a heads up...\n",
       "4         2  All the food is great here. But the best thing..."
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should write your own preprocessing routine for the data. \n",
    "While saving the dataframes, make sure that the files have dataframe columns as header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_save(dataframe,filename):\n",
    "  dataframe[\"text\"]=dataframe[\"text\"].str.replace(',',' ')\n",
    "  dataframe.to_csv(filename,index=None, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file=\"yelp_polarity_train.csv\"\n",
    "test_file=\"yelp_polarity_test.csv\"\n",
    "preprocess_and_save(train_data,train_file)\n",
    "preprocess_and_save(test_data,test_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UniversalDeepTransformer(UDT) can read data from a csv file (or you can specify your own delimiter). \n",
    "\n",
    "You have to specify the datatypes of the columns that you want your model to train on while initializing UDT. You also have to specify the target column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================= Bolt Model =======================\n",
      "input_1 (Input): dim=200000\n",
      "input_1 -> fc_1 (FullyConnected): dim=512, sparsity=1, act_func=ReLU\n",
      "fc_1 -> fc_2 (FullyConnected): dim=2, sparsity=1, act_func=Softmax\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_model = bolt.UniversalDeepTransformer(\n",
    "    data_types={\n",
    "        \"text\": bolt.types.text(),\n",
    "        \"category\": bolt.types.categorical(n_unique_classes=2)\n",
    "    },\n",
    "    target=\"category\",\n",
    "    delimiter=','\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will be training a model that has more than 100M parameters on an M1 under 10mins. \n",
    "\n",
    "After initializing UDT, we just have to specify the number of epochs and the learning rate for training. And we are good to go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading vectors from 'yelp_polarity_train.csv'\n",
      "Loaded 560000 vectors from 'yelp_polarity_train.csv' in 10 seconds.\n",
      "train epoch 0:\n",
      "\n",
      "[==================================================] 100%\n",
      "\n",
      "train | epoch 0 | updates 274 | {categorical_accuracy: 0.915975} | batches 274 | time 112s | complete\n",
      "\n",
      "train epoch 1:\n",
      "\n",
      "[==================================================] 100%\n",
      "\n",
      "train | epoch 1 | updates 548 | {categorical_accuracy: 0.960654} | batches 274 | time 105s | complete\n",
      "\n",
      "train epoch 2:\n",
      "\n",
      "[==================================================] 100%========             ] 73%\n",
      "\n",
      "train | epoch 2 | updates 822 | {categorical_accuracy: 0.975034} | batches 274 | time 107s | complete\n",
      "\n",
      "train epoch 3:\n",
      "\n",
      "[==================================================] 100%\n",
      "\n",
      "train | epoch 3 | updates 1096 | {categorical_accuracy: 0.981511} | batches 274 | time 104s | complete\n",
      "\n",
      "train epoch 4:\n",
      "\n",
      "[==============================                    ] 59%"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4.8032477e-02, 9.5196736e-01],\n",
       "       [9.9999559e-01, 4.3396126e-06],\n",
       "       [4.7769544e-10, 9.9999988e-01],\n",
       "       ...,\n",
       "       [9.9999928e-01, 6.3129028e-07],\n",
       "       [9.9999988e-01, 8.8657220e-10],\n",
       "       [9.9999988e-01, 1.5347833e-10]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100%\n",
      "\n",
      "train | epoch 4 | updates 1370 | {categorical_accuracy: 0.98777} | batches 274 | time 110s | complete\n",
      "\n",
      "Loading vectors from 'yelp_polarity_test.csv'\n",
      "Loaded 38000 vectors from 'yelp_polarity_test.csv' in 0 seconds.\n",
      "test:\n",
      "\n",
      "[==================================================] 100%\n",
      "\n",
      "predict | epoch 5 | updates 1370 | {categorical_accuracy: 0.920974} | batches 19 | time 5784ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_config = (bolt.TrainConfig(epochs=5, learning_rate=0.01)\n",
    "                    .with_metrics([\"categorical_accuracy\"]))\n",
    "\n",
    "text_model.train(train_file, train_config)\n",
    "\n",
    "test_config = (bolt.EvalConfig()\n",
    "                   .with_metrics([\"categorical_accuracy\"]))\n",
    "\n",
    "text_model.evaluate(test_file, test_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_model.save(\"sentiment_model.bolt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine learning models sometimes feel like a black box where it becomes very hard to gauge into how the model makes decisions about the input data points. Our explainability module lifts the curtain over predictions and offers you deeper insights into the decision process of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_sample={\"text\":\"I disliked the movie\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To explain the decision of the model for a datapoint, pass the datapoint as a dictionary to model.explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.9922657e-01 7.7333325e-04]\n",
      "column_name: \"text\" | keyword: \"dislike\" | percentage_significance: 24.3795\n"
     ]
    }
   ],
   "source": [
    "predicted_class=text_model.predict(inference_sample)\n",
    "print(predicted_class)\n",
    "\n",
    "explanations=text_model.explain(inference_sample)\n",
    "print(explanations[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the word \"dislike\" has the highest significance.\n",
    "\n",
    "Not only can we get insights the predictions of the model, but also how to change the datapoint to get the desired output. By specifying a target, we can find out what columns should be changed to get the desired output. \"Nobu is an underwhelming restaurant\" has negative sentiment and after setting the target as 1(positive), the model predicts that underwhelming is the word that should be changed to convert negative sentiment to positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column_name: \"text\" | keyword: \"underwhelming\" | percentage_significance: 54.4764\n"
     ]
    }
   ],
   "source": [
    "inference_sample={\"text\":\"Nobu is an underwhelming restaurant\"}\n",
    "explanations=text_model.explain(inference_sample, target_class=\"1\")\n",
    "print(explanations[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "50292dbb1f747f7151d445135d392af3138fb3c65386d17d9510cb605222b10b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
