{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Embeddings/Cold Start/ Recommendation from Raw Text using ThirdAI's UDT\n",
    "\n",
    "Cold Start is a common problem that most e-commerce companies deal with daily. Here, we demonstrate how to get a neural product search engine from a raw text in the product catalog. A catalog contains productID, title, descriptions (optional), and metadata (optional). We may not have data about the products purchased for a given query.\n",
    "\n",
    "This notebook shows how to use ThirdAI's Universal Deep Transformer (UDT) to pretain or cold-start a large neural model. The model can generate embeddings for any textual description or the entities provided during training. The model also provides a reasonable semantic search engine ready to go.\n",
    "\n",
    "#### Get Text and Entities Embeddings\n",
    "Once the cold-start model is pre-trained on raw text data, the model has two kinds of embeddings for use in other downstream AI tasks. We can use the model to generate any domain-specific embedding of a given text string. The model while training also generates the internal representation of entities (like documents or products)\n",
    "\n",
    "#### Fine-tune on supervised query-product data (Optional)\n",
    "If you have both a product catalog and query-product data, we first pre-train on just the catalog data (Cold Start), and the same model can be later fine-tuned on your query-product data for better results. Models pre-trained with cold start converge faster with significantly less supervised data than models trained from scratch on query-product data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Download\n",
    "\n",
    "We start with the Amazon Kaggle Product Catalog Dataset with 110K products. To make the demo run on a single core collab in few minutes, we randomly sample just 5% of the products (about 5000). Please download the dataset, extract the downloaded file and specify the filepath as *original_product_catalog_file* below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "os.system('wget -O amazon-kaggle-product-catalog.csv https://www.dropbox.com/s/9km4arjsjkevzw9/amazon-kaggle-product-catalog.csv?dl=0')\n",
    "\n",
    "catalog_file = \"./reformatted_trn_unsupervised.csv\"\n",
    "\n",
    "## for a quick demo, we are sampling just the first 5% of the products\n",
    "def sample_catalog(catalog_file, percentage=0.05):\n",
    "    df = pd.read_csv(catalog_file)\n",
    "    df = df.iloc[:int(percentage*df.shape[0])]\n",
    "    df[\"PRODUCT_ID\"] = [i for i in range(df.shape[0])]\n",
    "    #\n",
    "    sampled_catalog_file = f\"./amazon-kaggle-product-catalog-sampled-{percentage}.csv\"\n",
    "    df.to_csv(sampled_catalog_file, index=False)\n",
    "    #\n",
    "    return sampled_catalog_file, df\n",
    "\n",
    "sampled_catalog_file, dataframe = sample_catalog(catalog_file, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## A sample row from the sampled catalog file is printed below. Please ensure that your file has data in the correct format.\n",
    "pd.options.display.max_colwidth = 700\n",
    "dataframe[dataframe[\"PRODUCT_ID\"] == 300]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UDT Initialization\n",
    "\n",
    "Initialize a UDT model by simply specifying the input/output names. Here, we intend to use the model for query-to-product prediction. Hence, our input is a \"QUERY\" and the output is a \"PRODUCT_ID\". The \"QUERY\" column name can be anything of your choice. However, it has to be consistent with the prediction step (shown later). The \"PRODUCT_ID\" column name has to match with the name in your catalog file (shown above).\n",
    "\n",
    "Note: contextual_encoding has three options, 'local', 'global' and 'none'. If your queries are short in length (~5 tokens per query), 'global' tends to converge to a better accuracy. For longer queries, we would suggest using 'local', although you can experiment with either of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thirdai import bolt\n",
    "\n",
    "model = bolt.UniversalDeepTransformer(\n",
    "    data_types={\n",
    "        \"QUERY\": bolt.types.text(contextual_encoding=\"local\"),\n",
    "        \"PRODUCT_ID\": bolt.types.categorical(delimiter=';'),\n",
    "    },\n",
    "    target=\"PRODUCT_ID\",\n",
    "    n_target_classes=dataframe.shape[0],\n",
    "    integer_target=True,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cold Start Pretraining\n",
    "\n",
    "The following does the cold-start training on the model with the catalog information. You can specify what columns in the catalog should have a strong influence on the eventual embeddings and what columsn should have a weak influence. The column names should match with the catalog file. \n",
    "\n",
    "NOTE: Specifying learning rate and epochs is optional. We can sutomatically tune the training hyperparemeters, but we do give an option to specify if wish to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cold_start(\n",
    "    filename=sampled_catalog_file,\n",
    "    strong_column_names=[\"TITLE\"],\n",
    "    weak_column_names=[\"DESCRIPTION\", \"BULLET_POINTS\", \"BRAND\"],\n",
    "    learning_rate=0.001,\n",
    "    epochs=5,\n",
    "    metrics=[\"categorical_accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = './ust-cold-start-amzn-kaggle.model'\n",
    "\n",
    "## save the model\n",
    "model.save(model_save_path)\n",
    "\n",
    "## load it back\n",
    "bolt.UniversalDeepTransformer.load(model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper function to print the results\n",
    "def top_k_products(query, k):\n",
    "    result = model.predict({\"QUERY\": query})\n",
    "    #\n",
    "    k = min(k, len(result) - 1)\n",
    "    sorted_product_ids = result.argsort()[-k:][::-1]\n",
    "    #\n",
    "    print('***************************************************')\n",
    "    print('******************* STARTS HERE *******************')\n",
    "    print('***************************************************')\n",
    "    for p_id in sorted_product_ids:\n",
    "        print(dict(df.iloc[p_id,[1,2]]))\n",
    "        print('******************************')\n",
    "    #\n",
    "    print('***************************************************')\n",
    "    print('******************** ENDS HERE ********************')\n",
    "    print('***************************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## example 1\n",
    "top_k_products('laptop bag', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## example 2\n",
    "top_k_products('dust resistant laptop bag', 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Product Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get embeddings for a specific product\n",
    "\n",
    "product_id = 723\n",
    "product_embedding = model.get_entity_embeddings(product_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a Query Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_emb = model.embedding_representation({'QUERY':'washing machine'})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
