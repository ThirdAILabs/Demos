{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scripts to train a NER Model\n",
    "\n",
    "This script use ThirdAI's NER library to train a model on an NER dataset from scratch. For this demonstration, we are using the `https://huggingface.co/datasets/conll2003` dataset. We also show how to load a pre-trained ThirdAI NER model and further fine-tune it, provided the labels remain the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install thirdai==0.8.1\n",
    "!pip3 install datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datasets import load_dataset\n",
    "from thirdai import bolt, dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constants: Tag to label Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAG_MAP = {\n",
    "    \"O\": 0,\n",
    "    \"B-PER\": 1,\n",
    "    \"I-PER\": 2,\n",
    "    \"B-ORG\": 3,\n",
    "    \"I-ORG\": 4,\n",
    "    \"B-LOC\": 5,\n",
    "    \"I-LOC\": 6,\n",
    "    \"B-MISC\": 7,\n",
    "    \"I-MISC\": 8,\n",
    "}\n",
    "\n",
    "entries = list(TAG_MAP.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions to load dataset from huggingface and save training data as JSONL file. \n",
    "It could be txt file too, given each line contains a json of format: \n",
    "\n",
    "`{\"source\": [List of Text Tokens], \"target\": [List of Corresponding Text Tags]}`. \n",
    "\n",
    "Note: Make sure tags should not be outside of TAG_MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataset_as_jsonl(filename, loaded_data):\n",
    "    with open(filename, \"w\") as file:\n",
    "        for example in loaded_data:\n",
    "            data = {\n",
    "                \"source\": example[\"tokens\"],\n",
    "                \"target\": [entries[tag] for tag in example[\"ner_tags\"]],\n",
    "            }\n",
    "            file.write(json.dumps(data) + \"\\n\")\n",
    "\n",
    "\n",
    "def download_dataset_as_file(subset):\n",
    "    # Load dataset\n",
    "    dataset = load_dataset(\"conll2003\")\n",
    "    loaded_data = dataset[f\"{subset}\"]\n",
    "    filename = f\"{subset}_ner_data.jsonl\"\n",
    "    save_dataset_as_jsonl(filename, loaded_data)\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize a Bolt NER model given the column names and TAG_MAP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_model = bolt.NER(\"source\", \"target\", TAG_MAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use thirdai's dataset module to load train file into a NerDataSource and pass it to train function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data_source = dataset.NerDataSource(download_dataset_as_file(\"train\"))\n",
    "\n",
    "ner_model.train(\n",
    "    train_data=train_data_source,\n",
    "    epochs=1,\n",
    "    learning_rate=0.001,\n",
    "    batch_size=1024,\n",
    "    train_metrics=[\"loss\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have validation data, you can pass that to train function too as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_source = dataset.NerDataSource(download_dataset_as_file(\"train\"))\n",
    "val_data_source = dataset.NerDataSource(download_dataset_as_file(\"validation\"))\n",
    "\n",
    "ner_model.train(\n",
    "    train_data=train_data_source,\n",
    "    epochs=2,\n",
    "    learning_rate=0.001,\n",
    "    batch_size=1024,\n",
    "    train_metrics=[\"loss\"],\n",
    "    val_data=val_data_source,\n",
    "    val_metrics=[\"loss\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saves the model and then loads it again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_model.save(\"thirdai_ner_model\")\n",
    "ner_model = bolt.NER.load(\"thirdai_ner_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = load_dataset(\"conll2003\")[\"test\"]\n",
    "predictions = []\n",
    "actuals = []\n",
    "\n",
    "for example in test_data:\n",
    "    tokens = example[\"tokens\"]\n",
    "    actual_tags = [entries[tag] for tag in example[\"ner_tags\"]]\n",
    "\n",
    "    # Predict and evaluate\n",
    "    predicted_tags = ner_model.get_ner_tags([tokens])[0]\n",
    "\n",
    "    predictions.extend(predicted_tags)\n",
    "    actuals.extend(actual_tags)\n",
    "\n",
    "correct_predictions = sum(p[0][0] == a for p, a in zip(predictions, actuals))\n",
    "total_predictions = len(predictions)\n",
    "accuracy = correct_predictions / total_predictions\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case, you want to further finetune on a already trained model, using a subset of tags. Here, we are creating a small retraining data, further we save it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Sample sentences with corresponding NER tags\n",
    "sentences = [\n",
    "    (\"John Doe went to Paris\", [\"B-PER\", \"I-PER\", \"O\", \"O\", \"B-LOC\"]),\n",
    "    (\n",
    "        \"Alice and Bob are from New York City\",\n",
    "        [\"B-PER\", \"O\", \"B-PER\", \"O\", \"O\", \"B-LOC\", \"I-LOC\", \"I-LOC\"],\n",
    "    ),\n",
    "    (\"The Eiffel Tower is in France\", [\"O\", \"B-LOC\", \"I-LOC\", \"O\", \"O\", \"B-LOC\"]),\n",
    "    (\"Microsoft Corporation was founded by Bill Gates\", [\"B-ORG\", \"I-ORG\", \"O\", \"O\", \"O\", \"B-PER\", \"I-PER\"]),\n",
    "    (\"She visited the Louvre Museum in Paris last summer\", [\"O\", \"O\", \"O\", \"B-LOC\", \"I-LOC\", \"O\", \"B-LOC\", \"O\", \"O\"]),\n",
    "    (\"Google and IBM are big tech companies\", [\"B-ORG\", \"O\", \"B-ORG\", \"O\", \"O\", \"O\", \"O\"]),\n",
    "    (\"Mount Everest is the highest mountain in the world\", [\"B-LOC\", \"I-LOC\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]),\n",
    "    (\"Leonardo DiCaprio won an Oscar\", [\"B-PER\", \"I-PER\", \"O\", \"O\", \"O\"]),\n",
    "]\n",
    "\n",
    "# File to write the data\n",
    "retrain_filename = \"retraining_ner_data.json\"\n",
    "with open(retrain_filename, \"w\") as file:\n",
    "    for sentence, tags in sentences:\n",
    "        tokens = sentence.split()\n",
    "        data = {\"source\": tokens, \"target\": tags}\n",
    "        json_line = json.dumps(data)\n",
    "        file.write(json_line + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can just call the train function again for retraining the NER model on subset of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrain_data_source = dataset.NerDataSource(retrain_filename)\n",
    "\n",
    "ner_model.train(\n",
    "    train_data=retrain_data_source,\n",
    "    epochs=3,\n",
    "    learning_rate=0.001,\n",
    "    batch_size=1024,\n",
    "    train_metrics=[\"loss\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.remove(\"thirdai_ner_model\")\n",
    "os.remove(retrain_filename)\n",
    "os.remove(\"train_ner_data.jsonl\")\n",
    "os.remove(\"validation_ner_data.jsonl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
