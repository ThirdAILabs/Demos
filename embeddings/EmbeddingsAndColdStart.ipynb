{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Embeddings/Cold Start/ Recommendation from Raw Text using ThirdAI's UDT\n",
    "\n",
    "Cold Start is a common problem that most e-commerce companies deal with daily. Here, we demonstrate how to get a neural product search engine from a raw text in the product catalog. A catalog contains productID, title, descriptions (optional), and metadata (optional). We may not have data about the products purchased for a given query.\n",
    "\n",
    "This notebook shows how to use ThirdAI's Universal Deep Transformer (UDT) to pretain or cold-start a large neural model. The model can generate embeddings for any textual description or the entities provided during training. The model also provides a reasonable semantic search engine ready to go.\n",
    "You can immediately run a version of this notebook in your browser on Google Colab at the following link:\n",
    "\n",
    "https://githubtocolab.com/ThirdAILabs/Demos/blob/main/embeddings/EmbeddingsAndColdStart.ipynb\n",
    "#### Get Text and Entities Embeddings\n",
    "Once the cold-start model is pre-trained on raw text data, the model produces two kinds of embeddings for use in other downstream AI tasks. We can build embedding models of any given dimentions up to 50,000. This script produces 512 dimentional embedding (default). We can use the model to generate any data-specific text string embeddings. In addition, while training, the model also creates internal representations of entities like the raw text documents or products in the current demo. \n",
    "\n",
    "#### Fine-tune on supervised query-product data (Optional)\n",
    "Suppose you have both a product catalog and query-product data. In that case, we first pre-train on just the catalog data (Cold Start). The same pre-trained model can be further fine-tuned on supervised query-product data for better results. Fine-tunning is a standard supervised text classification where we load the UDT model and train it in a supervised classification way. Models pre-trained with cold start converge faster with significantly less supervised data than models trained from scratch on query-product data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install thirdai --upgrade\n",
    "\n",
    "import thirdai\n",
    "## activate the license (works only for this demo)\n",
    "thirdai.licensing.activate(\"A4D695-FE9744-A1918F-536DC9-F8728E-V3\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Download\n",
    "\n",
    "We start with the Amazon Kaggle Product Catalog Dataset with 110K products. To make the demo run on a single core collab in few minutes, we randomly sample just 5% of the products (about 5000). Please download the dataset, extract the downloaded file and specify the filepath as *original_product_catalog_file* below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "os.system('wget -O amazon-kaggle-product-catalog.csv https://www.dropbox.com/s/kq5396ypmtagsyr/amzn-kaggle-product-catalog.csv?dl=0')\n",
    "\n",
    "catalog_file = \"./amazon-kaggle-product-catalog.csv\"\n",
    "\n",
    "## for a quick demo, we are sampling just the first 5% of the products\n",
    "def sample_catalog(catalog_file, percentage=0.05):\n",
    "    df = pd.read_csv(catalog_file)\n",
    "    df = df.sample(frac=percentage, random_state=43)\n",
    "    df[\"PRODUCT_ID\"] = [i for i in range(df.shape[0])]\n",
    "    df[\"TITLE\"] = df[\"TITLE\"].str.lower()\n",
    "    df[\"DESCRIPTION\"] = df[\"DESCRIPTION\"].str.lower()\n",
    "    df[\"BULLET_POINTS\"] = df[\"BULLET_POINTS\"].str.lower()\n",
    "    df[\"BRAND\"] = df[\"BRAND\"].str.lower()\n",
    "    #\n",
    "    sampled_catalog_file = f\"./amazon-kaggle-product-catalog-sampled-{percentage}.csv\"\n",
    "    df.to_csv(sampled_catalog_file, index=False)\n",
    "    #\n",
    "    return sampled_catalog_file, df\n",
    "\n",
    "sampled_catalog_file, dataframe = sample_catalog(catalog_file, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## A sample row from the sampled catalog file is printed below.\n",
    "pd.options.display.max_colwidth = 700\n",
    "dataframe[dataframe[\"PRODUCT_ID\"] == 417]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UDT Initialization\n",
    "\n",
    "Initialize a UDT model by simply specifying the input/output names. Here, we intend to use the model for query-to-product prediction. Hence, our input is a \"QUERY\" and the output is a \"PRODUCT_ID\". The \"QUERY\" column name can be anything of your choice. However, it has to be consistent with the prediction step (shown later). The \"PRODUCT_ID\" column name has to match with the name in your catalog file (shown above).\n",
    "\n",
    "NOTE: *model_config* is optional. If not specified we will automatically initialize an appropriate model. Please reach out to contact@thirdai.com for more info on model configs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thirdai import bolt\n",
    "import os\n",
    "\n",
    "config_dir = os.path.join(os.path.abspath(\"\"), \"../configs/\")\n",
    "\n",
    "model = bolt.UniversalDeepTransformer(\n",
    "    data_types={\n",
    "        \"QUERY\": bolt.types.text(),\n",
    "        \"PRODUCT_ID\": bolt.types.categorical(),\n",
    "    },\n",
    "    target=\"PRODUCT_ID\",\n",
    "    n_target_classes=dataframe.shape[0],\n",
    "    integer_target=True,\n",
    "    model_config=os.path.join(config_dir, \"embeddings_and_cold_start.config\")\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cold Start a.k.a Pretraining\n",
    "\n",
    "The following code starts the pre-training (or cold start) on raw catalog information. UDT allows you to specify what columns in the catalog should strongly influence the eventual embeddings and what column should have a weak influence. In the example below, we choose the product title to have a strong influence and everything else to have a weak influence. The column names should match the catalog file.\n",
    "\n",
    "NOTE: Specifying learning rate and epochs is optional. We can sutomatically tune the training hyperparemeters, but we do give an option to specify if wish to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cold_start(\n",
    "    filename=sampled_catalog_file,\n",
    "    strong_column_names=[\"TITLE\"],\n",
    "    weak_column_names=[\"DESCRIPTION\", \"BULLET_POINTS\", \"BRAND\"],\n",
    "    learning_rate=0.001,\n",
    "    epochs=5,\n",
    "    metrics=[\"categorical_accuracy\"],\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = './udt-cold-start-amzn-kaggle.model'\n",
    "\n",
    "## save the model\n",
    "model.save(model_save_path)\n",
    "\n",
    "## load it back\n",
    "model = bolt.UniversalDeepTransformer.load(model_save_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper function to print the results\n",
    "def top_k_products(query, k):\n",
    "    result = model.predict({\"QUERY\": query})\n",
    "    #\n",
    "    k = min(k, len(result) - 1)\n",
    "    sorted_product_ids = result.argsort()[-k:][::-1]\n",
    "    #\n",
    "    for p_id in sorted_product_ids:\n",
    "        print(dict(dataframe.iloc[p_id,[1,2]]))\n",
    "        print('******************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## example 1\n",
    "top_k_products('laptop bag', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## example 2\n",
    "top_k_products('birthday gifts', 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Entity Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get embeddings for a specific product\n",
    "# The product ID should match with the catalog file use in the cold_start step\n",
    "\n",
    "product_id = 723\n",
    "product_embedding = model.get_entity_embedding(product_id)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Semantic Embedding of any Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_emb = model.embedding_representation({'QUERY':'washing machine'})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the embeddings\n",
    "\n",
    "If you want a super-cool 3D visualization of the embeddings that our UDT model learned for this dataset, please visit the following link. You can type in a search query and get results in the serch bar. You can click on any product and navigate the neighborhood for releated products.\n",
    "\n",
    "http://20.221.80.155/amazon-catalog\n",
    "\n",
    "If you want to build a similar visualization for your own datasets, please reach out to contact@thirdai.com. We will soon put up instructions to automatically generate the visualization with the trained embeddings."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
