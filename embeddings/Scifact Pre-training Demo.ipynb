{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-training and fine-tuning an LLM on CPU on BEIR datasets with ThirdAI's UDT\n",
    "\n",
    "In this notebook, we will pre-train an LLM from scratch on the popular BEIR datasets (https://github.com/beir-cellar/beir) using ThirdAI's Universal Deep Transformer (UDT). We will use the 'Scifact' dataset to demonstrate how UDT can just pre-train on a small dataset and outperform T5-large model trained on a huge corpus. \n",
    "\n",
    "This demo shows that one-model for all is sub-optimal and pre-training on specific downstream datasets is required to get the best results.\n",
    "\n",
    "While most LLMs cannot be fine-tuned even on a powerful GPU, ThirdAI's UDT can train a billion parameter model on just a moderate CPU in few minutes.\n",
    "\n",
    "Please Note: You can immediately run a version of this notebook in your browser on Google Colab at the following link:\n",
    "\n",
    "https://githubtocolab.com/ThirdAILabs/Demos/blob/main/Scifact%20Pre-training%20Demo.ipynb\n",
    "\n",
    "This notebook uses an activation key that will only work with this demo. If you want to try us out on your own dataset, you can obtain a free trial license at the following link: https://www.thirdai.com/try-bolt/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import thirdai and activate license"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install beir\n",
    "!pip3 install thirdai --upgrade\n",
    "\n",
    "import thirdai\n",
    "thirdai.licensing.activate('8E46E4-653FD6-AA2B02-65E265-A4FACA-V3')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and process the dataset into a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thirdai.demos import download_beir_dataset\n",
    "\n",
    "dataset = \"scifact\"\n",
    "unsup_file, sup_train_file, sup_test_file, n_target_classes = download_beir_dataset(dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above step, *unsup_file* refers to the corpus file with document id, title and text. We can have even more columns with other metadata for each document. Pre-training with UDT supports two types of columns, strong and weak. For the purpose of this demo, we choose 'title' to be the strong column and 'text' to be the weak column. You can play with different settings shown in the pre-training (model.cold_start()) step.\n",
    "\n",
    "A couple of sample rows of the *unsup_file* are shown below.\n",
    "\n",
    "PLEASE NOTE: Currently, UDT's cold_start function requires the DOC_ID to be an integer. We will add support for other formats in a future release."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.options.display.max_colwidth = 700\n",
    "pd.read_csv(unsup_file, nrows=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a UDT model\n",
    "\n",
    "The column name 'QUERY' has to match with the on in the header in *unsup_test_file*.\n",
    "The column name 'DOC_ID' should match with the one in the header of the corpus file (*unsup_file*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thirdai import bolt\n",
    "import os\n",
    "\n",
    "config_dir = os.path.join(os.path.abspath(\"\"), \"../configs/\")\n",
    "\n",
    "model = bolt.UniversalDeepTransformer(\n",
    "    data_types={\n",
    "        \"QUERY\": bolt.types.text(),\n",
    "        \"DOC_ID\": bolt.types.categorical(delimiter=':'),\n",
    "    },\n",
    "    target=\"DOC_ID\",\n",
    "    n_target_classes=n_target_classes,\n",
    "    integer_target=True,\n",
    "    model_config=os.path.join(config_dir, \"embeddings_and_cold_start.config\"),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-train (Cold Start) on the *unsup_file*\n",
    "\n",
    "In the following step, we do the pre-training by specifying the strong and weak columns. For this demo, we use 'TITLE' as the strong column and 'TEXT' as the weak column. We can have more columns in either of the lists. The training time and the test accuracies are shown below. We can see that by just pre-traiing on the Scifact dataset, we get 40% precision@1 which beats T5-large's performance on the same dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cold_start(\n",
    "    filename=unsup_file,\n",
    "    strong_column_names=[\"TITLE\"],\n",
    "    weak_column_names=[\"TEXT\"],\n",
    "    learning_rate=0.001,\n",
    "    epochs=5,\n",
    ")\n",
    "\n",
    "activations = model.evaluate(sup_test_file, metrics=['categorical_accuracy','recall@100'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tune on supervised data (OPTIONAL)\n",
    "\n",
    "If you have supervised data that maps queries to documents, you can further improve the model performance by fine-tuning your pre-trained model on the supervised data.\n",
    "\n",
    "Please note that in your *sup_train_file* and *sup_test_file* should have the same column names 'QUERY' and 'DOC_ID'.\n",
    "\n",
    "The training time to fine-tune and the final accuracy are shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(\n",
    "    filename=sup_train_file,\n",
    "    learning_rate=0.001,\n",
    "    epochs=5,\n",
    ")\n",
    "\n",
    "activations = model.evaluate(sup_test_file, metrics=['categorical_accuracy','recall@100'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./scidocs.model')\n",
    "\n",
    "model = bolt.UniversalDeepTransformer.load('./scidocs.model')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparisons against T5\n",
    "\n",
    "| Model | Precision@1 | Recall@100 |\n",
    "| --- | --- | --- |\n",
    "| UDT (pre-training + fine-tuning) | 58% | 90% |\n",
    "|  UDT (just pre-training) |     40%     | 82.3%      |\n",
    "| T5-large | 39.3%    | 82%        |\n",
    "| T5-base |  34.7%    | 80%        |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
