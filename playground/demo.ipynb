{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ThirdAI's Playground\n",
    "\n",
    "In this notebook, we will show \n",
    "\n",
    "1. How to easily build a semantic QnA engine for all your documents with ThirdAI's BOLT engine.\n",
    "\n",
    "2. (Optional) How to use your OpenAI key to get retrieval augmented answers from OpenAI.\n",
    "\n",
    "3. How to teach your retrieval model with RLHF.\n",
    "\n",
    "4. (Optional) How to save your models and export to ThirdAI's Playground web-app to do interative QnA and teach your model with RLHF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thirdai's license activation\n",
    "\n",
    "import thirdai\n",
    "try:\n",
    "    thirdai.licensing.activate(\"\")\n",
    "except:\n",
    "    print(\"You need a license key to use ThirdAI's library. Please request a trial license at https://www.thirdai.com/try-bolt/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thirdai import bolt\n",
    "import os\n",
    "import nltk\n",
    "nltk.data.path.append(\"./data/\")\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from student import models, documents, loggers, teachers, qa\n",
    "from student.state import State\n",
    "from student import documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many search results do you want to retrieve from your files for every query\n",
    "\n",
    "N_REFERENCES = 5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definition\n",
    "#### Option 1: Define a model from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a model from scratch\n",
    "\n",
    "state = State()\n",
    "state.documents = documents.DocList()\n",
    "state.model = models.Mach(id_col=\"id\", query_col=\"query\")\n",
    "state.logger = loggers.InMemoryLogger()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 2: Load from a checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from a checkpoint. \n",
    "# Please note that if you load a checkpoint that you saved after training on a file, the data associated with that file will also get loaded. \n",
    "# You can always clear the data associated with a checkpoint by simply running \"state.documents = documents.DocList()\" after \"state.load(path_to_checkpoint)\"\"\n",
    "\n",
    "path_to_checkpoint = \"/Users/tharunkr/qt-app/base_models/checkpoints_without_bias/msmarco_0_reindexes_frozen.zip\"\n",
    "\n",
    "state = State()\n",
    "state.load(path_to_checkpoint)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load your files\n",
    "\n",
    "#### Option 1: PDF or DOCX files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = ['/Users/tharunkr/Desktop/mutual_nda_teamplate_for_testing.pdf']\n",
    "\n",
    "pdfs = [name for name in filenames if name.endswith(\".pdf\")]\n",
    "docxs = [name for name in filenames if name.endswith(\".docx\")]\n",
    "\n",
    "combined_pdfs = \"\"\n",
    "combined_docxs = \"\"\n",
    "\n",
    "if len(pdfs)>0:\n",
    "    combined_pdfs = documents.PDF(\n",
    "        files=pdfs, \n",
    "        expected_id_col=state.model.get_id_col(),\n",
    "        hash_to_id_offset=state.documents.get_source_hash_to_id_offset_map(),\n",
    "        next_id_offset=state.documents.get_n_new_ids(),\n",
    "    )\n",
    "\n",
    "if len(docxs)>0:\n",
    "    combined_docxs = documents.DOCX(\n",
    "        files=docxs, \n",
    "        expected_id_col=state.model.get_id_col(),\n",
    "        hash_to_id_offset=state.documents.get_source_hash_to_id_offset_map(),\n",
    "        next_id_offset=state.documents.get_n_new_ids(),\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 2: CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = \"/Users/tharunkr/qt-app/checkpoint 2023-05-29 10:03:42.663941/documents/0/train.csv\"\n",
    "\n",
    "# Visualize the dataframe and get the column names in the csv_file. \n",
    "# You will have to pick your choice of strong_columns and weak_columns for the train step shown next.\n",
    "# Strong columns are usually the most important ones like titles of documents, keywords, categories etc\n",
    "# Weak columns are usually the long descriptions\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.display.max_colwidth = 700\n",
    "\n",
    "df = pd.read_csv(csv_file)\n",
    "df.iloc[0:1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model\n",
    "state.model.train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state.model.cold_start(\n",
    "    strong_columns = [\"passage\"]\n",
    "    weak_columns = [\"\"]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to teach your model (RLHF)\n",
    "\n",
    "This is one of the marquee feature that we provide. Thanks to our super efficient training capabilties, we can offer you to teach the retrieval model to correct itself in the event of it not being able to get the correct paragraphs from the document. To this effect, we provide two functions:\n",
    "\n",
    "1. Associate: Using this funciton, you can associate two phrases to give similar results. For examples, assume you're in the contract review domain. And you're interested in asking a question like \"who are the parties involved in this contract?\". However, most contracts have the phrase \"made by and between\" to suggest the parties involved in the contracts (like \"this agreement is made by and between company A and company B\"). In this scenario, you can simply call *model.associate([\"parties involved\",\"made by and between\"])* and the model would learn the relation. In the subsequent documents, you're more likely to retrieve the passage containing the correct information.\n",
    "\n",
    "2. Upvote: Let's say you searched for a query \"is there a limited liability clause?\" and you got 5 search results (aling with their passage IDs). If you know that the corect result is actually the 2nd one instead of the first one. Then you can simpley call *model.upvote(\"is there a limited liability clause\",passage_id_of_the_best_search_result)*.\n",
    "\n",
    "We provide two interfaces to do the teaching.\n",
    "\n",
    "1. You can save a checkpoint to your trained model and export it to our Playground web-app to do QnA and teaching.\n",
    "\n",
    "2. You can skip to the cell titled \"RLHF using function calls\" below."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1: Export your model to Playground App\n",
    "\n",
    "ThirdAI's playground is a dockerized Gradio app that you can run on your laptop and use any model checkpoint to do QnA and teach using the above mentioned functions. \n",
    "\n",
    "Before you save your checkpoint, please go through the following short video tutorial to install Docker Desktop and download our image and run the webapp through a container.\n",
    "\n",
    "https://drive.google.com/file/d/16tI1OAm2Lu0OuUOCiJzGrTjiBZejJWs3/view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your state (include model and the data)\n",
    "\n",
    "from student import models\n",
    "from student.documents import DocList\n",
    "from student.state import State\n",
    "from student.loggers import InMemoryLogger\n",
    "\n",
    "checkpoint_location = \"checkpoint_custom_name.zip\"\n",
    "\n",
    "state.save(checkpoint_location)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you save the checkpoint, please copy the .zip file to the folder from where you're running the docker container. And then go through this short video tutorial to do QnA and teach.\n",
    "\n",
    "https://drive.google.com/file/d/1WIt2-EpYkQJpFgFiUXbc_iYU9uhOJdMn/view"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. RLHF using function calls\n",
    "\n",
    "If you do not want to the dockerized web-app, you can continue from the above "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
