{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions for demo creators: this template is a rough draft to create UDT demo notebooks. \n",
    "You will need to fill in each block with information specific to your problem type (any snake\n",
    "case variable names should be replaced with the actual values)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# problem_name with ThirdAI's Universal Deep Transformer\n",
    "\n",
    "This notebook shows how to build a problem_name model with ThirdAI's\n",
    "Universal Deep Transformer (UDT) model, our all-purpose classifier for tabular datasets.\n",
    "In this demo, we will train and evaluate the model on the dataset_name dataset, \n",
    "but you can easily replace this with your own dataset.\n",
    "\n",
    "To run this notebook, you will need to obtain a ThirdAI license at the following link if you have not already:\n",
    "https://www.thirdai.com/try-bolt/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install thirdai\n",
    "!pip3 install pandas # We need Pandas in the utils module to convert downloaded datasets to CSV format\n",
    "!pip3 install numpy # We use numpy to analyze UDT performance in this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Download\n",
    "\n",
    "We will use the utils module in this repo to download dataset_name (if you have just copied this notebook and not cloned the entire repo, you will need to copy the utils.py file as well). You can replace \n",
    "this step and the next step with a download method and a UDT initilization step\n",
    "that is specific to your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "train_filename, test_filename, inference_batch = utils.download_dataset_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UDT Initilization\n",
    "\n",
    "We can now create a UDT model by passing in the types of each column in the dataset\n",
    "and the target column we want to be able to predict.\n",
    "\n",
    "\n",
    "Instructions to demo creators: if this is a time series UDT problem, include the following as well:\n",
    "\n",
    "For this demo, we additionally want to use \"temporal context\" to make predictions.\n",
    "Adding temporal context requires a single bolt.types.date() column to use to\n",
    "track the timestamp of training data. We pass in a dictionary called \n",
    "temporal_tracking_relationships that tells UDT we want to track value_variable_name\n",
    "over time for each key_variable_name. This allows UDT to make better predictions for\n",
    "the target column by creating temporal features that take into account the \n",
    "historical relationship between key_variable_name and value_variable_name. \n",
    "\n",
    "We customize the \"lookahead\" and \"time_granularity\" for this temporal UDT model:\n",
    "the model will then predict insert_lookahead_amount number of insert_time_granularity_value into the \n",
    "future. The model will use \"insert_time_granularity_value\" as the bin size\n",
    "to group temporal numerical features during training and inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thirdai import bolt\n",
    "model = bolt.UniversalDeepTransformer(\n",
    "    data_types={\n",
    "        \"text\": bolt.types.text(),\n",
    "        \"timestamp\": bolt.types.date(),\n",
    "        \"numerical\": bolt.types.numerical(range=(0, 25)),\n",
    "        \"category_1\": bolt.types.categorical(n_unique_classes=10),\n",
    "        \"category_2\": bolt.types.categorical(n_unique_classes=10)\n",
    "    },\n",
    "    target=\"category_2\",\n",
    "    # Remove below if not a temporal demo, otherwise fill in with correct values\n",
    "    # temporal_tracking_relationships={\"category_1\": [\"numerical\"]},\n",
    "    # lookahead=5,\n",
    "    # time_granularity=\"weekly\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "We can now train our UDT model with just two lines! Feel free to customize the\n",
    "number of epochs and the learning rate; we have chosen values that give good\n",
    "convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = (bolt.TrainConfig(epochs=5, learning_rate=0.01)\n",
    "                    .with_metrics([\"categorical_accuracy\"]))\n",
    "\n",
    "model.train(train_filename, train_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "Evaluating the performance of the UDT model is also just two lines! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_config = bolt.EvalConfig().with_metrics([\"categorical_accuracy\"])\n",
    "\n",
    "model.evaluate(test_filename, eval_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and Loading\n",
    "\n",
    "Saving and loading a trained UDT model to disk is also extremely straight forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_location = \"problem_name.model\"\n",
    "\n",
    "# Saving\n",
    "model.save(save_location)\n",
    "\n",
    "# Loading\n",
    "model = bolt.UniversalDeepTransformer.load(save_location)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Predictions\n",
    "\n",
    "The evaluation method is great for testing, but it requires labels, which don't\n",
    "exist in a production setting. We also have a predict method that can take in an \n",
    "in-memory batch of rows or a single row (without the target column), allowing \n",
    "easy integration into production pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(\"Inference batch:\", inference_batch)\n",
    "\n",
    "prediction = model.predict(inference_batch[0])\n",
    "prediction_batch = model.predict_batch(inference_batch)\n",
    "\n",
    "print(\"Inference prediction:\", model.class_name(np.argmax(prediction)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('ray')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c2b55f3c1070a737cba5ae26c80ccfca8c498ccfe0c448debd0609b3ad9fe7f9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
